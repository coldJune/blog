---
title: 数据加载、存储与文件格式
date: 2018-03-21 08:43:06
categories: 数据分析
copyright: true
tags:
    - 数据分析
    - 输入输出
description: 输入输出分为几个大类：读取文本文件和其他更高效的磁盘存储格式、加载数据库中的数据，利用Web API操作网络资源
---
## 读写文本格式的数据
pandas提供了一些用于将表格型数据读取为DataFrame对象的函数
* pandas中的解析函数

|      函数      |                                    说明                                    |
|:--------------:|:--------------------------------------------------------------------------:|
|    read_csv    |       从文件、URL、文件型对象中加载带分隔符的数据。默认分隔符为逗号        |
|   read_table   |   从文件、URL、文件型对象中加载带分隔符的数据。默认分隔符为制表符("\t")    |
|    read_fwf    |                       读取定宽列格式数据(没有分隔符)                       |
| read_clipboard | 读取剪贴板中的数据，可以看做read_table的剪贴板版。将网页转换为表格时很有用 |

这些函数的选项可以划分为几个大类：
1. 索引：将一个或多个列当做返回的DataFrame处理，以及是否从文件、用户获取列名
2. 类型推断和数据转换：包括用户定义值的转换、缺失值标记列表等
3. 日期解析： 包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列
4. 迭代：支持对大文件进行逐块迭代
5. 不规整数据问题：跳过一些行、页脚、注释或其他一些不重要的东西

* read_csv/read_table函数的参数

|        参数        |                                                                                                    说明                                                                                                    |
|:------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| filepath_or_buffer |                                                          表示文件系统位置、URL、文件型对象的字符串或任何有read()函数的对象(file handle或StringIO)                                                          |
|   sep/delimiter    |                                                                               用于对行中各字段进行拆分的字符序列或正则表达式                                                                               |
|       header       |                                                                     用作列名的行号。默认为0(第一行)，如果没有header行就应该设置为None                                                                      |
|     index_col      |                                                            用作行索引的列编号或列名。可以是单个名称/数字或由多个名称/数字组成的列表(层次化索引)                                                            |
|       names        |                                                                                    用于结果的列名列表，结合header=None                                                                                     |
|      skiprows      |                                                                      需要忽略的行数(从文件开始处算起)，或需要跳过的行号列表(从0开始)                                                                       |
|     na_values      |                                                                                             一组用于替换NA的值                                                                                             |
|      comment       |                                                                               用于将注释信息从行尾拆分出去的字符(一个或多个)                                                                               |
|    parse_dates     | 尝试将数据解析为日期，默认为False。如果为True，则尝试解析所有列。此外，还可以指定需要解析的一组列号或列名。如果列表的元素为列表或元组，就会将多个列组合到一起再进行日期解析工作(日期/时间分别位于两个列中) |
|   keep_data_col    |                                                                           如果连接多列解析日期，则保持参加连接的列。默认为False                                                                            |
|      dayfirst      |                                                                当解析有歧义的日期时，将其看做国际格式(7/6/2018 -> June 7,2018)。默认为False                                                                |
|    date_parser     |                                                                                             用于解析日期的函数                                                                                             |
|       nrows        |                                                                                      需要读取的行数(从文件开始处算起)                                                                                      |
|      iterator      |                                                                                     返回一个TextParser以便逐块读取文件                                                                                     |
|     chunksize      |                                                                                           文件快的大小(用于迭代)                                                                                           |
|    skip_footer     |                                                                                      需要忽略的行数(从文件末尾处算起)                                                                                      |
|      verbose       |                                                                            打印各种解析器输出信息，比如“非数值列中缺失值的数量”                                                                            |
|      encoding      |                                                                          用于unicode的文本编码格式。“utf-8”表示用UTF-8编码的文本                                                                           |
|      squeeze       |                                                                                   如果数据经解析后仅含一列，则返回Series                                                                                   |
|     thousands      | 千分位分隔符，如“，”或“.”                                                                                                                                                                                                           |

可以使用`read_csv`和`read_table`读取一个以逗号分隔的(CSV)文本文件，使用`read_table`是指定分隔符`sep=','`；当未指定列名时，会使用第一行数据当做列名，可以通过设置`header=None`使用默认的列名，也可以使用`names=[]`自己定义列名:
```
In [12]: !type ex1.csv
a,b,c,d,message
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
In [13]: pd.read_csv('ex1.csv')
Out[13]:
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

In [14]: pd.read_table('ex1.csv',sep=',')
Out[14]:
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

In [15]: pd.read_csv('ex1.csv',header=None)
Out[15]:
   0   1   2   3        4
0  a   b   c   d  message
1  1   2   3   4    hello
2  5   6   7   8    world
3  9  10  11  12      foo

In [16]: pd.read_csv('ex1.csv',names=['col1','col2','col3','col4'])
Out[16]:
  col1 col2 col3     col4
a    b    c    d  message
1    2    3    4    hello
5    6    7    8    world
9   10   11   12      foo

In [17]: pd.read_csv('ex1.csv',names=['col1','col2','col3','col4','col5'])
Out[17]:
  col1 col2 col3 col4     col5
0    a    b    c    d  message
1    1    2    3    4    hello
2    5    6    7    8    world
3    9   10   11   12      foo
```
如果需要将数据指定为索引列，可以通过设置`index_col`参数指定索引列，而希望将多个列做成一个层次化索引，只需要传入列编号或列名组成的列表即可：
```
In [21]: !type csv_mindex.csv
key1,key2,value1,value2
one,a,1,2
one,b,3,4
one,c,5,6
one,d,7,8
two,a,9,10
two,b,11,12
two,c,13,14
two,d,15,16

In [22]: pd.read_csv('csv_mindex.csv',index_col='key1')
Out[22]:
     key2  value1  value2
key1
one     a       1       2
one     b       3       4
one     c       5       6
one     d       7       8
two     a       9      10
two     b      11      12
two     c      13      14
two     d      15      16

In [23]: pd.read_csv('csv_mindex.csv',index_col=['key1','key2'])
Out[23]:
           value1  value2
key1 key2
one  a          1       2
     b          3       4
     c          5       6
     d          7       8
two  a          9      10
     b         11      12
     c         13      14
     d         15      16
```
有些表格可能不是固定的分隔符去分隔字段的，对此可以编写一个正则表达式来作为`read_table`的分隔符:
```
In [26]: list(open('ex3.txt'))
Out[26]:
['            A         B         C\n',
 'aaa -0.264438 -1.026059 -0.619500\n',
 'bbb  0.927272  0.302904 -0.032399\n',
 'ccc -0.264273 -0.386314 -0.217601\n',
 'ddd -0.871858 -0.348382  1.100491\n']

In [27]: pd.read_table('ex3.txt',sep='\s+')
Out[27]:
            A         B         C
aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
ccc -0.264273 -0.386314 -0.217601
ddd -0.871858 -0.348382  1.100491
```
同时可以使用`skiprows`跳过指定的行：
```
In [28]: !type ex4.csv
# hey!
a,b,c,d,message
# just wanted to make things more difficult for you
# who reads CSV files with computers, anyway?
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
In [29]: pd.read_csv('ex4.csv',skiprows=[0,2,3])
Out[29]:
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```
默认情况pandas会用一组经常出现的标记值识别缺失值，如NA、-1.#IND以及NULL，可以使用`na_values`指定一组用于表示缺失值的字符串，可以使用一个字典为各列指定不同的NA标记值:
```
In [30]: !type ex5.csv
something,a,b,c,d,message
one,1,2,3,4,NA
two,5,6,,8,world
three,9,10,11,12,foo
In [31]: pd.read_csv('ex5.csv')
Out[31]:
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo

In [32]: pd.read_csv('ex5.csv',na_values=['NULL'])
Out[32]:
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo

In [33]: pd.read_csv('ex5.csv',na_values={'message':['foo','NA'],'something':['two']})
Out[33]:
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       NaN  5   6   NaN   8   world
2     three  9  10  11.0  12     NaN
```
### 逐块读取文本文件
在读取大文件中的参数时，只想读取文件的一小部分或逐块对文件进行迭代;`nrows`用于指定读取几行;`chunksize`用于逐块读取文件时设置行数，`read_csv`返回的TextParse对象可以根据`chunksize`对文件进行逐块迭代：
```
In [46]: pd.read_csv('ex6.csv')
Out[46]:
           one       two     three      four key
0     0.467976 -0.038649 -0.295344 -1.824726   L
1    -0.358893  1.404453  0.704965 -0.200638   B
2    -0.501840  0.659254 -0.421691 -0.057688   G
...        ...       ...       ...       ...  ..
9998 -0.362559  0.598894 -1.843201  0.887292   G
9999 -0.096376 -1.012999 -0.657431 -0.573315   0

[10000 rows x 5 columns]

In [47]: chunk = pd.read_csv('ex6.csv',chunksize=1000)

In [48]: tot = Series([])

In [49]: for piece in chunk:
    ...:     tot = tot.add(piece['key'].value_counts(),fill_value=0)
    ...:

In [50]: tot = tot.sort_values(ascending=False)

In [51]: tot[:10]
Out[51]:
E    368.0
X    364.0
L    346.0
O    343.0
Q    340.0
M    338.0
J    337.0
F    335.0
K    334.0
H    330.0
dtype: float64
```

### 将数据写出到文本格式
利用DataFrame的`to_csv`方法可以将数据写到一个以逗号分隔的文件中，可以是`sep`参数指定其他的分隔符；缺失值在输出结果空会被表示为空字符串，可以使用`na_rep`设置别的标记值；如果没有设置其他选项，则会写出行和列的标签，可以通过`index=False`和`header=False`设置禁用；可以通过设置`columns`来指定顺序排列：
```
In [52]: data = pd.read_csv('ex5.csv')

In [53]: data
Out[53]:
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo

In [54]: data.to_csv('out.csv')

In [55]: !type out.csv
,something,a,b,c,d,message
0,one,1,2,3.0,4,
1,two,5,6,,8,world
2,three,9,10,11.0,12,foo

In [56]: data.to_csv(sys.stdout,sep='|')
|something|a|b|c|d|message
0|one|1|2|3.0|4|
1|two|5|6||8|world
2|three|9|10|11.0|12|foo

In [57]: data.to_csv(sys.stdout,na_rep='NULL')
,something,a,b,c,d,message
0,one,1,2,3.0,4,NULL
1,two,5,6,NULL,8,world
2,three,9,10,11.0,12,foo

In [58]: data.to_csv(sys.stdout,index=False,header=False)
one,1,2,3.0,4,
two,5,6,,8,world
three,9,10,11.0,12,foo

In [60]: data.to_csv(sys.stdout,index=False,columns=['a','b','c'])
a,b,c
1,2,3.0
5,6,
9,10,11.0
```
Series也有`ro_csv`方法，同时Series可以使用`from_csv`读取数据
```
In [61]: Series.from_csv('tseries.csv',parse_dates=True)
Out[61]:
2000-01-01    0
2000-01-02    1
2000-01-03    2
2000-01-04    3
2000-01-05    4
2000-01-06    5
2000-01-07    6
dtype: int64
```
### 手工处理分隔符格式
* CSV语支选项

|       参数       |                                                                                       说明                                                                                       |
|:----------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
|    delimiter     |                                                                      用于分隔字段的单字符字符串。默认为","                                                                       |
|  lineterminator  |                                                 用于写操作的行结束符，默认为"\r\n"。读操作将忽略此选项，它能认出跨平台的行结束符                                                 |
|    quotechar     |                                                              用于带有特殊字符(如分隔符)的字段的引用符号。默认为“"”                                                               |
|     quoting      | 引用约定。可选值包括csv.QUOTE_ALL(引用所有字段)、csv.QUOTE_MINIMAL(只应用带有诸如分隔符之类的特殊字符的字段)、csv.QUOTE_NONNUMERIC以及csv.QUOTE_NON(不引用)。默认为QUOTE_MINIMAL |
| skipinitialspace |                                                                       忽略分隔符后面的空白符。默认为False                                                                        |
|   doublequote    |                                                                  如何处理字段内的引用符号。如果为True，则双写。                                                                  |
|    escapechar    |                                                    用于调分隔符进行转义的字符串(如果quoting被设置为csv.QUOIE_NONE)。默认禁用                                                     |

对于单字符分隔符文件，可以使用Python内置`csv`模块，将任意已打开的文件或文件型对象传给`csv.reader`,对这个reader进行迭代将会为每一行产生去除引号的列表，为了是数据合乎要求，可以做一些整理:
```
In [66]: !type ex7.csv
"a","b","c"
"1","2","3"
"1","2","3"

In [67]: import csv

In [68]: f = open('ex7.csv')

In [69]: reader=csv.reader(f)

In [70]: for line in reader:
    ...:     print(line)
    ...:
['a', 'b', 'c']
['1', '2', '3']
['1', '2', '3']

In [66]: !type ex7.csv
"a","b","c"
"1","2","3"
"1","2","3"

In [67]: import csv

In [68]: f = open('ex7.csv')

In [69]: reader=csv.reader(f)

In [70]: for line in reader:
    ...:     print(line)
    ...:
['a', 'b', 'c']
['1', '2', '3']
['1', '2', '3']
```
csv的文件有很多，可以定义`csv.Dialect`的子类定义出新格式(专门的分隔符、字符串引用约定、行结束符等)，CSV语支的参数也可以以关键字的形式提供给`csv.reader`：
```
In [84]: class my_dialect(csv.Dialect):
    ...:     lineterminator = '\n'
    ...:     delimiter = ';'
    ...:     quotechar = '"'
    ...:     quoting = csv.QUOTE_MINIMAL
    ...:

In [85]: reader = csv.reader(f, dialect=my_dialect)

In [86]: reader = csv.reader(f,delimiter='|')
```
### JSON、XML和HTML
关于此类文件解析可查看[Python文本处理](http://coldjune.com/2018/03/13/Python%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/)

## 二进制数据格式
可以使用Python内置的pickle序列化来实现数据的二进制存储可以使用`pandas.read_pickle`函数将数据读回到Python：
```
In [91]: frame.to_pickle('frame')

In [92]: pd.read_pickle('frame')
Out[92]:
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

### 使用HDF5格式
HDF5能实现高效读取磁盘上以二进制格式存储的科学依据。HDF5中HDF指的是层次性数据格式。每个HDF5文件都含有一个文件系统式的节点结构，能够存储多个数据集并支持元数据。HDF5支持多种压缩器的及时压缩，还能更高效地存储重复模式数据。对于那些非常大的无法直接放入内存的数据集，它可以高效地分块读写。Python的HDF5库有两个接口(PyTables和h5py)。
* PyTables
> PyTables抽象了HDF5的许多细节以提供多种灵活的数据容器、表索引、查询功能以及对核外计算技术的支持。

* h5py
> h5py提供了一种直接而高级的HDF5 API访问接口。

使用SDFStore类需要先下载`tables`：
```
pip3 install tables
```
然后通过PyTables存储pandas对象，HDF5文件中的对象可以通过与字典一样的方式进行获取:
```
In [101]: store['obj1'] = frame

In [102]: store
Out[102]:
<class 'pandas.io.pytables.HDFStore'>
File path: mydata.h5
/obj1            frame        (shape->[3,5])

In [103]: store['obj1']
Out[103]:
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```
### 读取Microsoft Excel文件
pandas的ExcelFile类支持读取存储在Excel 2003(或更高版本)中的表格型数据。由于ExcelFile用到了xlrd和openpyxl包，所以需要安装它们:
```
In [104]: !pip3 install xlrd
In [105]: !pip3 install openpyxl
```
通过传入一个xls或xlsx的路径创建一个ExcelFile实例然后将存放在工作表中的数据读取到DataFrame中：
```
In [112]: xls_file = pd.ExcelFile('ex1.xlsx')

In [113]: table = xls_file.parse('Sheet1')

In [114]: table
Out[114]:
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

## HTML和Web API
HTML和Web API相关内容查看[Python-We客户端和服务器](http://coldjune.com/2018/03/06/Python-Web%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8/)

## 数据库
数据库相关内容查看[Python数据库编程](http://coldjune.com/2018/02/28/Python数据库编程-一/)
