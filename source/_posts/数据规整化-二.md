---
title: 数据规整化(二)
date: 2018-03-22 15:01:03
categories: 数据分析
copyright: true
tags:
    - 数据清洗
    - 数据分析
description: 上一章主要记录了合并数据集，这里讲介绍转换和重塑
---
## 重塑和轴向旋转
### 重塑层次化索引
层次化索引为DataFrame数据的重排提供了具有良好一致性的方式。主要功能包括：
1. stack:将数据的列"旋转"为行
2. unstack:将数据的行"旋转"为列

* stack
对于一个简单的DataFrame使用`stack`方法会得到一个Series，`stack`在运算的时候默认会滤除缺失值，指定`dropna=False`可以保留：
```Python
In [112]: data = DataFrame(np.arange(6).reshape((2,3)),
     ...:                  index=pd.Index(['row1','row2'],name='row'),
     ...:                  columns=pd.Index(['col1','col2','col3'],name='col'))
     ...:

In [113]: data
Out[113]:
col   col1  col2  col3
row
row1     0     1     2
row2     3     4     5

In [114]: resulst = data.stack()

In [115]: resulst
Out[115]:
row   col
row1  col1    0
      col2    1
      col3    2
row2  col1    3
      col2    4
      col3    5
dtype: int32

In [124]: s1 = Series(np.arange(4),index=list('abcd'))

In [125]: s2 = Series([4,5,6],index=list('cde'))

In [126]: data2 = pd.concat([s1,s2],keys=['one','two'])

In [127]: data2
Out[127]:
one  a    0
     b    1
     c    2
     d    3
two  c    4
     d    5
     e    6
dtype: int64

In [129]: data2.unstack()
Out[129]:
       a    b    c    d    e
one  0.0  1.0  2.0  3.0  NaN
two  NaN  NaN  4.0  5.0  6.0

In [130]: data2.unstack().stack()
Out[130]:
one  a    0.0
     b    1.0
     c    2.0
     d    3.0
two  c    4.0
     d    5.0
     e    6.0
dtype: float64

In [132]: data2.unstack().stack(dropna=False)
Out[132]:
one  a    0.0
     b    1.0
     c    2.0
     d    3.0
     e    NaN
two  a    NaN
     b    NaN
     c    4.0
     d    5.0
     e    6.0
dtype: float64
```
* unstack
`unstack`可以将`stack`方法得到的Series重排为一个DataFrame；默认情况下，`unstack`操作的是最内层。传入分层级别的编号或名称即可对其他级别进行`unstack`操作，如果不是所有级别值都能在各分组中找到的话会引入缺失值；在对DataFrame进行`unstack`操作时，作为旋转轴的级别将会成为结果中的最低级别:
```Python
In [140]: resulst
Out[140]:
row   col
row1  col1    0
      col2    1
      col3    2
row2  col1    3
      col2    4
      col3    5
dtype: int32

In [141]: resulst.unstack()
Out[141]:
col   col1  col2  col3
row
row1     0     1     2
row2     3     4     5

In [142]: resulst.unstack(0)
Out[142]:
row   row1  row2
col
col1     0     3
col2     1     4
col3     2     5

In [143]: resulst.unstack('row')
Out[143]:
row   row1  row2
col
col1     0     3
col2     1     4
col3     2     5

In [144]: data2
Out[144]:
one  a    0
     b    1
     c    2
     d    3
two  c    4
     d    5
     e    6
dtype: int64

In [145]: data2.unstack()
Out[145]:
       a    b    c    d    e
one  0.0  1.0  2.0  3.0  NaN
two  NaN  NaN  4.0  5.0  6.0

In [151]: df = DataFrame({'left':resulst,'right':resulst+5},
     ...:                 columns=pd.Index(['left','right'], name='side'))
     ...:

In [152]: df
Out[152]:
side       left  right
row  col
row1 col1     0      5
     col2     1      6
     col3     2      7
row2 col1     3      8
     col2     4      9
     col3     5     10

In [153]: df.unstack('col')
Out[153]:
side left           right
col  col1 col2 col3  col1 col2 col3
row
row1    0    1    2     5    6    7
row2    3    4    5     8    9   10

In [154]: df.unstack('col').stack('side')
Out[154]:
col         col1  col2  col3
row  side
row1 left      0     1     2
     right     5     6     7
row2 left      3     4     5
     right     8     9    10
```

### 将“长格式”旋转为“宽格式”
先预处理实验数据，首先加载数据，使用`PeriodIndex`生成新的索引，使用`Index`选取索引然后使用`reindex`方法根据新的列索引生成数据，然后修改数据的行索引为时间索引，最后生成需要的数据:
```Python
In [217]: periods = pd.PeriodIndex(year=data.year, quarter=data.quarter,name='date')

In [218]: colums = pd.Index(['realgdp','infl','unemp'],name='item')

In [219]: data = data.reindex(columns=colums)

In [220]: data.index = periods.to_timestamp('D','end')

In [221]: ldata = data.stack().reset_index().rename(columns={0:'value'})
```
`pivot`第一个参数节后行索引的列名，第二参数是列索引的列名，最后一个参数值用于填充DataFrame的数据列的列名，如果忽略最后一个参数得到的DataFrame就会带有层次化的列:
```Python
In [233]: ldata[:10]
Out[233]:
        date     item     value
0 1959-03-31  realgdp  2710.349
1 1959-03-31     infl     0.000
2 1959-03-31    unemp     5.800
3 1959-06-30  realgdp  2778.801
4 1959-06-30     infl     2.340
5 1959-06-30    unemp     5.100
6 1959-09-30  realgdp  2775.488
7 1959-09-30     infl     2.740
8 1959-09-30    unemp     5.300
9 1959-12-31  realgdp  2785.204

In [234]: pivoted = ldata.pivot('date','item','value')

In [235]: pivoted.head()
Out[235]:
item        infl   realgdp  unemp
date
1959-03-31  0.00  2710.349    5.8
1959-06-30  2.34  2778.801    5.1
1959-09-30  2.74  2775.488    5.3
1959-12-31  0.27  2785.204    5.6
1960-03-31  2.31  2847.699    5.2

In [236]: ldata['value2'] = np.random.randn(len(ldata))

In [237]: ldata[:10]
Out[237]:
        date     item     value    value2
0 1959-03-31  realgdp  2710.349  0.944599
1 1959-03-31     infl     0.000  0.244179
2 1959-03-31    unemp     5.800  0.055830
3 1959-06-30  realgdp  2778.801  1.182520
4 1959-06-30     infl     2.340  0.266359
5 1959-06-30    unemp     5.100 -0.881742
6 1959-09-30  realgdp  2775.488  0.007021
7 1959-09-30     infl     2.740 -1.171792
8 1959-09-30    unemp     5.300  0.007356
9 1959-12-31  realgdp  2785.204  0.631422

In [238]: pivoted = ldata.pivot('date','item')

In [239]: pivoted[:5]
Out[239]:
           value                    value2
item        infl   realgdp unemp      infl   realgdp     unemp
date
1959-03-31  0.00  2710.349   5.8  0.244179  0.944599  0.055830
1959-06-30  2.34  2778.801   5.1  0.266359  1.182520 -0.881742
1959-09-30  2.74  2775.488   5.3 -1.171792  0.007021  0.007356
1959-12-31  0.27  2785.204   5.6  0.136254  0.631422 -0.850516
1960-03-31  2.31  2847.699   5.2 -2.338798  0.897056  0.296124

In [240]: pivoted['value2'][:5]
Out[240]:
item            infl   realgdp     unemp
date
1959-03-31  0.244179  0.944599  0.055830
1959-06-30  0.266359  1.182520 -0.881742
1959-09-30 -1.171792  0.007021  0.007356
1959-12-31  0.136254  0.631422 -0.850516
1960-03-31 -2.338798  0.897056  0.296124
```
相当于使用`set_index`创建层次化索引，再用`unstack`重塑:
```Python
In [243]: ldata.set_index(['date','item']).unstack('item')[:5]
Out[243]:
           value                    value2
item        infl   realgdp unemp      infl   realgdp     unemp
date
1959-03-31  0.00  2710.349   5.8  0.244179  0.944599  0.055830
1959-06-30  2.34  2778.801   5.1  0.266359  1.182520 -0.881742
1959-09-30  2.74  2775.488   5.3 -1.171792  0.007021  0.007356
1959-12-31  0.27  2785.204   5.6  0.136254  0.631422 -0.850516
1960-03-31  2.31  2847.699   5.2 -2.338798  0.897056  0.296124
```
## 数据转换
前面描述的均为数据重排，而另一类重要操作则是过滤、清理以及其他转换工作。
### 移除重复数据
DataFrame的`duplicated`方法返回一个布尔型Series，表示各行是否有重复行；`drop_duplicates`方法用于返回一个移除了重复行的DataFrame。这两个方法默认会判断全部列，可以传入一个列表指定部分列作为重复项判断标准，即根据某些列过滤重复项；两个方法默认保留第一个出现的组合，传入`keep='last'`[^1]则会保留最后一个：
```Python
In [18]: data = DataFrame({'k1':['one']*3+['two']*2,
    ...:                   'k2':[1,1,2,3,3,]})
    ...:

In [19]: data
Out[19]:
    k1  k2
0  one   1
1  one   1
2  one   2
3  two   3
4  two   3

In [20]: data.duplicated()
Out[20]:
0    False
1     True
2    False
3    False
4     True
dtype: bool

In [21]: data.drop_duplicates()
Out[21]:
    k1  k2
0  one   1
2  one   2
3  two   3

In [22]: data.drop_duplicates(['k1'])
Out[22]:
    k1  k2
0  one   1
3  two   3

In [23]: data.drop_duplicates(['k2','k1'],keep='last')
Out[23]:
    k1  k2
1  one   1
2  one   2
4  two   3
```

### 利用函数或映射进行数据转换
Series的`map`方法可以接受一个函数或含有映射关系的字典型对象，使用`map`是一种实现元素级转换以及其他数据清理工作的便捷方式。
```Python
In [48]: data = DataFrame({'food':['bacon','pulled pork','bacon','Pastrami','corned beef',
    ...:                           'Bacon','pastrami','honey ham','nava lox'],
    ...:                   'ounces':[4,3,12,6,7.5,8,3,5,6]})
    ...:

In [49]: meat_to_animal={
    ...:     'bacon':'pig',
    ...:     'pulled pork':'pig',
    ...:     'pastrami':'cow',
    ...:     'corned beef':'cow',
    ...:     'honey ham':'pig',
    ...:     'nava lox':'salmon'
    ...: }

In [50]: data
Out[50]:
          food  ounces
0        bacon     4.0
1  pulled pork     3.0
2        bacon    12.0
3     Pastrami     6.0
4  corned beef     7.5
5        Bacon     8.0
6     pastrami     3.0
7    honey ham     5.0
8     nava lox     6.0

In [51]: data['animal']=data['food'].map(str.lower).map(meat_to_animal)

In [52]: data
Out[52]:
          food  ounces  animal
0        bacon     4.0     pig
1  pulled pork     3.0     pig
2        bacon    12.0     pig
3     Pastrami     6.0     cow
4  corned beef     7.5     cow
5        Bacon     8.0     pig
6     pastrami     3.0     cow
7    honey ham     5.0     pig
8     nava lox     6.0  salmon

In [53]: data['food'].map(lambda x: meat_to_animal[x.lower()])
Out[53]:
0       pig
1       pig
2       pig
3       cow
4       cow
5       pig
6       cow
7       pig
8    salmon
Name: food, dtype: object
```
### 替换值
`replace`方法提供了一种实现替换功能的更简单、更灵活的方式；`replace`支持一次性替换多个值，只需要传入一个由待替换值组成的列表以及一个替换值；如果希望对不同的值进行不同的替换，则传入一个由替换关系组成的列表即可，也可以是字典：
```Python
In [54]: data = Series([1,0,2,0,3,2,0])

In [55]: data.replace(0,-1)
Out[55]:
0    1
1   -1
2    2
3   -1
4    3
5    2
6   -1
dtype: int64

In [56]: data.replace([0,2],-1)
Out[56]:
0    1
1   -1
2   -1
3   -1
4    3
5   -1
6   -1
dtype: int64

In [57]: data.replace([0,2],[-1,9])
Out[57]:
0    1
1   -1
2    9
3   -1
4    3
5    9
6   -1
dtype: int64

In [58]: data.replace({0:-1,1:9})
Out[58]:
0    9
1   -1
2    2
3   -1
4    3
5    2
6   -1
dtype: int64
```
### 重命名轴索引
和Series相同，轴标签也可以通过函数或映射进行转换，从而得到一个新对象。轴还可以被就地修改而无需新建一个数据结构，这些都可以使用`map`方法实现：
```Python
In [63]: data = DataFrame(np.arange(9).reshape((3,3)),
    ...:                  index = ['row1','row2','row4'],
    ...:                  columns=['one','two','three'])
    ...:

In [64]: data
Out[64]:
      one  two  three
row1    0    1      2
row2    3    4      5
row4    6    7      8

In [65]: data.index = data.index.map(str.upper)

In [66]: data
Out[66]:
      one  two  three
ROW1    0    1      2
ROW2    3    4      5
ROW4    6    7      8
```
如果要创建数据集的转换版(而不是修改原始数据)，可以使用`rename`方法；`rename`方法可以结合字典型对象实现对部分轴标签的更新；如果希望就地修改可以传入`implace=True`：
```Python
In [72]: data.rename(index=str.title, columns=str.upper)
Out[72]:
      ONE  TWO  THREE
Row1    0    1      2
Row2    3    4      5
Row4    6    7      8

In [73]: data.rename(index={'ROW1':'ROW'}, columns={'three':'col3'})
Out[73]:
      one  two  col3
ROW     0    1     2
ROW2    3    4     5
ROW4    6    7     8

In [74]: data.rename(index={'ROW1':'ROW'}, columns={'three':'col3'},inplace=True)

In [75]: data
Out[75]:
      one  two  col3
ROW     0    1     2
ROW2    3    4     5
ROW4    6    7     8
```
### 离散化和面元划分
为了便于分析，连续的数据常常被离散化或拆分为“面元”。`cut`函数可以实现将数据划分为面元；其返回的是一个特殊的Categorical对象，相当于一组表示面元名称的字符串。其中`categories`表示不同分类的名称,`codes`属性表示各个数据所属分组的标号。和“区间”的数学符号一样，圆括号表示开端，而方括号则被考试闭端(包括)，哪边是闭端可以使用`right=True`来确定。可以通过`labels`参数设置自己的面元名称。如果向`cut`传入的是面元的数量而不是确切的面元边界，则会根据最大值和最小值来计算等长面元：
```Python
In [96]: ages = [20,22,25,27,21,23,47,54,35,37,32]

In [97]: bins = [18,25,35,60,100]

In [98]: cats = pd.cut(ages,bins)

In [99]: cats
Out[99]:
[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (35, 60], (35, 60], (25, 35], (35, 60], (25, 35]]
Length: 11
Categories (4, interval[int64]): [(18, 25] < (25, 35] < (35, 60] < (60, 100]]

In [100]: cats.categories
Out[100]:
IntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]]
              closed='right',
              dtype='interval[int64]')

In [101]: cats.codes
Out[101]: array([0, 0, 0, 1, 0, 0, 2, 2, 1, 2, 1], dtype=int8)

In [102]: cats = pd.cut(ages,bins,right=False)

In [103]: cats
Out[103]:
[[18, 25), [18, 25), [25, 35), [25, 35), [18, 25), ..., [35, 60), [35, 60), [35, 60), [35, 60), [25, 35)]
Length: 11
Categories (4, interval[int64]): [[18, 25) < [25, 35) < [35, 60) < [60, 100)]

In [104]: group_names=['Youth','YoungAdult','MiddleAged','Senior']

In [105]: cats = pd.cut(ages,bins,labels=group_names,right=False)

In [106]: cats
Out[106]:
[Youth, Youth, YoungAdult, YoungAdult, Youth, ..., MiddleAged, MiddleAged, MiddleAged, MiddleAged, YoungAdult]
Length: 11
Categories (4, object): [Youth < YoungAdult < MiddleAged < Senior]

In [107]: data = np.random.rand(20)

In [108]: pd.cut(data,4,precision=2)
Out[108]:
[(0.75, 0.98], (0.75, 0.98], (0.75, 0.98], (0.52, 0.75], (0.52, 0.75], ..., (0.29, 0.52], (0.061, 0.29], (0.061, 0.29], (0.52, 0.75], (0.52, 0.75]]
Length: 20
Categories (4, interval[float64]): [(0.061, 0.29] < (0.29, 0.52] < (0.52, 0.75] < (0.75, 0.98]]
```
`qcut`是一个类似于`cut`的函数，它可以根据样本分位数对数据进行面元划分，可以得到大小基本相等的面元，和`cut`相同它可以自定义分位数：
```Python
In [109]: data = np.random.rand(1000)

In [110]: cats = pd.qcut(data,4) #按四分位数进行切割

In [111]: cats
Out[111]:
[(0.499, 0.749], (0.263, 0.499], (0.263, 0.499], (0.499, 0.749], (0.263, 0.499], ..., (0.263, 0.499], (0.499, 0.749], (-0.000892, 0.263], (0.749, 0.999], (0.263, 0.499]]
Length: 1000
Categories (4, interval[float64]): [(-0.000892, 0.263] < (0.263, 0.499] < (0.499, 0.749] < (0.749, 0.999]]

In [112]: pd.value_counts(cats)
Out[112]:
(0.749, 0.999]        250
(0.499, 0.749]        250
(0.263, 0.499]        250
(-0.000892, 0.263]    250
dtype: int64

In [113]: pd.qcut(data,[0,0.1,0.5,0.9,1])
Out[113]:
[(0.499, 0.909], (0.104, 0.499], (0.104, 0.499], (0.499, 0.909], (0.104, 0.499], ..., (0.104, 0.499], (0.499, 0.909], (0.104, 0.499], (0.499, 0.909], (0.104, 0.499]]
Length: 1000
Categories (4, interval[float64]): [(-0.000892, 0.104] < (0.104, 0.499] < (0.499, 0.909] < (0.909, 0.999]]
```
### 检测和过滤异常值
异常值(孤立点或离群值)的过滤或变换运算在很大程度上其实就是数组运算,使用数组运算的方法来进行过滤：
```Python
In [123]: np.random.seed(12345)

In [124]: data = DataFrame(np.random.randn(1000,4))

In [125]: col = data[3]

In [126]: col[np.abs(col)>3] #选出绝对值大小超过3的值
Out[126]:
97     3.927528
305   -3.399312
400   -3.745356
Name: 3, dtype: float64

In [127]: data[(np.abs(data)>3).any(1)]#选出超过3或-3的行
Out[127]:
            0         1         2         3
5   -0.539741  0.476985  3.248944 -1.021228
97  -0.774363  0.552936  0.106061  3.927528
102 -0.655054 -0.565230  3.176873  0.959533
305 -2.315555  0.457246 -0.025907 -3.399312
324  0.050188  1.951312  3.260383  0.963301
400  0.146326  0.508391 -0.196713 -3.745356
499 -0.293333 -0.242459 -3.056990  1.918403
523 -3.428254 -0.296336 -0.439938 -0.867165
586  0.275144  1.179227 -3.184377  1.369891
808 -0.362528 -3.548824  1.553205 -2.186301
900  3.366626 -2.372214  0.851010  1.332846

In [128]: data[np.abs(data)>3] = np.sign(data)*3#将值限制在区间-3到3，sign返回的是一个1和-1组成的数组，表示原始值的符号

In [129]: data.describe()
Out[129]:
                 0            1            2            3
count  1000.000000  1000.000000  1000.000000  1000.000000
mean     -0.067623     0.068473     0.025153    -0.002081
std       0.995485     0.990253     1.003977     0.989736
min      -3.000000    -3.000000    -3.000000    -3.000000
25%      -0.774890    -0.591841    -0.641675    -0.644144
50%      -0.116401     0.101143     0.002073    -0.013611
75%       0.616366     0.780282     0.680391     0.654328
max       3.000000     2.653656     3.000000     3.000000
```
### 排列和随机采样
利用`numpy.random.permutation`函数实现对Series或DataFrame的列的排列工作(即随机重排序)。通过需要排列的轴的长度调用`permitation`，可产生一个表示新顺序的整数数组；如果不想用替换的方式选取随机自己可以使用`permitation`，其返回的数组中切下前k个元素；而要通过替换的方式产生样本，最快的方式是通过`np.random.randint`得到一组随机整数：
```Python
In [130]: df = DataFrame(np.arange(5*4).reshape(5,4))

In [131]: sample = np.random.permutation(5)

In [132]: sample
Out[132]: array([1, 0, 2, 3, 4])

In [133]: df
Out[133]:
    0   1   2   3
0   0   1   2   3
1   4   5   6   7
2   8   9  10  11
3  12  13  14  15
4  16  17  18  19

In [134]: df.take(sample)
Out[134]:
    0   1   2   3
1   4   5   6   7
0   0   1   2   3
2   8   9  10  11
3  12  13  14  15
4  16  17  18  19

In [135]: df.take(np.random.permutation(len(df))[:3])
Out[135]:
    0   1   2   3
1   4   5   6   7
3  12  13  14  15
4  16  17  18  19

In [136]: bag = np.array([5,3,25,-1,2])

In [137]: sampler = np.random.randint(0,len(bag),size=10)

In [138]: draws = bag.take(sampler)

In [139]: draws
Out[139]: array([ 2,  2, 25, 25, 25,  5, -1,  5,  2,  3])
```
### 计算指标/哑变量
将分类变量转换为哑变量或指标矩阵是常用于统计建模或机器学习的转换方式。pandas的`get_dummies`函数可以实现如果DataFrame的某一列中含有k个不同的值来派生出一个k列矩阵或DataFrame(其值全为0或1)；如果需要个指标DataFrame的列加上一个前缀以便和其他数据进行合并可以使用`prefix`参数:
```Python
In [152]: df = DataFrame({'key':list('bbacab'),
     ...:                 'data':range(6)})
     ...:

In [153]: df
Out[153]:
   data key
0     0   b
1     1   b
2     2   a
3     3   c
4     4   a
5     5   b

In [154]: pd.get_dummies(df['key'])
Out[154]:
   a  b  c
0  0  1  0
1  0  1  0
2  1  0  0
3  0  0  1
4  1  0  0
5  0  1  0

In [155]: dummies = pd.get_dummies(df['key'],prefix='key')

In [156]: dummies
Out[156]:
   key_a  key_b  key_c
0      0      1      0
1      0      1      0
2      1      0      0
3      0      0      1
4      1      0      0
5      0      1      0

In [157]: df_with_dummies = df[['data']].join(dummies)

In [158]: df_with_dummies
Out[158]:
   data  key_a  key_b  key_c
0     0      0      1      0
1     1      0      1      0
2     2      1      0      0
3     3      0      0      1
4     4      1      0      0
5     5      0      1      0
```
## 字符串操作
### 字符串对象方法

* Python内置的字符串方法

|         方法          |                                              说明                                              |
|:---------------------:|:----------------------------------------------------------------------------------------------:|
|         count         |                              返回子串在字符串中的出现次数(非重叠)                              |
| endswith、startswith  |                      如果字符串以某个后缀结尾(以某个前缀开头)，则返回True                      |
|         join          |                             将字符串用作连接其他字符串序列的分隔符                             |
|         index         |     如果在字符串中找到子串，则返回子串第一个字符所在的位置。如果没有找到，则引发ValueError     |
|         find          |    如果在字符串中找到子串，则返回第一个发现的子串的第一个字符所在的位置。如果没有找到返回-1    |
|         rfind         | 如果在字符串中找到子串，则返回最后一个发现的子串的第一个字符所在的位置。如果没有找到，则返回-1 |
|        replace        |                                   用另一个字符串替换指定子串                                   |
| strip、rstrip、lstrip |                                    去除空白符(包括换行符)。                                    |
|         split         |                             通过指定的分隔符将字符串拆分为一组子串                             |
|     lower、upper      |                                 分别将字母字符转换为小写或大写                                 |
|     ljust、rjust      |                 用空格(或其他字符)填充字符串的空白侧以返回符合最低宽度的字符串                 |

```Python
In [2]: var = 'a, ,b, c'

In [3]: var.split(',')
Out[3]: ['a', ' ', 'b', ' c']

In [5]: pieces = [x.strip() for x in var.split(',')]

In [6]: pieces
Out[6]: ['a', '', 'b', 'c']

In [7]: first,sencond,third,fourth = pieces

In [8]: first+'::'+sencond+'::'+third+'::'+fourth
Out[8]: 'a::::b::c'

In [9]: '::'.join(pieces)
Out[9]: 'a::::b::c'

In [10]: var.index(':')
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-10-d73873441320> in <module>()
----> 1 var.index(':')

ValueError: substring not found

In [11]: var.count(',')
Out[11]: 3

In [12]: var.replace(',','::')
Out[12]: 'a:: ::b:: c'

In [13]: var.replace(',','')
Out[13]: 'a b c'
```

### 正则表达式
见[正则表达式](http://coldjune.com/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/)部分

### pandas中矢量化的字符串函数
* 矢量化的字符串方法

|         方法          |                                     说明                                      |
|:---------------------:|:-----------------------------------------------------------------------------:|
|          cat          |                   实现元素级的字符串连接操作，可指定分隔符                    |
|       contains        |                 返回表示各字符串是否含有指定模式的布尔型数组                  |
|         count         |                                模式的出现次数                                 |
| endswith、startswith  |         相当于对各个元素执行x.endswith(patten)或x.startswith(pattern)         |
|        findall        |                            计算各字符串的模式列表                             |
|          get          |                             获取各元素的第i个字符                             |
|         join          |               根据指定的分隔符将Series中各元素的字符串连接起来                |
|          len          |                              计算各字符串的长度                               |
|     lower、upper      |             转换大小写。相当于对各个元素执行x.lower()或x.upper()              |
|         match         |                  根据指定的正则表达式对各个元素执行re.match                   |
|          pad          |                   在字符串的左边、右边或左右两边添加空白符                    |
|        center         |                            相当于pad(side='both')                             |
|        repeat         |             重复值。例如x.str.repeat(3)相当于对各个字符串执行x*3              |
|         slice         |                      对Series中的各个字符串进行子串截取                       |
|         split         |                    根据分隔符或正则表达式对字符串进行拆分                     |
| strip、rstrip、lstrip | 去除空白符，包括换行符。相当于对各个元素执行x.strip()、x.rstrip()、x.lstrip() |

为了解决`map`方法应用于pandas对象时遇到NA值报错的问题，Series可以通过str属性访问跳过NA的字符串操作方法,可以执行正则表达式:
```Python
In [32]: data = {'Jone':'123@qq.com','bob':'asd@163.com','jim':'jim@gmail.com','tom':np.nan}

In [33]: data = Series(data)

In [34]: data.isnull()
Out[34]:
Jone    False
bob     False
jim     False
tom      True
dtype: bool

In [35]: data.str.contains('gmail')
Out[35]:
Jone    False
bob     False
jim      True
tom       NaN
dtype: object

In [36]: pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]{2,4})'

In [37]: data.str.findall(pattern,flags=re.I)
Out[37]:
Jone       [(123, qq, com)]
bob       [(asd, 163, com)]
jim     [(jim, gmail, com)]
tom                     NaN
dtype: object
```

## 示例
[处理食品数据集](https://github.com/coldJune/Python/blob/master/ipython/ipython_log.py)

[^1]: keep可以取‘first’、‘last’、False分别表示保留第一个，保留最后一个，全部删除。详细可以查看文档。
