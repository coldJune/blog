---
title: 机器学习总结
date: 2019-08-12 20:12:43
categories: 机器学习
copyright: true
mathjax: true
tags:
    - 机器学习
description: 对自己接触和学习到的机器学习算法相关知识点进行一个梳理和总结
---
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设用**P**来评估计算机程序在某任务类**T**上的性能，若一个程序通过利用经验**E**在**T**中任务上获得了性能改善，则我们就说关于**T**和**P**，该程序对**E**进行了学习。<br>
<div style="text-align:right" scoped>Mitcell,1997</div><br>

# 模型评估与选择
## 误差

* 误差
>**误差**是学习器的实际预测输出与样本真实输出之间的差异，其中在训练集上的误差称为**训练误差**或者**经验误差**，在新样本上的误差称为**泛化误差**。

* 过拟合与欠拟合
>**过拟合**是指学习器把训练样本学习得“太好”，可能将训练样本的一些特点当做所有潜在样本都具有的一般性质而导致泛化性能下降。**欠拟合**则相反，它表示对训练样本的一般性质都未曾学到。欠拟合可以克服而过拟合只能缓解。

## 模型评估
* 留出法
>**留出法**直接将训练集划分为两个不相交的子集，一个作为训练集，一个作为测试集。为了保证被划分后的数据拥有和原始数据同样的分布，避免因数据划分而引入额外的偏差影响最终的结果，可以采用**分层采样**(*stratified sampling*)来保留类别比例；因一个数据集可能存在多种划分方式，如果单次使用留出法可能导致结果不够稳定可靠，一般可采用随机划分、重复进行实验后取平均值作为留出法的评估结果；数据划分将导致最后的模型不是整个数据集的训练结果，而只是一部分数据训练出来的，这将降低评估结果的**保真性**(*fidelity*)，由于没有完美的解决方案，一般是将大约$\frac{2}{3}$~$\frac{4}{5}$的样本用作训练，剩余用于测试(测试集至少应含30个样例)

* 交叉验证法
>**交叉验证法**将数据分为$k$个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性(分层采样)，每次用$k-1$个子集的并集作为训练集，剩下的那个作为测试集，如此进行$k$次则可通过$k$组训练/测试集得到$k$个测试结果，最后取均值。交叉验证法又称为**k折交叉验证**(*k-fold cross validation*)，它评估结果的稳定性和保真性很大程度上取决于$k$，这里$k$的取值常用10；与留出法类似，一个数据集可能存在多种划分，为减小划分引入的差别，k折验证法需要使用不同的划分进行$p$次，最终的结果是这p次k折交叉验证结果的均值。

* 留一法
> **留一法**(*Leave-One-Out, LOO*)是交叉验证法的特例，它将大小为$m$的数据集划分成$m$个子集，即每个子集只包含一个样本，这样就不会受随机划分的影响，同时也让用训练集训练的模型和期望评估的用整个数据集训练的模型相似(两个数据集样本数差一)，使结果更为准确。但是当数据量变大时，留一法需要训练$m$个模型，这个计算开销是巨大而不能忍受的。

* 自助法
> 所谓**自助法**(*booststrapping*)就是通过**自助采样**(*booststrap sampling*)[^1]从原始数据集$D$中有放回地随机选取$m$个样本组成训练用数据集$D'$，因为是有放回的采样，所以$D$中的一部分样本可能在$D'$中多次出现，而另一部分样本则不会出现，样本在$m$次采样中始终不出现的概率为$(1-\frac{1}{1})^m$，对$m$取极限可得$\lim_{m \rightarrow \inf}{(1- \frac{1}{m})^m} = \frac{1}{e} \approx 0.368$。这说明通过自助采样之后有$36.8\%$的数据未参与训练，因此我们可以使用这部分数据作为测试数据集，这样获得的测试结果叫做**包外估计**(*out-of-bag estimate*)。虽然自助法在数据集较小，难以有效划分有效训练集/测试集时很有效，并且由于它能参数多个不同的训练集，在集成学习中也能发挥巨大的作用，但由于它产生的数据集改变了原始数据集的分布，引入了估计偏差，因此在数据量足够多时还是使用留一法或交叉验证法会更好一些。

## 性能度量
### 回归
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回归任务中最常用的性能度量是**均方误差**，即对各个样本预测值$f(\boldsymbol{x}_i)$与对应真实值$y_i$的差值的平方进行求和再取平均数：$$E(x;D)=\frac{1}{m}\sum^1_m(f(\boldsymbol{x}_i-y_i))^2$$

### 分类
#### 错误率与精度
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**错误率**是分类错误的样本数占样本总数的比例，**精度**是分类正确的样本数占样本总数的比例，两者相加为$1$。<br>
* 错误率[^2]
$$E(f;D)=\frac{1}{m}\sum_m^1\bold{I}(f(\boldsymbol{x}_i \ne y_i))$$
* 精度
$$acc(f;D)=\frac{1}{m}\sum_m^1\bold{I}(f(\boldsymbol{x}_i = y_i))$$
#### 查准率(准确率)、查全率(召回率)和F1
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**查准率**表示分类结果中真正为正的样本(*真正例*)在分类为正的样本中所占的比例，**查全率**表示分类结果中真正为正的样本在总样本中所占的比例。对于这两个度量标准，可以通过混淆矩阵进行直观的展现，
![混淆矩阵](机器学习总结/混淆矩阵.png)
其中**真正例**(*true positive*)表示预测为真实际也为真，**假反例**(*false negative*)表示实际为真预测为加，**假正例**(*false negative*)表示预测为真实际为假，**真反例**(*true negative*)表示实际为假预测也为假，这四种情形对应的样例数之和为总的样本数。而查准率和查全率用可以用这几种情形进行表示
* 查准率(准确率)
$$P = \frac{TP}{TP+FP}$$
* 查全率(召回率)
$$F = \frac{TP}{TP+FN}$$
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;查准率和查全率是一对相互矛盾的度量，查准率高则查全率低，反之亦然。
# 监督学习
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**监督学习**是指通过给定一个已知正确输出的数据集，使用该数据集训练出一个表示输入和输出之间关系的模型。监督学习的典型代表是**分类(*classification*)**和**回归(*regression*)**。

## 线性回归
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**线性模型**试图学习一个通过属性的线性组合来进行预测的函数，而许多非线性模型也可在线性模型的基础上通过引入层级结构和高维映射获得。线性模型的一般表达式如下:
$$f(x)=w_1x_1+w_2x_2+w_3x_3+...+w_dx_d+b$$
向量形式为:
$$f(x)=\boldsymbol{w^Tx}+b$$
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线性模型因为其中的$\boldsymbol{w}$直观地表达了各属性在预测中的重要性，所以具有很好的**可解释性**。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**线性回归**试图学得一个线性模型来尽可能准确地预测。

[^1]: 即有放回采样
[^2]: $\bold{I}$为指示函数，成立时才为$1$