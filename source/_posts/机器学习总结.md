---
title: 机器学习总结
date: 2019-08-12 20:12:43
categories: 机器学习
copyright: true
mathjax: true
tags:
    - 机器学习
description: 对自己接触和学习到的机器学习算法相关知识点进行一个梳理和总结
---
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设用**P**来评估计算机程序在某任务类**T**上的性能，若一个程序通过利用经验**E**在**T**中任务上获得了性能改善，则我们就说关于**T**和**P**，该程序对**E**进行了学习。<br>
<div style="text-align:right" scoped>Mitcell,1997</div><br>

# 模型评估与选择
## 误差
* 错误率与精度
>**错误率**是指分类错误样本数占总样本数的比率,即$m$个样本有$a$个样本分类错误，错误率为$E=\frac{a}{m}$；**精度**为$acc = 1-\frac{a}{m}$，即“精度=1-错误率”。

* 误差
>**误差**是学习器的实际预测输出与样本真实输出之间的差异，其中在训练集上的误差称为**训练误差**或者**经验误差**，在新样本上的误差称为**泛化误差**。

* 过拟合与欠拟合
>**过拟合**是指学习器把训练样本学习得“太好”，可能将训练样本的一些特点当做所有潜在样本都具有的一般性质而导致泛化性能下降。**欠拟合**则相反，它表示对训练样本的一般性质都未曾学到。欠拟合可以克服而过拟合只能缓解。

## 模型评估
* 留出法
>**留出法**直接将训练集划分为两个不相交的子集，一个作为训练集，一个作为测试集。为了保证被划分后的数据拥有和原始数据同样的分布，避免因数据划分而引入额外的偏差影响最终的结果，可以采用**分层采样**(*stratified sampling*)来保留类别比例；因一个数据集可能存在多种划分方式，如果单次使用留出法可能导致结果不够稳定可靠，一般可采用随机划分、重复进行实验后取平均值作为留出法的评估结果；数据划分将导致最后的模型不是整个数据集的训练结果，而只是一部分数据训练出来的，这将降低评估结果的**保真性**(*fidelity*)，由于没有完美的解决方案，一般是将大约$\frac{2}{3}$~$\frac{4}{5}$的样本用作训练，剩余用于测试(测试集至少应含30个样例)

* 交叉验证法
>**交叉验证法**将数据分为$k$个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性(分层采样)，每次用$k-1$个子集的并集作为训练集，剩下的那个作为测试集，如此进行$k$次则可通过$k$组训练/测试集得到$k$个测试结果，最后取均值。交叉验证法又称为**k折交叉验证**(*k-fold cross validation*)，它评估结果的稳定性和保真性很大程度上取决于$k$，这里$k$的取值常用10；与留出法类似，一个数据集可能存在多种划分，为减小划分引入的差别，k折验证法需要使用不同的划分进行$p$次，最终的结果是这p次k折交叉验证结果的均值。

* 留一法
> **留一法**(*Leave-One-Out, LOO*)是交叉验证法的特例，它将大小为$m$的数据集划分成$m$个子集，即每个子集只包含一个样本，这样就不会受随机划分的影响，同时也让用训练集训练的模型和期望评估的用整个数据集训练的模型相似(两个数据集样本数差一)，使结果更为准确。但是当数据量变大时，留一法需要训练$m$个模型，这个计算开销是巨大而不能忍受的。

# 监督学习
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**监督学习**是指通过给定一个已知正确输出的数据集，使用该数据集训练出一个表示输入和输出之间关系的模型。监督学习的典型代表是**分类(*classification*)**和**回归(*regression*)**。

## 线性回归
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**线性模型**试图学习一个通过属性的线性组合来进行预测的函数，而许多非线性模型也可在线性模型的基础上通过引入层级结构和高维映射获得。线性模型的一般表达式如下:
$$f(x)=w_1x_1+w_2x_2+w_3x_3+...+w_dx_d+b$$
向量形式为:
$$f(x)=\boldsymbol{w^Tx}+b$$
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线性模型因为其中的$\boldsymbol{w}$直观地表达了各属性在预测中的重要性，所以具有很好的**可解释性**。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**线性回归**试图学得一个线性模型来尽可能准确地预测。