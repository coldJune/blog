<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[时间序列(一)]]></title>
    <url>%2F2018%2F03%2F27%2F%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[在多个时间点观察或测量到的任何事物都可以形成一段时间序列。很多时间序列是固定频率的，数据点是根据某种规律定期出现的(比如没15秒、每5分钟、每月出现一次)。时间序列也可以是不定期的。时间序列数据的意义取决于具体的应用场景，主要有几种: 时间戳(timestamp)，特定的时刻 固定时期(period)，如2018年3月或2018年全年 时间间隔(interval),由起始和结束时间戳表示。时期(period)可以被看做间隔(interval)的特例。 实验或过程时间，每个时间点都是相对于特定起始时间的一个度量。例如，从放入烤箱时起，每秒钟饼干的直径 日期和时间数据类型及工具Python标准库包含用于日期(date)和时间(time)数据的数据类型，而且有日历方面的功能。主要用到的事datetime、time、canlendar模块；datetime以毫秒形式存储日期和时间；datetime.timedelta表示两个datetime对象之间的时间差，可以给datetime对象加上(或减去)一个或多个timedelta产生一个新对象 datetime模块中的数据类型 类型 说明 date 以公历形式存储日历日期(年、月、日) time 将时间存储为时、分、秒、毫秒 datetime 存储日期和时间 timedelta 表示两个datetime值之间的差(日、秒、毫秒) 12345678910111213141516171819202122232425262728293031323334In [1]: from datetime import datetimeIn [2]: now = datetime.now()In [3]: nowOut[3]: datetime.datetime(2018, 3, 27, 9, 18, 40, 701738)In [4]: now.year, now.month, now.dayOut[4]: (2018, 3, 27)In [5]: # 使用timedeltaIn [6]: delta = datetime.now() - datetime(2017,8,4)In [7]: deltaOut[7]: datetime.timedelta(235, 33622, 69715)In [8]: delta.daysOut[8]: 235In [9]: delta.secondsOut[9]: 33622In [10]: # 加减timedeltaIn [11]: from datetime import timedeltaIn [12]: start = datetime.now()In [13]: start+timedelta(12)Out[13]: datetime.datetime(2018, 4, 8, 9, 21, 53, 280284)In [14]: start - 2*timedelta(2)Out[14]: datetime.datetime(2018, 3, 23, 9, 21, 53, 280284) 字符串和datetime的相互转换利用str或strftime方法(传入一个格式化字符串),datetime对象和pandas的Timestamp对象可以被格式化为字符串datetime.strptime可以使用相应的格式化编码将字符串转换为日期1 datetime格式定义 代码 说明 %Y 4位数的年 %y 2位数的年 %m 2位数的月[01,12] %d 2位数的日[01,31] %H 时(24小时制)[00,23] %I 是(12小时制)[01,12] %M 2位数的分[00,59] %S 秒00,61 %w 用整数表示的星期几[0(星期天),6] %U 每年的第几周[00,53]。星期天被认为是每周的第一天，每年第一个星期天之前的那几天被认为是”第0周” %W 每年的第几周[00,53]。星期一被认为是每周的第一天，每年第一个星期一之前的那几天被认为是”第0周” %z 以+HHMM或-HHMM表示的UTC时区为naive，则返回空字符串 %F %Y0%m-%d简写形式，例如2018-03-27 %D %m%d%y简写形式，例如03/27/18 特定于当前环境的日期格式 代码 说明 %a 星期几的简写 %A 星期几的全称 %b 月份的简写 %B 月份的全称 %c 完整的日期和时间。例如”Tue 01 May 2012 04:20:57 PM” %p 不同环境中的AM或PM %x 适用于当前环境的日期格式，在美国“May 1, 2012”会产生”05/01/2012” %X 适用于当前环境的时间格式，例如”04:24:12 PM” datetime.strptime是通过已知格式进行日期解析的最佳方式，而对于一些常见的日期格式，可以使用dateutil这个三方包中的parser.parse方法来避免编写格式定义；dateutil可以解析除中文外几乎所有人类能够理解的日期表现形式212345678910111213141516171819202122232425262728293031323334In [18]: #将日期转换为字符串In [19]: stamp = datetime.now()In [20]: str(stamp)Out[20]: '2018-03-27 14:19:08.645810'In [21]: stamp.strftime('%Y-%m-%d')Out[21]: '2018-03-27'In [22]: #将字符串转换为日期In [23]: value = '2018-03-27'In [24]: datetime.strptime(value,'%Y-%m-%d')Out[24]: datetime.datetime(2018, 3, 27, 0, 0)In [25]: datestrs = ['8/4/2017','3/27/2018']In [27]: [datetime.strptime(x, '%m/%d/%Y') for x in datestrs]Out[27]: [datetime.datetime(2017, 8, 4, 0, 0), datetime.datetime(2018, 3, 27, 0, 0)]In [30]: from dateutil.parser import parseIn [31]: parse('2018/03/27')Out[31]: datetime.datetime(2018, 3, 27, 0, 0)In [32]: parse('Jan 31, 1997 10:45 PM')Out[32]: datetime.datetime(1997, 1, 31, 22, 45)In [33]: # 日出现在月的前面，传入dayfirst = TrueIn [34]: parse('4/8/2017', dayfirst=True)Out[34]: datetime.datetime(2017, 8, 4, 0, 0) pandas通常是用于处理成组日期的，不管这些日期时DataFrame的轴索引还是列。to_datetime方法可以解析多种不同的日期表示形式，并且它还可以处理缺失值(None、空字符串等)，NaT(Not a Time) 是pandas中时间戳数据的NA值12345678910111213141516In [45]: datestrsOut[45]: ['8/4/2017', '3/27/2018']In [46]: pd.to_datetime(datestrs)Out[46]: DatetimeIndex(['2017-08-04', '2018-03-27'], dtype='datetime64[ns]', freq=None)In [47]: idx = pd.to_datetime(datestrs + [None])In [48]: idxOut[48]: DatetimeIndex(['2017-08-04', '2018-03-27', 'NaT'], dtype='datetime64[ns]', freq=None)In [49]: idx[2]Out[49]: NaTIn [50]: pd.isnull(idx)Out[50]: array([False, False, True], dtype=bool) 时间序列基础pandas最基本的时间序列类型是以时间戳(以字符串或datetime对象表示)为索引的Series，datetime对象实际上是被放在DatetimeIndex中的，不同索引的时间序列之间的算数运算会自动按日期对齐；pandas使用NumPy的datetime64数据类型以纳秒形式存储时间戳，而DatetimeIndex中各个标量值是pandas的Timestamp对象，在需要的时候Timestamp可以随时自动转换为datetime对象，并且它还可以存储频率信息，且知道如何执行时区转换以及其他操作：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950In [58]: # 创建时间序列In [59]: dates = [datetime(2018,3,d) for d in range(21,27)]In [60]: ts = Series(np.random.randn(6), index=dates)In [61]: tsOut[61]:2018-03-21 0.5550442018-03-22 -0.4045482018-03-23 -1.3347042018-03-24 -0.5506042018-03-25 0.0372302018-03-26 0.298817dtype: float64In [62]: # ts的类型In [63]: type(ts)Out[63]: pandas.core.series.SeriesIn [64]: ts.indexOut[64]:DatetimeIndex(['2018-03-21', '2018-03-22', '2018-03-23', '2018-03-24', '2018-03-25', '2018-03-26'], dtype='datetime64[ns]', freq=None)In [65]: # 不同索引的时间序列之间的算数运算会自动按日期对齐In [66]: ts+ts[::2]Out[66]:2018-03-21 1.1100882018-03-22 NaN2018-03-23 -2.6694092018-03-24 NaN2018-03-25 0.0744612018-03-26 NaNdtype: float64In [67]: # 时间戳类型In [68]: ts.index.dtypeOut[68]: dtype('&lt;M8[ns]')In [69]: #DateIndex中的各个标量值是pandas的Timestamp对象In [70]: stamp =ts.index[0]In [71]: stampOut[71]: Timestamp('2018-03-21 00:00:00') 索引、选取、子集构造索引和数据选取和Series的行为相同，也可以传入一个被解释为日期的字符串；对于较长的时间序列，可以传入 “年” 或 “年月” 选取数据的切片，而通过日期切片的方式只对规则Series有效；对大部分时间序列的数据来说都是按照时间先后排序的，因此可以用不存在于改时间序列中的时间戳进行切片(即范围查找)，而这里同样可以传入字符串日期、datetime或Timestamp，和NumPy一样都是产生原时间序列的视图。可以调用truncate方法并传入before和after来实现相同的效果。而这些对DataFrame同样有效:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143In [73]: # 选取索引和数据In [74]: stamp = ts.index[2]In [75]: ts[stamp]Out[75]: -1.3347042513067129In [81]: # 通过"年"或"年月"切片In [82]: long_ts = Series(np.random.randn(1000),index=pd.date_range('1/1/2018', periods=1000))In [83]: long_tsOut[83]:2018-01-01 0.0472812018-01-02 -0.6303862018-01-03 0.630630 ...2020-09-26 0.993575Freq: D, Length: 1000, dtype: float64In [84]: long_ts['2019']Out[84]:2019-01-01 0.8903282019-01-02 -1.1311932019-01-03 -0.2254572019-01-04 -0.097514 ...2019-12-28 1.0966102019-12-29 0.5341312019-12-30 -1.8596652019-12-31 -0.408150Freq: D, Length: 365, dtype: float64In [85]: long_ts['2019-09']Out[85]:2019-09-01 0.9503792019-09-02 0.5083692019-09-03 0.631864 ...2019-09-26 1.9828012019-09-27 1.6265222019-09-28 0.5467442019-09-29 -0.9716172019-09-30 0.106587Freq: D, dtype: float64In [88]: # 通过日期进行切片In [89]: ts[datetime(2018,3,24):]Out[89]:2018-03-24 -0.5506042018-03-25 0.0372302018-03-26 0.298817dtype: float64In [95]: # 按时间戳进行切片In [96]: tsOut[96]:2018-03-21 0.5550442018-03-22 -0.4045482018-03-23 1.0000002018-03-24 1.0000002018-03-25 1.0000002018-03-26 0.298817dtype: float64In [97]: ts['23/3/2018':'25/3/2018']Out[97]:2018-03-23 1.02018-03-24 1.02018-03-25 1.0dtype: float64In [119]: #切片数据是源数据的视图In [120]: ts = Series(np.random.randn(6), index=dates)In [121]: tsOut[121]:2018-03-21 -0.2097842018-03-22 -0.0341172018-03-23 -0.3831312018-03-24 1.2077782018-03-25 -1.4194932018-03-26 0.019064dtype: float64In [122]: ts_slice = ts['23/3/2018':'25/3/2018']In [123]: ts_slice[0]=1In [124]: tsOut[124]:2018-03-21 -0.2097842018-03-22 -0.0341172018-03-23 1.0000002018-03-24 1.2077782018-03-25 -1.4194932018-03-26 0.019064dtype: float64In [125]: #通过truncate实现切片并实现复制In [126]: ts.truncate(after='24/3/2018', copy=True)Out[126]:2018-03-21 -0.2097842018-03-22 -0.0341172018-03-23 1.0000002018-03-24 1.207778dtype: float64In [127]: ts_slice = ts.truncate(after='24/3/2018', copy=True)In [128]: ts_slice[0]=1In [129]: tsOut[129]:2018-03-21 -0.2097842018-03-22 -0.0341172018-03-23 1.0000002018-03-24 1.2077782018-03-25 -1.4194932018-03-26 0.019064dtype: float64In [130]: # 对DataFrame的行进行索引In [131]: date = pd.date_range('1/3/2018', periods=100, freq='W-WED')In [132]: long_df = DataFrame(np.random.randn(100,4), ...: index=date, ...: columns=['col1','col2','col3','col4']) ...:In [133]: long_df.loc['5-2018']Out[133]: col1 col2 col3 col42018-05-02 -1.217853 -0.052510 1.854937 0.1878702018-05-09 0.555552 -0.276599 -0.145089 -0.6763292018-05-16 0.704234 0.316785 -0.057501 0.0335672018-05-23 0.451673 0.367754 0.121129 -0.8618552018-05-30 -1.057437 -0.904105 -0.025711 -2.689067 带有重复索引的时间序列当多个观测数据落在同一个时间点上的时候，可以通过检查索引的is_unique属性来确定它是否唯一，而对这个时间序列进行索引要么产生 标量值(不重复)，要么产生 切片(重复)；如果需要对具有非唯一时间戳的数据进行聚合，使用groupby并传入level=0(索引的唯一一层):123456789101112131415161718192021222324252627282930313233343536373839404142434445464748In [137]: # 生成时间索引的SeriesIn [138]: dates = pd.DatetimeIndex(['1/3/2018','1/3/2018','2/3/2018','2/3/2018','3/3/2018'])In [139]: dup_ts = Series(np.arange(5), index=dates)In [140]: dup_tsOut[140]:2018-01-03 02018-01-03 12018-02-03 22018-02-03 32018-03-03 4dtype: int32In [141]: #检查索引是否唯一In [142]: dup_ts.index.is_uniqueOut[142]: FalseIn [143]: #对时间序列进行索引In [144]: dup_ts['3/3/2018'] #不重复Out[144]: 4In [145]: dup_ts['2/3/2018'] #重复Out[145]:2018-02-03 22018-02-03 3dtype: int32In [150]: # 进行分组聚合In [151]: grouped = dup_ts.groupby(level=0)In [152]: grouped.count()Out[152]:2018-01-03 22018-02-03 22018-03-03 1dtype: int64In [153]: grouped.mean()Out[153]:2018-01-03 0.52018-02-03 2.52018-03-03 4.0dtype: float64 日期的范围、频率以及移动pandas有一整套标准时间序列频率以及用于重采样、频率推断、生成固定频率日期范围的工具。调用resample方法将时间序列转换为一个具有固定频率的时间序列:12345678910111213141516171819202122232425262728293031In [176]: dates = [datetime(2018,3,d) for d in arange(21, 31, step=2)]In [177]: ts.resample('D').sum()Out[177]:2018-03-21 -2.0840442018-03-22 NaN2018-03-23 1.0758802018-03-24 NaN2018-03-25 0.0452012018-03-26 NaN2018-03-27 -0.7540862018-03-28 NaN2018-03-29 -0.448258Freq: D, dtype: float64In [178]: dates = [datetime(2018,3,d) for d in arange(21, 31, step=2)]In [179]: ts = Series(np.random.randn(5), index=dates)In [180]: ts.resample('D').sum() #转换成固定频率(每日)Out[180]:2018-03-21 -0.3765272018-03-22 NaN2018-03-23 0.2827882018-03-24 NaN2018-03-25 -0.0149752018-03-26 NaN2018-03-27 1.2099552018-03-28 NaN2018-03-29 -1.279524Freq: D, dtype: float64 生成日期范围pandas.data_range用于生成指定长度的DatatimeIndex，默认情况下data_range会产生按天计算的时间点。如果只传入起始或结束时间，那么的传入一个表示一段时间的数字periods。起始和结束日期定义了日期索引的严格边界(如果想要生成一个由每个月最后一个工作日组成的日期索引，传入”BM”频率，这样只会包含时间间隔内(或刚好在边界上)符合频率要求的日期)。data_range默认会保留起始或结束时间戳的 时间 信息(有的话)。如果希望产生一组被规范化到午夜的时间戳，可以设置normalize=True：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556In [182]: index = pd.date_range('8/4/2017','3/27/2018')In [183]: indexOut[183]:DatetimeIndex(['2017-08-04', '2017-08-05', '2017-08-06', '2017-08-07', '2017-08-08', '2017-08-09', '2017-08-10', '2017-08-11', '2017-08-12', '2017-08-13', ... '2018-03-18', '2018-03-19', '2018-03-20', '2018-03-21', '2018-03-22', '2018-03-23', '2018-03-24', '2018-03-25', '2018-03-26', '2018-03-27'], dtype='datetime64[ns]', length=236, freq='D')In [185]: #传入起始日期或结束日期并设置一段时间In [186]: pd.date_range(start='8/4/2017',periods=20)Out[186]:DatetimeIndex(['2017-08-04', '2017-08-05', '2017-08-06', '2017-08-07', '2017-08-08', '2017-08-09', '2017-08-10', '2017-08-11', '2017-08-12', '2017-08-13', '2017-08-14', '2017-08-15', '2017-08-16', '2017-08-17', '2017-08-18', '2017-08-19', '2017-08-20', '2017-08-21', '2017-08-22', '2017-08-23'], dtype='datetime64[ns]', freq='D')In [187]: pd.date_range(end='8/4/2017',periods=20)Out[187]:DatetimeIndex(['2017-07-16', '2017-07-17', '2017-07-18', '2017-07-19', '2017-07-20', '2017-07-21', '2017-07-22', '2017-07-23', '2017-07-24', '2017-07-25', '2017-07-26', '2017-07-27', '2017-07-28', '2017-07-29', '2017-07-30', '2017-07-31', '2017-08-01', '2017-08-02', '2017-08-03', '2017-08-04'], dtype='datetime64[ns]', freq='D')In [188]: #传入频率In [189]: pd.date_range('8/4/2017','3/27/2018', freq='BM')Out[189]:DatetimeIndex(['2017-08-31', '2017-09-29', '2017-10-31', '2017-11-30', '2017-12-29', '2018-01-31', '2018-02-28'], dtype='datetime64[ns]', freq='BM')In [193]: #保留时间信息In [194]: pd.date_range('8/4/2017 12:21:56', periods=5)Out[194]:DatetimeIndex(['2017-08-04 12:21:56', '2017-08-05 12:21:56', '2017-08-06 12:21:56', '2017-08-07 12:21:56', '2017-08-08 12:21:56'], dtype='datetime64[ns]', freq='D')In [203]: #规范化时间In [204]: date_r = pd.date_range('8/4/2017 12:21:56', periods=5, normalize=True)In [205]: date_r[1]Out[205]: Timestamp('2017-08-05 00:00:00', freq='D') 频率和日期偏移量pandas中的频率由一个 基础频率 和一个 乘数 组成。基础频率通常以一个字符串别名表示，比如“M”表示每月，“H”表示每小时。对于每个基础频率，都有一个被称为 日期偏移量 的对象与之对应。按小时计算可以使用Hour类，传入一个整数即可定义偏移量的倍数。一般来说无需显式创建便宜对象，直接使用诸如”H”或”4H”这样的字符串别名即可，在基础频率前加上一个整数可创建倍数；大部分的偏移量对象可以通过加法进行连接，而传入”1h30min”这样的频率字符串也能被高效地解析为等效的表达式。有些频率描述的时间点并不是均匀分隔的。(“M”(日历月末)和”BM”(每月最后一个工作日)就取决于每月的天数，对于后者还要考虑月末是不是周末，这种称为锚点偏移量(anchored offset)3)。 时间序列的基础频率 别名 偏移量类型 说明 D Day 每日历日 B BusinessDay 每工作日 H Hour 每小时 T或min Minute 每分 S Second 每秒 L或ms Milli 每毫秒(即每千分之一秒) U Micro 每微秒(即每百万分之一秒) M MonthEnd 每月最后一个日历日 BM BusinessMonthEnd 每月最后一个工作日 MS MonthBegin 每月第一个日历日 BMS BusinessMonthBegin 每月第一个工作日 W-MON、W-TUE… Week 从指定的星期几(MON、TUE、WED、THU、FRI、SAT、SUN)开始算起，每周 WOM-1MON、WOM-2MON… WeekOfMonth 产生每月第一、第二、第三或第四轴的星期几。例如，WOM-3FRI表示每月的第三个星期五 Q-JAN、Q-FEB… QuaterEnd 对于以指定月份(JAN、FEB、MAR、APR、MAY、JUN、JUL、AUG、SEP、OCT、NOV、DEC)结束的年度，每季度最后一月的最后一个日历日 BQ-JAN、BQ-FEB… BusinessQuarterEnd 对于以指定月份结束的年度，每季度最后一个月的最后一个工作日 QS-JAN、QS-FEB… QuarterBegin 对于以指定月份结束的年度，每季度最后一月的第一个日历日 BQS-JAN、BQS-FEB… BusinessQuarterBegin 对于以指定月份结束的年度，每季度最后一月的第一个工作日 A-JAN、A-FEB… YearEnd 每年指定月份(JAN、FEB、MAR、APR、MAY、JUN、JUL、AUG、SEP、OCT、NOV、DEC)的最后一个日历日 BA-JAN、BA-FEB… BusinessYearEnd 每年指定月份的最后一个工作日 AS-JAN、AS-FEB… YearBegin 每年指定月份的最后一个日历日 BAS-JAN、BAS-FEB… BusinessYearBegin 每年指定月份的最后一个工作日 123456789101112131415161718192021222324252627282930313233343536373839404142434445In [189]: #按小时计算的频率In [190]: from pandas.tseries.offsets import Hour, MinuteIn [191]: hour = Hour()In [192]: hourOut[192]: &lt;Hour&gt;In [193]: four_hours = Hour(4)In [194]: four_hoursOut[194]: &lt;4 * Hours&gt;In [195]: #使用“H”或“4H”字符串别名In [196]: pd.date_range('3/27/2018','3/30/2018', freq='4h')Out[196]:DatetimeIndex(['2018-03-27 00:00:00', '2018-03-27 04:00:00', '2018-03-27 08:00:00', '2018-03-27 12:00:00', '2018-03-27 16:00:00', '2018-03-27 20:00:00', '2018-03-28 00:00:00', '2018-03-28 04:00:00', '2018-03-28 08:00:00', '2018-03-28 12:00:00', '2018-03-28 16:00:00', '2018-03-28 20:00:00', '2018-03-29 00:00:00', '2018-03-29 04:00:00', '2018-03-29 08:00:00', '2018-03-29 12:00:00', '2018-03-29 16:00:00', '2018-03-29 20:00:00', '2018-03-30 00:00:00'], dtype='datetime64[ns]', freq='4H')In [197]: #通过加法连接偏移量In [198]: Hour(2)+Minute(30)Out[198]: &lt;150 * Minutes&gt;In [199]: #传入频率字符串In [200]: pd.date_range('3/27/2018',periods=10,freq='2h30min')Out[200]:DatetimeIndex(['2018-03-27 00:00:00', '2018-03-27 02:30:00', '2018-03-27 05:00:00', '2018-03-27 07:30:00', '2018-03-27 10:00:00', '2018-03-27 12:30:00', '2018-03-27 15:00:00', '2018-03-27 17:30:00', '2018-03-27 20:00:00', '2018-03-27 22:30:00'], dtype='datetime64[ns]', freq='150T') WOM日期WOM(Week Of Month)是一种非常实用的频率类，它以 WOM 开头，能够获得诸如“每个月第三个星期五”之类的日期：123456789In [202]: # 每月第三个星期五In [203]: rng = pd.date_range('3/1/2018','9/1/2018',freq='WOM-3FRI')In [204]: rngOut[204]:DatetimeIndex(['2018-03-16', '2018-04-20', '2018-05-18', '2018-06-15', '2018-07-20', '2018-08-17'], dtype='datetime64[ns]', freq='WOM-3FRI') 移动(超前和滞后)数据移动(shifting) 指的是沿着时间轴将数据前移或后移。Series和DataFrame又一个shift方法用于执行单纯的前移或后移操作，保持索引不变.shift通常用于计算一个时间序列或多个时间序列中的百分比变化(ts/ts.shift(1)-1)。单纯的移位操作不会修改索引，所以部分数据会被丢弃。2⃣️如果频率已知，可以将其传给shift来实现对时间戳进行位移而不是对数据进行简单位移：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051In [205]: #使用shift方法对数据移位In [206]: ts = Series(np.random.randn(4), index=pd.date_range('27/3/2018',periods=4, freq='M'))In [207]: tsOut[207]:2018-03-31 0.5902462018-04-30 -0.4252452018-05-31 0.5055582018-06-30 -0.467728Freq: M, dtype: float64In [208]: ts.shift(2)#后移两位Out[208]:2018-03-31 NaN2018-04-30 NaN2018-05-31 0.5902462018-06-30 -0.425245Freq: M, dtype: float64In [209]: ts.shift(-2)#前移两位Out[209]:2018-03-31 0.5055582018-04-30 -0.4677282018-05-31 NaN2018-06-30 NaNFreq: M, dtype: float64In [212]: ts.shift(2,freq='M') #通过频率对时间戳进行移位，后移两个月Out[212]:2018-05-31 0.5902462018-06-30 -0.4252452018-07-31 0.5055582018-08-31 -0.467728Freq: M, dtype: float64In [213]: ts.shift(-3,freq='D') #通过频率对时间戳进行移位，前移3天Out[213]:2018-03-28 0.5902462018-04-27 -0.4252452018-05-28 0.5055582018-06-27 -0.467728dtype: float64In [214]: ts.shift(-1,freq='3D') #通过频率对时间戳进行移位，前移3天Out[214]:2018-03-28 0.5902462018-04-27 -0.4252452018-05-28 0.5055582018-06-27 -0.467728dtype: float64 通过偏移量对日期进行位移pandas的日期偏移量可以用在datetime或Timestamp对象上；如果是锚点偏移量(比如MethodEnd)，第一次增量会将原日期向前滚动到符合频率规则的下一个日期；通过锚点偏移量的rollforward和rollback方法，可显式地将日期向前或向后滚动；也可以通过groupby或者resample方法来滚动:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051In [219]: #在datetime或Timestamp对象上使用日期偏移量In [220]: from pandas.tseries.offsets import Day, MonthEndIn [221]: now = datetime.now()In [222]: nowOut[222]: datetime.datetime(2018, 3, 27, 20, 19, 34, 880551)In [223]: now + 3* Day()Out[223]: Timestamp('2018-03-30 20:19:34.880551')In [224]: #加上锚点偏移量In [225]: now + MonthEnd()Out[225]: Timestamp('2018-03-31 20:19:34.880551')In [226]: now + MonthEnd(2)Out[226]: Timestamp('2018-04-30 20:19:34.880551')In [231]: #使用rollforward和rollback方法显式向前或向后滚动日期In [232]: offset = MonthEnd()In [233]: offset.rollforward(now) #向前滚动Out[233]: Timestamp('2018-03-31 20:19:34.880551')In [234]: offset.rollback(now) #向后滚动Out[234]: Timestamp('2018-02-28 20:19:34.880551')In [238]: #使用groupby使用滚动In [239]: ts = Series(np.random.randn(20), index=pd.date_range('27/3/2018',periods=20, freq='4d'))In [240]: ts.groupby(offset.rollforward).mean()Out[240]:2018-03-31 0.8474762018-04-30 -0.1946612018-05-31 0.0923922018-06-30 -0.710720dtype: float64In [243]: # 使用resampleIn [244]: ts.resample('M').mean()Out[244]:2018-03-31 0.8474762018-04-30 -0.1946612018-05-31 0.0923922018-06-30 -0.710720Freq: M, dtype: float64 时区处理时区是以UTC偏移量的形式表示。在Python中时区信息来自第三方库pytz，它使Python可以使用Olson数据库(汇编了世界时区信息)。而pandas包装了pytz的功能，所以一般不需要单独学习，只需要记住时区名即可。时区名既可以在官方文档中查看也可以通过交互式的方式查看；要从pytz中获取时区对象，使用pytz.timezone即可，pandas方法虽然接收时区名和时区对象，但建议使用时区名：12345678910111213In [3]: # 使用交互式方式查看时区名In [4]: import pytzIn [5]: pytz.common_timezones[-5:]Out[5]: ['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']In [6]: # 从pytz中获取时区对象In [7]: tz = pytz.timezone('US/Hawaii')In [8]: tzOut[8]: &lt;DstTzInfo 'US/Hawaii' LMT-1 day, 13:29:00 STD&gt; 本地化和转换默认情况下pandas中的时间序列是 单纯的(naive) 时区，其索引的tz字段为 None，在生成日期范围的时候可以加上tz=时区集；从单纯到本地化的转换可以通过tz_localize方法处理，一旦时间序列被本地化到某个特定时区，就可以用tz_convert将其转换到别的时区;tz_localize和tz_convert两个方法都是DatetimeIndex的实例方法:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495In [9]: # 生成时间序列In [10]: rng = pd.date_range('3/29/2018 8:51', periods=6, freq='D')In [11]: ts = Series(np.random.randn(len(rng)), index=rng)In [13]: print(ts.index.tz)NoneIn [16]: # 在生成日期范围时加上时区集In [17]: pd.date_range('3/28/2018 8:53',periods=10, freq='D', tz='UTC')Out[17]:DatetimeIndex(['2018-03-28 08:53:00+00:00', '2018-03-29 08:53:00+00:00', '2018-03-30 08:53:00+00:00', '2018-03-31 08:53:00+00:00', '2018-04-01 08:53:00+00:00', '2018-04-02 08:53:00+00:00', '2018-04-03 08:53:00+00:00', '2018-04-04 08:53:00+00:00', '2018-04-05 08:53:00+00:00', '2018-04-06 08:53:00+00:00'], dtype='datetime64[ns, UTC]', freq='D')In [18]: # 使用tz_localize方法将单纯转换为本地化In [19]: tsOut[19]:2018-03-29 08:51:00 -2.4962072018-03-30 08:51:00 0.6329442018-03-31 08:51:00 1.0187562018-04-01 08:51:00 -0.0179842018-04-02 08:51:00 -2.5229742018-04-03 08:51:00 1.096955Freq: D, dtype: float64In [20]: ts_utc = ts.tz_localize('UTC')In [21]: ts_utcOut[21]:2018-03-29 08:51:00+00:00 -2.4962072018-03-30 08:51:00+00:00 0.6329442018-03-31 08:51:00+00:00 1.0187562018-04-01 08:51:00+00:00 -0.0179842018-04-02 08:51:00+00:00 -2.5229742018-04-03 08:51:00+00:00 1.096955Freq: D, dtype: float64In [22]: ts_utc.indexOut[22]:DatetimeIndex(['2018-03-29 08:51:00+00:00', '2018-03-30 08:51:00+00:00', '2018-03-31 08:51:00+00:00', '2018-04-01 08:51:00+00:00', '2018-04-02 08:51:00+00:00', '2018-04-03 08:51:00+00:00'], dtype='datetime64[ns, UTC]', freq='D')In [23]: # 使用tz_covert方法转换到别的时区In [24]: ts_utc.tz_convert('US/Eastern')Out[24]:2018-03-29 04:51:00-04:00 -2.4962072018-03-30 04:51:00-04:00 0.6329442018-03-31 04:51:00-04:00 1.0187562018-04-01 04:51:00-04:00 -0.0179842018-04-02 04:51:00-04:00 -2.5229742018-04-03 04:51:00-04:00 1.096955Freq: D, dtype: float64In [25]: # 将ts本地化到EST再转换为UTC或柏林时间In [26]: ts_eastern = ts.tz_localize('US/Eastern')In [27]: ts_eastern.tz_convert('UTC')Out[27]:2018-03-29 12:51:00+00:00 -2.4962072018-03-30 12:51:00+00:00 0.6329442018-03-31 12:51:00+00:00 1.0187562018-04-01 12:51:00+00:00 -0.0179842018-04-02 12:51:00+00:00 -2.5229742018-04-03 12:51:00+00:00 1.096955Freq: D, dtype: float64In [28]: ts_eastern.tz_convert('Europe/Berlin')Out[28]:2018-03-29 14:51:00+02:00 -2.4962072018-03-30 14:51:00+02:00 0.6329442018-03-31 14:51:00+02:00 1.0187562018-04-01 14:51:00+02:00 -0.0179842018-04-02 14:51:00+02:00 -2.5229742018-04-03 14:51:00+02:00 1.096955Freq: D, dtype: float64In [29]: # tz_localize和tz_convert是DatetimeIndex的实例方法In [30]: ts.index.tz_localize('Asia/Shanghai')Out[30]:DatetimeIndex(['2018-03-29 08:51:00+08:00', '2018-03-30 08:51:00+08:00', '2018-03-31 08:51:00+08:00', '2018-04-01 08:51:00+08:00', '2018-04-02 08:51:00+08:00', '2018-04-03 08:51:00+08:00'], dtype='datetime64[ns, Asia/Shanghai]', freq='D') 操作时区意识型Timestamp对象跟时间序列和日期范围一样，Timestamp对象也能被从 单纯型(naive) 本地化为 时区意识型(time zone-aware)，并从一个时区转换到另一个时区；可以在创建Timestamp对象时，传入一个时区信息。时区意识型Timestamp对象在内部保存了一个UTC时间戳值(自UNIX纪元(1970年1月1日)算起的纳秒数)，而这个UTC值在时区转换过程中不会变化，当使用pandas的DateOffset对象执行时间算术运算时，运算过程会自动关注是否存在夏令时转变期:12345678910111213141516171819202122232425262728293031323334353637383940In [34]: # 创建Timestamp对象并本地化，转换时区In [35]: stamp = pd.Timestamp('2018-3-28 9:08')In [36]: stamp_utc = stamp.tz_localize('UTC') #本地化为UTCIn [37]: stamp_utcOut[37]: Timestamp('2018-03-28 09:08:00+0000', tz='UTC')In [38]: stamp_utc.tz_convert('US/Eastern') #转换到USE时区Out[38]: Timestamp('2018-03-28 05:08:00-0400', tz='US/Eastern')In [39]: # 创建一个带有时区信息的TimestampIn [40]: stamp_moscow = pd.Timestamp('2018-3-28 9:00', tz='Asia/Shanghai')In [41]: stamp_moscowOut[41]: Timestamp('2018-03-28 09:00:00+0800', tz='Asia/Shanghai')In [43]: stamp_moscow.valueOut[43]: 1522198800000000000In [44]: stamp_moscow.tz_convert('US/Eastern').valueOut[44]: 1522198800000000000In [52]: # DateOffset对象执行算术运算In [53]: stamp = pd.Timestamp('2012-3-12 1:30', tz='US/Eastern') #夏令时转变前30minIn [54]: stamp + Hour()Out[54]: Timestamp('2012-03-12 02:30:00-0400', tz='US/Eastern')In [55]: stamp = pd.Timestamp('2012-11-4 00:30', tz='US/Eastern') #夏令时转变前90minIn [56]: stampOut[56]: Timestamp('2012-11-04 00:30:00-0400', tz='US/Eastern')In [57]: stamp + 2*Hour()Out[57]: Timestamp('2012-11-04 01:30:00-0500', tz='US/Eastern') 不同时区之间的运算如果两个时间序列的时区不同，在将它们合并到一起时，最终结果就会是UTC；而由于时间戳是以UTC存储的，所以不需要发生任何转换:123456789101112131415161718192021222324252627282930313233343536In [78]: rng = pd.date_range('3/29/2018 8:51', periods=6, freq='B')In [79]: ts = Series(np.random.randn(len(rng)), index=rng)In [80]: # 分别设置时区In [81]: ts1 = ts[:6].tz_localize('Asia/Shanghai')In [82]: ts2 = ts1[2:].tz_convert('Europe/Moscow')In [83]: ts1Out[83]:2018-03-29 08:51:00+08:00 -0.6850112018-03-30 08:51:00+08:00 0.2579922018-04-02 08:51:00+08:00 -0.6503802018-04-03 08:51:00+08:00 0.0505112018-04-04 08:51:00+08:00 -0.4414192018-04-05 08:51:00+08:00 -1.618306Freq: B, dtype: float64In [84]: ts2Out[84]:2018-04-02 03:51:00+03:00 -0.6503802018-04-03 03:51:00+03:00 0.0505112018-04-04 03:51:00+03:00 -0.4414192018-04-05 03:51:00+03:00 -1.618306Freq: B, dtype: float64In [85]: result = ts1+ts2In [86]: result.indexOut[86]:DatetimeIndex(['2018-03-29 00:51:00+00:00', '2018-03-30 00:51:00+00:00', '2018-04-02 00:51:00+00:00', '2018-04-03 00:51:00+00:00', '2018-04-04 00:51:00+00:00', '2018-04-05 00:51:00+00:00'], dtype='datetime64[ns, UTC]', freq='B') 1.闰秒，是指为保持协调世界时接近于世界时时刻，由国际计量局统一规定在年底或年中（也可能在季末）对协调世界时增加或减少1秒的调整 ↩2.dateutil.parser并不完美，它会将一些原本不是日期的字符串认作是日期(例如将’23’解析成当月的23号，而大于日期的例如’32’会被解析为2032年的今天) ↩3.来源于书上的叫法(《利用Python进行数据分析》) ↩]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据聚合与分组运算示例]]></title>
    <url>%2F2018%2F03%2F26%2F%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88%E4%B8%8E%E5%88%86%E7%BB%84%E8%BF%90%E7%AE%97%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[用特定与分组的值填充缺失值 对于缺失数据的清理工作，有时会用dropna将其滤除，而有时则可能希望用一个固定值或由数据集本身所衍生出来的值去填充NA值，这时就需要使用fillna。 1234567891011121314151617181920212223In [3]: s = Series(np.random.randn(6))In [4]: s[::2] = np.nanIn [5]: sOut[5]:0 NaN1 1.4673292 NaN3 0.0665194 NaN5 -0.324448dtype: float64In [6]: s.fillna(s.mean()) # 用平均值填充NA值Out[6]:0 0.4031331 1.4673292 0.4031333 0.0665194 0.4031335 -0.324448dtype: float64 对不同的分组填充不同的值，只需将数据分组，并使用apply和一个能够对各数据块调用fillna的函数：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859In [7]: states = ['CD', 'CQ','XJ','XM','SH','BJ','NJ','TJ']In [8]: group_key = ['West']*4 +['East']*4In [9]: data = Series(np.random.randn(8),index=states)In [10]: data[['XJ','BJ','TJ']] = np.nanIn [11]: dataOut[11]:CD 0.438333CQ 0.156206XJ NaNXM 0.309649SH -0.692189BJ NaNNJ 1.812046TJ NaNdtype: float64In [12]: data.groupby(group_key).mean()Out[12]:East 0.559928West 0.301396dtype: float64In [13]: # 用分组平均值去填充NA值In [14]: fill_mean = lambda g: g.fillna(g.mean())In [15]: data.groupby(group_key).apply(fill_mean)Out[15]:CD 0.438333CQ 0.156206XJ 0.301396XM 0.309649SH -0.692189BJ 0.559928NJ 1.812046TJ 0.559928dtype: float64In [22]: # 在代码中预定义各组的填充值，可以使用各分组的name属性In [23]: fill_values=&#123;'East':0.5,'West':1&#125;In [24]: fill_func = lambda g: g.fillna(fill_values[g.name])In [25]: data.groupby(group_key).apply(fill_func)Out[25]:CD 0.438333CQ 0.156206XJ 1.000000XM 0.309649SH -0.692189BJ 0.500000NJ 1.812046TJ 0.500000dtype: float64 随机采样和排列 从一个大数据集中随机抽取样本可以选取np.random.permutation(N)的前K个元素，其中N为完整数据的大小，K为期望的样本大小下面将构造一个扑克牌 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677In [37]: # 红桃(Hearts)、黑桃(Spades)、梅花(Clubs)、方片(Diamonds)In [38]: suits = ['H','S','C','D']In [39]: card_val = (list(range(1,11))+[10]*3)*4In [40]: base_names = ['A']+list(range(2,11))+['J','K','Q']In [41]: cards = []In [42]: for suit in suits: ...: # 构造卡牌 ...: cards.extend(str(num)+ suit for num in base_names) ...:In [43]: deck = Series(card_val,index=cards)In [44]: deck[:13] # 长度为52的Series，其索引为牌名，值则是用于记分的点数Out[44]:AH 12H 23H 34H 45H 56H 67H 78H 89H 910H 10JH 10KH 10QH 10dtype: int64In [47]: def draw(deck, n=5): ...: # 从整副牌中抽出5张 ...: return deck.take(np.random.permutation(len(deck))[:n]) ...:In [48]: draw(deck) # 抽牌Out[48]:3H 3KS 109D 910S 10JH 10dtype: int64In [53]: # 从每种花色中抽取两张牌。由于花色是最后一个字符，所以根据这个进行分组并使用applyIn [54]: get_suit = lambda card:card[-1] # 只要最后一个字母In [55]: deck.groupby(get_suit).apply(draw, n=2)Out[55]:C 10C 10 KC 10D JD 10 6D 6H 6H 6 3H 3S JS 10 7S 7dtype: int64In [56]: # 另一种方法In [57]: deck.groupby(get_suit, group_keys=False).apply(draw, n=2)Out[57]:7C 73C 310D 105D 5KH 108H 8AS 16S 6dtype: int64 分组加权平均数和相关系数 根据groupby的“拆分-应用-合并”范式，DataFrame的列与列之间或两个Series之间的运算(比如分组加权平均)称为一种标准作业 1234567891011121314151617181920212223242526272829In [60]: df = DataFrame(&#123;'category':list('aaaabbbb'), ...: 'data':np.random.randn(8), ...: 'weights':np.random.rand(8)&#125;) ...:In [61]: dfOut[61]: category data weights0 a -0.183911 0.0658501 a -0.977102 0.8974962 a 1.632742 0.0529663 a 1.820148 0.9148464 b -1.387401 0.2564625 b 0.858152 0.9776656 b 1.613297 0.5494507 b 0.365536 0.472255In [69]: # 利用catefory计算加权平均数:In [70]: grouped = df.groupby('category')In [71]: get_wavg = lambda g: np.average(g['data'], weights=g['weights'])In [72]: grouped.apply(get_wavg)Out[72]:categorya 0.446664b 0.683660dtype: float64 来自Yahoo!Finance的数据集，其中含有标准普尔500指数(SPX字段)和几只股票的收盘价123456789101112131415161718192021222324252627282930313233343536373839404142434445In [75]: # 读取数据In [76]: close_px = pd.read_csv('stock_px.csv', parse_dates=True, index_col=0)In [77]: close_px[:4]Out[77]: AA AAPL GE IBM JNJ MSFT PEP SPX XOM1990-02-01 4.98 7.86 2.87 16.79 4.27 0.51 6.04 328.79 6.121990-02-02 5.04 8.00 2.87 16.89 4.37 0.51 6.09 330.92 6.241990-02-05 5.07 8.18 2.87 17.32 4.34 0.51 6.05 331.85 6.251990-02-06 5.01 8.12 2.88 17.56 4.32 0.51 6.15 329.66 6.23In [78]: # 计算一个由日收益率(通过百分数变化计算)与SPX之间的年度相关系数组成的DataFrameIn [79]: rets = close_px.pct_change().dropna()In [80]: spx_corr = lambda x: x.corrwith(x['SPX'])In [81]: by_year = rets.groupby(lambda x: x.year)In [84]: by_year.apply(spx_corr)[:5]Out[84]: AA AAPL GE IBM JNJ MSFT PEP \1990 0.595024 0.545067 0.752187 0.738361 0.801145 0.586691 0.7831681991 0.453574 0.365315 0.759607 0.557046 0.646401 0.524225 0.6417751992 0.398180 0.498732 0.632685 0.262232 0.515740 0.492345 0.4738711993 0.259069 0.238578 0.447257 0.211269 0.451503 0.425377 0.3850891994 0.428549 0.268420 0.572996 0.385162 0.372962 0.436585 0.450516 SPX XOM1990 1.0 0.5175861991 1.0 0.5693351992 1.0 0.3184081993 1.0 0.3189521994 1.0 0.395078In [85]: # 计算列和列之间的相关系数In [88]: by_year.apply(lambda g: g['AAPL'].corr(g['MSFT']))[:4] #计算苹果和微软的年度相关系数Out[88]:1990 0.4082711991 0.2668071992 0.4505921993 0.236917dtype: float64 面向分组的线性回归 利用statsmodels库对各数据块执行普通最小二乘法回归: 安装statsmodels库 1In [89]: !pip3 install statsmodels 计算线性回归 1234567891011121314151617181920212223242526272829303132333435In [90]: import statsmodels.api as smIn [91]: def regress(data, yvar, xvars): ...: Y = data[yvar] ...: X = data[xvars] ...: X['intercept'] = 1. ...: result = sm.OLS(Y,X).fit() ...: return result.params ...:In [92]: by_year.apply(regress, 'AAPL', ['SPX']) # 按年计算AAPL对SPX收益率的线性回归Out[92]: SPX intercept1990 1.512772 0.0013951991 1.187351 0.0003961992 1.832427 0.0001641993 1.390470 -0.0026571994 1.190277 0.0016171995 0.858818 -0.0014231996 0.829389 -0.0017911997 0.749928 -0.0019011998 1.164582 0.0040751999 1.384989 0.0032732000 1.733802 -0.0025232001 1.676128 0.0031222002 1.080330 -0.0001992003 1.187770 0.0006902004 1.363463 0.0042012005 1.766415 0.0032462006 1.645496 0.0000802007 1.198761 0.0034382008 0.968016 -0.0011102009 0.879103 0.0029542010 1.052608 0.0012612011 0.806605 0.001514 2012联邦选举委员会数据库12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788In [105]: # 读取文件In [106]: fec = pd.read_csv('P00000001-ALL.csv', low_memory=False)In [107]: #fec.loc[123456]In [108]: # 读取文件In [109]: fec = pd.read_csv('P00000001-ALL.csv', low_memory=False)In [110]: fec.loc[123456] #DataFrame中记录Out[110]:cmte_id C00431445cand_id P80003338cand_nm Obama, Barackcontbr_nm ELLMAN, IRAcontbr_city TEMPEcontbr_st AZcontbr_zip 852816719contbr_employer ARIZONA STATE UNIVERSITYcontbr_occupation PROFESSORcontb_receipt_amt 50contb_receipt_dt 01-DEC-11receipt_desc NaNmemo_cd NaNmemo_text NaNform_tp SA17Afile_num 772372Name: 123456, dtype: objectIn [111]: # 数据中没有党派信息，通过unique可以获取全部候选人名单，利用字典说明党派关系In [112]: unique_cands = fec.cand_nm.unique()In [113]: unique_candsOut[113]:array(['Bachmann, Michelle', 'Romney, Mitt', 'Obama, Barack', "Roemer, Charles E. 'Buddy' III", 'Pawlenty, Timothy', 'Johnson, Gary Earl', 'Paul, Ron', 'Santorum, Rick', 'Cain, Herman', 'Gingrich, Newt', 'McCotter, Thaddeus G', 'Huntsman, Jon', 'Perry, Rick'], dtype=object)In [117]: parties=&#123;'Bachmann, Michelle':'Republican', ...: 'Romney, Mitt':'Republican', ...: "Roemer, Charles E. 'Buddy' III":'Republican', ...: 'Pawlenty, Timothy':'Republican', ...: 'Johnson, Gary Earl':'Republican', ...: 'Paul, Ron':'Republican', ...: 'Santorum, Rick':'Republican', ...: 'Cain, Herman':'Republican', ...: 'Gingrich, Newt':'Republican', ...: 'McCotter, Thaddeus G':'Republican', ...: 'Huntsman, Jon':'Republican', ...: 'Obama, Barack':'Democrat', ...: 'Perry, Rick':'Republican'&#125; ...:In [118]: # 通过这个映射以及Series对象的map方法可以根据候选人姓名得到一组党派信息In [119]: fec.cand_nm[123456:123461]Out[119]:123456 Obama, Barack123457 Obama, Barack123458 Obama, Barack123459 Obama, Barack123460 Obama, BarackName: cand_nm, dtype: objectIn [120]: fec.cand_nm[123456:123461].map(parties)Out[120]:123456 Democrat123457 Democrat123458 Democrat123459 Democrat123460 DemocratName: cand_nm, dtype: objectIn [121]: # 将其添加为一个新列In [122]: fec['party'] = fec.cand_nm.map(parties)In [123]: # 限定该数据集只有正的出资额In [124]: fec = fec[fec.contb_receipt_amt&gt;0]In [125]: # 由于Barack Obama和Mitt Romney是最主要的两名候选人，所以准备一个只包含针对两人的竞选活动的赞助信息的子集In [126]: fec_mrbo = fec[fec.cand_nm.isin(['Obama, Barack','Romney, Mitt'])] 根据职业和雇主统计赞助信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071In [127]: #根据职业计算出资总额In [128]: fec.contbr_occupation.value_counts()[:10]Out[128]:RETIRED 233990INFORMATION REQUESTED 35107ATTORNEY 34286HOMEMAKER 29931PHYSICIAN 23432INFORMATION REQUESTED PER BEST EFFORTS 21138ENGINEER 14334TEACHER 13990CONSULTANT 13273PROFESSOR 12555Name: contbr_occupation, dtype: int64In [129]: # 许多职业都涉及相同的基本工作类型，或者同一样东西有多重辩题。下面通过将一个职业信息映射到另一个来清理这样的数据In [130]: occ_mapping =&#123; ...: 'INFORMATION REQUESTED PER BEST EFFORTS':'NOT PROVIDED', ...: 'INFORMATION REQUESTED':'NOT PROVIDED', ...: 'INFORMATION REQUESTED (BEST EFFORTS)':'NOT PROVIDED', ...: 'C.E.O':'CEO'&#125; ...:In [131]: # 使用dict.get允许没有映射关系的职业也能通过，如果没有映射关系则返回xIn [132]: f = lambda x: occ_mapping.get(x,x)In [133]: fec.contbr_occupation = fec.contbr_occupation.map(f)In [134]: # 对雇主也进行相同的处理In [135]: emp_mapping = &#123; ...: 'INFORMATION REQUESTED PER BEST EFFORTS':'NOT PROVIDED', ...: 'INFORMATION REQUESTED':'NOT PROVIDED', ...: 'SELF':'SELF-EMPLOYED', ...: 'SELF EMPLOYED':'SELF-EMPLOYED',&#125; ...:In [136]: f = lambda x : emp_mapping.get(x,x)In [137]: fec.contbr_employer = fec.contbr_employer.map(f)In [138]: # 通过pivor_table根据党派和职业对数据进行聚合，然后过滤掉总出资额不足200万美元的数据In [139]: by_occupation = fec.pivot_table('contb_receipt_amt', index='contbr_occupation',columns='party',aggfunc='sum')In [140]: over_2mm = by_occupation[by_occupation.sum(1)&gt;2000000]In [141]: over_2mmOut[141]:party Democrat Republicancontbr_occupationATTORNEY 11141982.97 7.477194e+06C.E.O. 1690.00 2.592983e+06CEO 2074284.79 1.640758e+06CONSULTANT 2459912.71 2.544725e+06ENGINEER 951525.55 1.818374e+06EXECUTIVE 1355161.05 4.138850e+06HOMEMAKER 4248875.80 1.363428e+07INVESTOR 884133.00 2.431769e+06LAWYER 3160478.87 3.912243e+05MANAGER 762883.22 1.444532e+06NOT PROVIDED 4866973.96 2.056547e+07OWNER 1001567.36 2.408287e+06PHYSICIAN 3735124.94 3.594320e+06PRESIDENT 1878509.95 4.720924e+06PROFESSOR 2165071.08 2.967027e+05REAL ESTATE 528902.09 1.625902e+06RETIRED 25305116.38 2.356124e+07SELF-EMPLOYED 672393.40 1.640253e+06 出资总额大于两百万美元 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980In [159]: # 对Obama和Romney总出资最高的职业和企业In [160]: #先对候选人进行分组In [161]: def get_top_amounts(group, key, n=5): ...: # 求最大值 ...: totals = group.groupby(key)['contb_receipt_amt'].sum() ...: # 根据key对totals进行降序排列 ...: return totals.sort_values(ascending=False)[n:] ...:In [162]: # 根据职业和雇主进行聚合In [163]: grouped = fec_mrbo.groupby('cand_nm')In [164]: grouped.apply(get_top_amounts, 'contbr_occupation',n=7)Out[164]:cand_nm contbr_occupationObama, Barack PROFESSOR 2165071.08 CEO 2073284.79 PRESIDENT 1878509.95 NOT EMPLOYED 1709188.20 EXECUTIVE 1355161.05 TEACHER 1250969.15 WRITER 1084188.88 OWNER 1001567.36 ENGINEER 951525.55 INVESTOR 884133.00 ARTIST 763125.00 MANAGER 762883.22 SELF-EMPLOYED 672393.40 STUDENT 628099.75 REAL ESTATE 528902.09 CHAIRMAN 496547.00 ARCHITECT 483859.89 DIRECTOR 471741.73 BUSINESS OWNER 449979.30 EDUCATOR 436600.89 PSYCHOLOGIST 427299.92 SOFTWARE ENGINEER 396985.65 PARTNER 395759.50 SALES 392886.91 EXECUTIVE DIRECTOR 348180.94 MANAGING DIRECTOR 329688.25 SOCIAL WORKER 326844.43 VICE PRESIDENT 325647.15 ADMINISTRATOR 323079.26 SCIENTIST 319227.88 ...Romney, Mitt NON-PROFIT VETERANS ORG. CHAIR/ANNUITA 10.00 PARAPLANNER 10.00 APPRAISAL 10.00 SIGN CONTRACTOR 10.00 POLITICAL OPERATIVE 10.00 PORT MGT 10.00 PRESIDENT EMERITUS 10.00 CONTRACTS SPECIALIST 9.00 TEACHER &amp; FREE-LANCE JOURNALIST 9.00 FOUNDATION CONSULTANT 6.00 MAIL HANDLER 6.00 TREASURER &amp; DIRECTOR OF FINANCE 6.00 SECRETARY/BOOKKEPPER 6.00 ELAYNE WELLS HARMER 6.00 CHICKEN GRADER 5.00 DIRECTOR REISCHAUER CENTER FOR EAST A 5.00 SCOTT GREENBAUM 5.00 EDUCATION ADMIN 5.00 ENGINEER/RISK EXPERT 5.00 PLANNING AND OPERATIONS ANALYST 5.00 VILLA NOVA 5.00 FINANCIAL INSTITUTION - CEO 5.00 HORTICULTURIST 5.00 MD - UROLOGIST 5.00 DISTRICT REPRESENTATIVE 5.00 INDEPENDENT PROFESSIONAL 3.00 REMODELER &amp; SEMI RETIRED 3.00 AFFORDABLE REAL ESTATE DEVELOPER 3.00 IFC CONTRACTING SOLUTIONS 3.00 3RD GENERATION FAMILY BUSINESS OWNER 3.00Name: contb_receipt_amt, Length: 35975, dtype: float64 对出资额分组1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889In [165]: # 利用cut函数根据出资额的大小将数据离散到多个面元中In [166]: bins = np.array([0,1,10,100,1000,10000,100000,1000000,10000000])In [167]: labels = pd.cut(fec_mrbo.contb_receipt_amt,bins)In [168]: labelsOut[168]:411 (10, 100]412 (100, 1000]413 (100, 1000]414 (10, 100]415 (10, 100]416 (10, 100]417 (100, 1000]418 (10, 100]419 (100, 1000]420 (10, 100]421 (10, 100]422 (100, 1000]423 (100, 1000]424 (100, 1000]425 (100, 1000]426 (100, 1000]427 (1000, 10000]428 (100, 1000]429 (100, 1000]430 (10, 100]431 (1000, 10000]432 (100, 1000]433 (100, 1000]434 (100, 1000]435 (100, 1000]436 (100, 1000]437 (10, 100]438 (100, 1000]439 (100, 1000]440 (10, 100] ...701356 (10, 100]701357 (1, 10]701358 (10, 100]701359 (10, 100]701360 (10, 100]701361 (10, 100]701362 (100, 1000]701363 (10, 100]701364 (10, 100]701365 (10, 100]701366 (10, 100]701367 (10, 100]701368 (100, 1000]701369 (10, 100]701370 (10, 100]701371 (10, 100]701372 (10, 100]701373 (10, 100]701374 (10, 100]701375 (10, 100]701376 (1000, 10000]701377 (10, 100]701378 (10, 100]701379 (100, 1000]701380 (1000, 10000]701381 (10, 100]701382 (100, 1000]701383 (1, 10]701384 (10, 100]701385 (100, 1000]Name: contb_receipt_amt, Length: 694282, dtype: categoryCategories (8, interval[int64]): [(0, 1] &lt; (1, 10] &lt; (10, 100] &lt; (100, 1000] &lt; (1000, 10000] &lt; (10000, 100000] &lt; (100000, 1000000] &lt; (1000000, 10000000]]n [171]: # 根据候选人姓名以及面元标签对数据进行分组In [172]: grouped = fec_mrbo.groupby(['cand_nm',labels])In [173]: grouped.size().unstack(0)Out[173]:cand_nm Obama, Barack Romney, Mittcontb_receipt_amt(0, 1] 493.0 77.0(1, 10] 40070.0 3681.0(10, 100] 372280.0 31853.0(100, 1000] 153991.0 43357.0(1000, 10000] 22284.0 26186.0(10000, 100000] 2.0 1.0(100000, 1000000] 3.0 NaN(1000000, 10000000] 4.0 NaN 两位候选人收到的各种捐赠总额比例 根据州统计赞助信息1234567891011121314151617181920212223242526272829303132333435363738394041n [181]: # 根据候选人和州对数据进行聚合In [182]: grouped = fec_mrbo.groupby(['cand_nm','contbr_st'])In [183]: totals = grouped.contb_receipt_amt.sum().unstack(0).fillna(0)In [184]: totals = totals[totals.sum(1)&gt;100000]In [185]: totals[:10]Out[185]:cand_nm Obama, Barack Romney, Mittcontbr_stAK 281840.15 86204.24AL 543123.48 527303.51AR 359247.28 105556.00AZ 1506476.98 1888436.23CA 23824984.24 11237636.60CO 2132429.49 1506714.12CT 2068291.26 3499475.45DC 4373538.80 1025137.50DE 336669.14 82712.00FL 7318178.58 8338458.81In [186]: # 对各行除以总赞助额会得到各候选人在各州的总赞助额比例In [187]: percent = totals.div(totals.sum(1),axis=0)In [188]: percent[:10]Out[188]:cand_nm Obama, Barack Romney, Mittcontbr_stAK 0.765778 0.234222AL 0.507390 0.492610AR 0.772902 0.227098AZ 0.443745 0.556255CA 0.679498 0.320502CO 0.585970 0.414030CT 0.371476 0.628524DC 0.810113 0.189887DE 0.802776 0.197224FL 0.467417 0.532583]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>聚合与分组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据聚合和分组运算]]></title>
    <url>%2F2018%2F03%2F25%2F%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88%E5%92%8C%E5%88%86%E7%BB%84%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[Python和pandas可以利用任何合一接受pandas对象或NumPy数组的函数执行复杂的分组运算： 根据一个或多个键(可以是函数、数组或DataFrame列名)拆分pandas对象 计算分组摘要统计，如计数、平均数、标准差或用户自定义函数 对DataFrame的列应用各种各样的函数 应用组内转换或其他运算，如规格化、线性回归、排名或选取子集等 计算透视表或交叉表 执行分位数分析以及其他分组分析 GroupBy技术pandas对象(无论是Series、DataFrane还是其他)中的数据会根据提供的一个或多个键被拆分(split)为多组。拆分操作是在对象的特定轴上执行。然后将一个函数应用(apply)到各个分组并产生一个新值。最后这些函数的执行结果会被合并(combine)到最终结果中。结果对象的形式一般取决于数据上所执行的操作。 split-apply-combine(分组聚合) 分组键可以有多种形式，且类型不必相同(后三种只是快捷方式其最终目的是产生一组用于拆分对象的值)： 列表或数组，其长度和待分组轴一样 表示DataFrame某个列名的值 字典或Series，给出待分组轴上的值或分组名之间的对应关系 函数、用于处理轴索引或索引中的各个标签 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152In [4]: df = DataFrame(&#123;'key1':list('aabba'), ...: 'key2':['one','two','one','two','one'], ...: 'data1':np.random.randn(5), ...: 'data2':np.random.randn(5)&#125;) ...:In [5]: dfOut[5]: data1 data2 key1 key20 -0.007051 1.406114 a one1 1.136247 1.320876 a two2 0.285600 -2.665997 b one3 1.578314 0.772522 b two4 0.263382 -0.067916 a oneIn [6]: #按key1进行分组，并计算data1的平均值In [7]: #访问data1，并根据key1调用groupbyIn [8]: grouped = df['data1'].groupby(df['key1'])In [9]: grouped #变量grouped是一个GroupBy对象。它没有进行任何计算，该对象已经有了接下来对分组执行运算所需的一切信息Out[9]: &lt;pandas.core.groupby.SeriesGroupBy object at 0x11292e4e0&gt;In [10]: #调用GroupBy的mean方法计算分组平均值In [11]: grouped.mean()#数据(Series)根据分组键进行了聚合，产生新的一个Series，其索引为key1列中的唯一值Out[11]:key1a 0.464193b 0.931957Name: data1, dtype: float64In [12]: # 传入多个数组In [15]: means = df['data1'].groupby([df['key1'],df['key2']]).mean()#通过两个键对数据进行了分组，得到一个Series具有层次化索引(由唯一的建对组成)In [16]: meansOut[16]:key1 key2a one 0.128166 two 1.136247b one 0.285600 two 1.578314Name: data1, dtype: float64In [17]: means.unstack()Out[17]:key2 one twokey1a 0.128166 1.136247b 0.285600 1.578314 以上分组键均为Series，2⃣️分组键可以是任何 长度适当 的数组，也可以将列名(可以是字符串、数字或其他Python对象)用作分组键:1234567891011121314151617181920212223242526272829303132In [18]: states=np.array(['Ohio','California','California','Ohio','Ohio'])In [19]: years = np.array([2005,2005,2006,2005,2006])In [20]: df['data1'].groupby([states,years]).mean()#分组键为适当长度的数组Out[20]:California 2005 1.136247 2006 0.285600Ohio 2005 0.785631 2006 0.263382Name: data1, dtype: float64In [21]: # 分组键为列名In [22]: df.groupby('key1').mean()Out[22]: data1 data2key1a 0.464193 0.886358b 0.931957 -0.946738In [23]: # 结果中没有key2列是因为这一列不是数值数据，会从结果中排除。默认情况所有数值列都会被聚合In [24]: df.groupby(['key1','key2']).mean()Out[24]: data1 data2key1 key2a one 0.128166 0.669099 two 1.136247 1.320876b one 0.285600 -2.665997 two 1.578314 0.772522 对分组进行迭代GroupBy对象支持迭代，可以产生一组二元元组(由分组名和数据块组成):123456789101112131415In [26]: for name, group in df.groupby('key1'): ...: print('分组名',name) ...: print('数据块\n',group) ...:分组名 a数据块 data1 data2 key1 key20 -0.007051 1.406114 a one1 1.136247 1.320876 a two4 0.263382 -0.067916 a one分组名 b数据块 data1 data2 key1 key22 0.285600 -2.665997 b one3 1.578314 0.772522 b two 对于多重键的情况，元组的第一个元素将会是由键值组成的元组：12345678910111213141516171819202122232425262728293031323334353637In [28]: for (k1,k2), group in df.groupby(['key1','key2']): ...: print(k1,k2) ...: print(group) ...:a one data1 data2 key1 key20 -0.007051 1.406114 a one4 0.263382 -0.067916 a onea two data1 data2 key1 key21 1.136247 1.320876 a twob one data1 data2 key1 key22 0.2856 -2.665997 b oneb two data1 data2 key1 key23 1.578314 0.772522 b twoIn [33]: # 将数据片段转化成一个字典In [34]: pieces = dict(list(df.groupby('key1')))In [35]: pieces['a']Out[35]: data1 data2 key1 key20 -0.007051 1.406114 a one1 1.136247 1.320876 a two4 0.263382 -0.067916 a oneIn [36]: piecesOut[36]:&#123;'a': data1 data2 key1 key2 0 -0.007051 1.406114 a one 1 1.136247 1.320876 a two 4 0.263382 -0.067916 a one, 'b': data1 data2 key1 key2 2 0.285600 -2.665997 b one 3 1.578314 0.772522 b two&#125; groupby默认是在axis=0(DataFrame行)上进行分组，通过设置可以在其他任何轴上进行分组：1234567891011121314151617In [42]: # 通过dtype对列进行分组In [43]: grouped = df.groupby(df.dtypes, axis=1)In [44]: dict(list(grouped))Out[44]:&#123;dtype('float64'): data1 data2 0 -0.007051 1.406114 1 1.136247 1.320876 2 0.285600 -2.665997 3 1.578314 0.772522 4 0.263382 -0.067916, dtype('O'): key1 key2 0 a one 1 a two 2 b one 3 b two 4 a one&#125; 选取一个或一组列对于由DataFrame产生的GroupBy对象，如果用一个(单个字符串)或一组(字符串数组)列名对其进行索引，就能实现选取部分列进行聚合的目的：df.groupby(&#39;key1&#39;)[&#39;data1&#39;]相当于df[&#39;data1&#39;].groupby(&#39;key1&#39;)；df.groupby(&#39;key1&#39;)[[&#39;data2&#39;]]相当于df[[&#39;data2&#39;]].groupby(df[&#39;key1&#39;])。对于大数据集很可能只需要对部分列进行聚合，这种索引操作返回的对象是一个DataFrame(如果传入的是列表或数组)或已分组的Series(如果传入的是标量形式的单个列名):123456789101112131415161718192021222324In [46]: # 计算data2列的平均值并以DataFrame形式得到结果In [47]: df.groupby(['key1','key2'])[['data2']].mean()Out[47]: data2key1 key2a one 0.669099 two 1.320876b one -2.665997 two 0.772522In [48]: s_grouped= df.groupby(['key1','key2'])['data2']In [49]: s_groupedOut[49]: &lt;pandas.core.groupby.SeriesGroupBy object at 0x1119a86a0&gt;In [50]: s_grouped.mean()Out[50]:key1 key2a one 0.669099 two 1.320876b one -2.665997 two 0.772522Name: data2, dtype: float64 通过字典或Series进行分组除了数组以外，分组信息可以是 字典和 Series。Series会被看成一个固定大小的映射，如果用Series作为分组键，则pandas会检查Series以确保其索引跟分组轴对齐：123456789101112131415161718192021222324252627282930313233343536373839404142434445In [55]: people = DataFrame(np.random.randn(5,5), ...: columns=list('abcde'), ...: index=['tom','john','jim','lancy','lucy']) ...:In [56]: people.loc[2:3,['b','c']] = np.nanIn [57]: peopleOut[57]: a b c d etom 1.522909 -1.357885 -0.262730 0.180761 -1.662128john 0.941963 -0.330136 0.520398 -0.069789 0.856472jim -0.077905 NaN NaN 0.527588 -0.162906lancy -0.141172 0.699214 -0.602441 -2.306901 -0.228982lucy -1.345708 0.931025 0.615641 -0.733455 1.321982In [58]: # 字典作为分组键In [59]: mapping = &#123;'a':'red', 'b':'red', 'c':'blue', ...: 'd':'blue', 'e':'red', 'f':'orange'&#125; ...:In [60]: by_column = people.groupby(mapping, axis=1)In [61]: by_column.sum()Out[61]: blue redtom -0.081968 -1.497105john 0.450609 1.468299jim 0.527588 -0.240812lancy -2.909342 0.329059lucy -0.117814 0.907299In [64]: # Series用作分组键In [65]: map_series = Series(mapping)In [66]: people.groupby(map_series, axis=1).count()Out[66]: blue redtom 2 3john 2 3jim 1 2lancy 2 3lucy 2 3 通过函数进行分组任何作为分组键的函数都会在各个索引值上被调用一次，其返回值就会被用作分类名称；同时将函数跟数组、列表、字典、Series混用也可以，因为任何东西都会被转换为数组：1234567891011121314151617181920In [67]: # 根据人名的长度进行分组，可以仅仅传入一个len函数In [68]: people.groupby(len).sum()Out[68]: a b c d e3 1.445004 -1.357885 -0.262730 0.708349 -1.8250354 -0.403745 0.600890 1.136039 -0.803243 2.1784545 -0.141172 0.699214 -0.602441 -2.306901 -0.228982In [72]: # 将函数、列表和数组混用In [73]: key_list =['one','one','one','two','two']In [74]: people.groupby([len,key_list]).min()Out[74]: a b c d e3 one -0.077905 -1.357885 -0.262730 0.180761 -1.6621284 one 0.941963 -0.330136 0.520398 -0.069789 0.856472 two -1.345708 0.931025 0.615641 -0.733455 1.3219825 two -0.141172 0.699214 -0.602441 -2.306901 -0.228982 根据索引级别分组通过level关键字传入级别编号或名称来根据索引级别聚合层次化索引数据集:1234567891011121314151617181920In [77]: columns = pd.MultiIndex.from_arrays([['US','US','US','CH','CH'],[1,3,5,1,3]],names=['cty','tenor'])In [78]: hier_df = DataFrame(np.random.randn(4,5), columns=columns)In [79]: hier_dfOut[79]:cty US CHtenor 1 3 5 1 30 -1.544928 0.860951 -1.021428 0.150361 0.8633321 1.500901 0.411124 0.717717 -1.186560 -0.3416702 1.728200 0.507285 -0.974570 0.856083 0.6066693 0.356776 0.399169 -0.254092 0.274927 0.169848In [80]: hier_df.groupby(level='cty',axis=1).count()Out[80]:cty CH US0 2 31 2 32 2 33 2 3 数据聚合聚合指任何能够从数组产生标量值的数据转换过程，许多常见的聚合运算都有就地计算数据集统计信息的优化实现，也可以自己定义聚合运算，还可以调用分组对象上已经定义好的任何方法。 经过优化的groupby方法 函数名 说明 count 分组中非NA值的数量 sum 非NA值的和 mean 非NA值的平均数 median 非NA值的算术中位数 std、var 无偏(分母为n-1)标准差和方差 min、max 非NA值的最小值和最大值 prod 非NA值的积 first、last 第一个和最后一个非NA值 12345678910111213141516171819In [6]: dfOut[6]: data1 data2 key1 key20 0.303363 -1.985931 a one1 -1.510949 0.351845 a two2 1.665133 -0.527562 b one3 0.851907 -0.377448 b two4 0.141499 0.969610 a oneIn [7]: grouped = df.groupby('key1')In [8]: # 使用quantile计算Series或DataFrame列的样本分位数In [9]: grouped['data1'].quantile(0.9)Out[9]:key1a 0.27099b 1.58381Name: data1, dtype: float64 quantile是一个Series方法。GroupBy会高效地对Series进行切片，然后对各片调用quantile(0.9).要使用自己写的聚集函数，需要将其传入aggregate或agg方法：12345678910In [45]: def get_to_peak(arr): ...: return arr.max()-arr.min() ...:In [46]: grouped.agg(get_to_peak)Out[46]: data1 data2key1a 1.814312 2.955541b 0.813225 0.150115 并非严格的聚合运算(如describe)也可以在这里使用：12345678910111213141516171819In [47]: grouped.describe()Out[47]: data1 \ count mean std min 25% 50% 75%key1a 3.0 -0.355362 1.004035 -1.510949 -0.684725 0.141499 0.222431b 2.0 1.258520 0.575037 0.851907 1.055214 1.258520 1.461827 data2 \ max count mean std min 25% 50%key1a 0.303363 3.0 -0.221492 1.558956 -1.985931 -0.817043 0.351845b 1.665133 2.0 -0.452505 0.106147 -0.527562 -0.490034 -0.452505 75% maxkey1a 0.660727 0.969610b -0.414976 -0.377448 面向列的多函数应用对Series或DataFrame列的聚合运算其实是使用aggregate(使用自定义函数)或调用诸如mean、std之类的方法。如果希望对不同的列使用不同的聚合函数，活一次应用多个函数可以将函数名以 字符串 的形式传入；如果传入 一组 函数或函数名，得到的DataFrame的列就会以相应的函数命名；如果传入(name，function)元组组成的列表，则元组的第一个元素就会被用作DataFrame的列名(二元元组列表可以看成一个有序映射)；对于DataFrame可以定义一组应用于全部列的函数或不同的列应用不同的函，而结果DataFrame拥有层次化的列，相当于分别对各列进行聚合然后用concat将结果组装到一起，这里也可以传入带有自定义名称的元组列表；如果要对不同的列应用不同的函数，向agg传入一个从列名映射到函数的字典；只有将多个函数应用到至少一列事，DataFrame才会拥有层次化的列，使用小费数据集:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112In [5]: # 准备数据集In [6]: tips = pd.read_csv('tips.csv')In [7]: # 添加"小费占总额百分比"的列In [8]: tips['tip_pct'] = tips['tip']/tips['total_bill']In [9]: tips[:3]Out[9]: total_bill tip smoker day time size tip_pct0 16.99 1.01 No Sun Dinner 2 0.0594471 10.34 1.66 No Sun Dinner 3 0.1605422 21.01 3.50 No Sun Dinner 3 0.166587In [20]: grouped = tips.groupby(['smoker','time']) # 根据smoker和time对tips进行分组In [21]: grouped_pct = grouped['tip_pct']In [22]: grouped_pct.agg('mean') #将函数名以字符串的形式传入Out[22]:smoker timeNo Dinner 0.158653 Lunch 0.160920Yes Dinner 0.160828 Lunch 0.170404Name: tip_pct, dtype: float64In [23]: def peak_to_peak(arr): ...: # 自定义方法 ...: return arr.max() - arr.min() ...:In [24]: grouped_pct.agg(['mean','std', peak_to_peak]) # 传入一组函数或函数名，得到的DataFrame的列名为对应的函数名Out[24]: mean std peak_to_peaksmoker timeNo Dinner 0.158653 0.040458 0.235193 Lunch 0.160920 0.038989 0.193350Yes Dinner 0.160828 0.095153 0.674707 Lunch 0.170404 0.042770 0.169300 In [26]: grouped_pct.agg([('foo','mean'),('bar',np.std)]) #传入一个由(name,function)组成的二元元组列表 Out[26]: foo bar smoker time No Dinner 0.158653 0.040458 Lunch 0.160920 0.038989 Yes Dinner 0.160828 0.095153 Lunch 0.170404 0.042770In [27]: # 定义一组用于全部列的函数In [28]: functions = ['count','mean','max']In [29]: result = grouped['tip_pct','total_bill'].agg(functions)In [30]: resultOut[30]: tip_pct total_bill count mean max count mean maxsmoker timeNo Dinner 106 0.158653 0.291990 106 20.095660 48.33 Lunch 45 0.160920 0.266312 45 17.050889 41.19Yes Dinner 70 0.160828 0.710345 70 21.859429 50.81 Lunch 23 0.170404 0.259314 23 17.399130 43.11In [31]: # 结果DataFrame拥有层次化的列，相当于分别对各列进行聚合，然后用concat将结果组装到一起(列名用作keys参数)In [32]: result['tip_pct']Out[32]: count mean maxsmoker timeNo Dinner 106 0.158653 0.291990 Lunch 45 0.160920 0.266312Yes Dinner 70 0.160828 0.710345 Lunch 23 0.170404 0.259314In [33]: # 传入自定义名称的元组列表In [34]: ftuples = [('Durchschnit','mean'),('Abweichung',np.var)]In [35]: grouped['tip_pct','total_bill'].agg(ftuples)Out[35]: tip_pct total_bill Durchschnit Abweichung Durchschnit Abweichungsmoker timeNo Dinner 0.158653 0.001637 20.095660 69.604821 Lunch 0.160920 0.001520 17.050889 59.587154Yes Dinner 0.160828 0.009054 21.859429 104.148753 Lunch 0.170404 0.001829 17.399130 61.958436In [36]: # 对不同的列应用不同的函数，向agg传入一个从列名映射到函数的字典In [37]: grouped.agg(&#123;'tip':np.max,'size':'sum'&#125;)Out[37]: tip sizesmoker timeNo Dinner 9.0 290 Lunch 6.7 113Yes Dinner 10.0 173 Lunch 5.0 51In [38]: grouped.agg(&#123;'tip_pct':['min','max','mean','std'],'size':'sum'&#125;)Out[38]: tip_pct size min max mean std sumsmoker timeNo Dinner 0.056797 0.291990 0.158653 0.040458 290 Lunch 0.072961 0.266312 0.160920 0.038989 113Yes Dinner 0.035638 0.710345 0.160828 0.095153 173 Lunch 0.090014 0.259314 0.170404 0.042770 51 以”无索引”的形式返回聚合数据可以通过向groupby传入as_index=False以禁用生成唯一分组键组成的索引(层次化索引):1234567In [39]: tips.groupby(['smoker','time'], as_index=False).mean()Out[39]: smoker time total_bill tip size tip_pct0 No Dinner 20.095660 3.126887 2.735849 0.1586531 No Lunch 17.050889 2.673778 2.511111 0.1609202 Yes Dinner 21.859429 3.066000 2.471429 0.1608283 Yes Lunch 17.399130 2.834348 2.217391 0.170404 分组级运算和转换聚合是分组运算的其中一种，它是数据转换的一个特例，它接受能够将一维数组简化为标量值的函数12345678910111213141516171819202122232425262728In [43]: #使用县聚合再合并的方式为一个DataFrame添加一个用于存放各索引分组平均值的列In [44]: dfOut[44]: data1 data2 key1 key20 0.568585 -0.865028 a one1 0.191774 0.063184 a two2 1.877514 -0.445805 b one3 0.834648 -0.260108 b two4 -0.250249 -1.472969 a oneIn [45]: k1_means = df.groupby('key1').mean().add_prefix('mean_')# 利用np.mean函数对两个数据列进行转换In [46]: k1_meansOut[46]: mean_data1 mean_data2key1a 0.170037 -0.758271b 1.356081 -0.352957In [47]: pd.merge(df,k1_means, left_on='key1', right_index=True)Out[47]: data1 data2 key1 key2 mean_data1 mean_data20 0.568585 -0.865028 a one 0.170037 -0.7582711 0.191774 0.063184 a two 0.170037 -0.7582714 -0.250249 -1.472969 a one 0.170037 -0.7582712 1.877514 -0.445805 b one 1.356081 -0.3529573 0.834648 -0.260108 b two 1.356081 -0.352957 transformtransform会将一个函数应用到各个分组，然后将结果放置到适当的位置上。如果各分组产生的是一个标量值，则该值就会被广播出去；transform和aggregate一样也是一个有着严格条件的特殊函数：传入的函数只能产生两种结果，要么产生一个可以广播的标量值，要么产生一个相同大小的结果数组：12345678910111213141516In [49]: key=['one','two','one','two','one']In [50]: people.groupby(key).mean()Out[50]: a b c d eone -0.761405 0.060654 0.157032 -0.791220 0.330372two -0.253093 0.201181 0.138541 0.459374 0.860159In [51]: people.groupby(key).transform(np.mean)Out[51]: a b c d etom -0.761405 0.060654 0.157032 -0.791220 0.330372john -0.253093 0.201181 0.138541 0.459374 0.860159jim -0.761405 0.060654 0.157032 -0.791220 0.330372lancy -0.253093 0.201181 0.138541 0.459374 0.860159lucy -0.761405 0.060654 0.157032 -0.791220 0.330372 从各组中减去平均值：123456789101112131415161718192021In [52]: def demean(arr): ...: # 创建一个距平化函数 ...: return arr - arr.mean() ...:In [53]: dameaned = people.groupby(key).transform(demean)In [54]: dameanedOut[54]: a b c d etom -0.529944 0.771323 -1.053227 0.098752 -0.720876john 1.022316 0.626768 -0.418873 -0.901180 -0.117146jim 0.626749 0.642272 -0.110584 0.192733 -0.023483lancy -1.022316 -0.626768 0.418873 0.901180 0.117146lucy -0.096805 -1.413596 1.163811 -0.291486 0.744359In [55]: dameaned.groupby(key).mean() #检查现在分组的平均值是否为0Out[55]: a b c d eone -7.401487e-17 0.0 0.0 3.700743e-17 -3.700743e-17two 0.000000e+00 0.0 0.0 0.000000e+00 -5.551115e-17 apply:一般性的”拆分-应用-合并”apply会将待处理的对象拆分成多个片段，然后对各片段调用传入的函数，最后尝试将各片段组合到一起；如果传给apply的函数能够接受其他参数或关键字，可以将这些内容放在函数名后面一并传入:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172In [58]: def top(df, n=5, column='tip_pct'): ...: # 在指定列找出最大值，然后把这个值所在的行选取出来 ...: return df.sort_values(by=column)[-n:] ...:In [59]: top(tips, n=3)Out[59]: total_bill tip smoker day time size tip_pct67 3.07 1.00 Yes Sat Dinner 1 0.325733178 9.60 4.00 Yes Sun Dinner 2 0.416667172 7.25 5.15 Yes Sun Dinner 2 0.710345In [60]: top(tips, n=6)Out[60]: total_bill tip smoker day time size tip_pct109 14.31 4.00 Yes Sat Dinner 2 0.279525183 23.17 6.50 Yes Sun Dinner 4 0.280535232 11.61 3.39 No Sat Dinner 2 0.29199067 3.07 1.00 Yes Sat Dinner 1 0.325733178 9.60 4.00 Yes Sun Dinner 2 0.416667172 7.25 5.15 Yes Sun Dinner 2 0.710345In [61]: def top(df, n=5, column='tip_pct'): ...: # 在指定列找出最大值，然后把这个值所在的行选取出来 ...: return df.sort_values(by=column)[-n:] ...:In [62]: top(tips, n=3)Out[62]: total_bill tip smoker day time size tip_pct67 3.07 1.00 Yes Sat Dinner 1 0.325733178 9.60 4.00 Yes Sun Dinner 2 0.416667172 7.25 5.15 Yes Sun Dinner 2 0.710345In [65]: tips.groupby('smoker').apply(top) #top函数在DataFrame的各个片段上调用，然后结果由pandas.concat组装到一起，并以分 ...: 组名称进行了标记，最后得到了一个层次化索引，内层索引值来源于原DataFrameOut[65]: total_bill tip smoker day time size tip_pctsmokerNo 88 24.71 5.85 No Thur Lunch 2 0.236746 185 20.69 5.00 No Sun Dinner 5 0.241663 51 10.29 2.60 No Sun Dinner 2 0.252672 149 7.51 2.00 No Thur Lunch 2 0.266312 232 11.61 3.39 No Sat Dinner 2 0.291990Yes 109 14.31 4.00 Yes Sat Dinner 2 0.279525 183 23.17 6.50 Yes Sun Dinner 4 0.280535 67 3.07 1.00 Yes Sat Dinner 1 0.325733 178 9.60 4.00 Yes Sun Dinner 2 0.416667 172 7.25 5.15 Yes Sun Dinner 2 0.710345In [66]: # 传给apply的函数能接受其他参数或关键字，则可以将这些内容放在函数名后面In [67]: tips.groupby(['smoker','day']).apply(top,n=2,column='total_bill')Out[67]: total_bill tip smoker day time size tip_pctsmoker dayNo Fri 91 22.49 3.50 No Fri Dinner 2 0.155625 94 22.75 3.25 No Fri Dinner 2 0.142857 Sat 59 48.27 6.73 No Sat Dinner 4 0.139424 212 48.33 9.00 No Sat Dinner 4 0.186220 Sun 112 38.07 4.00 No Sun Dinner 3 0.105070 156 48.17 5.00 No Sun Dinner 6 0.103799 Thur 85 34.83 5.17 No Thur Lunch 4 0.148435 142 41.19 5.00 No Thur Lunch 5 0.121389Yes Fri 90 28.97 3.00 Yes Fri Dinner 2 0.103555 95 40.17 4.73 Yes Fri Dinner 4 0.117750 Sat 102 44.30 2.50 Yes Sat Dinner 3 0.056433 170 50.81 10.00 Yes Sat Dinner 3 0.196812 Sun 184 40.55 3.00 Yes Sun Dinner 2 0.073983 182 45.35 3.50 Yes Sun Dinner 3 0.077178 Thur 83 32.68 5.00 Yes Thur Lunch 2 0.152999 197 43.11 5.00 Yes Thur Lunch 4 0.115982 禁止分组键分组键会跟原始对象的索引共同构成结果对象中的层次化索引,向groupvy传入group_keys=False禁用:1234567In [68]: tips.groupby('smoker',group_keys=False).apply(top,n=2)Out[68]: total_bill tip smoker day time size tip_pct149 7.51 2.00 No Thur Lunch 2 0.266312232 11.61 3.39 No Sat Dinner 2 0.291990178 9.60 4.00 Yes Sun Dinner 2 0.416667172 7.25 5.15 Yes Sun Dinner 2 0.710345 分位数和桶分析pandas有一些根据指定面元或样本分位数1将数据拆分成多块的工具(比如cut和qcut)，将这些函数跟groupby结合起来，能实现对数据集的桶(bucket)2或分位数(quantile)分析。 长度相等的桶 12345678910111213141516171819202122232425262728293031323334353637In [73]: # 生成随机数据集In [74]: frame = DataFrame(&#123;'data1':np.random.randn(1000), ...: 'data2':np.random.randn(1000)&#125;) ...:In [75]: factor = pd.cut(frame.data1, 4) #使用cut将其装入长度相等的桶In [76]: factor[:5]Out[76]:0 (-0.019, 1.563]1 (-1.601, -0.019]2 (1.563, 3.146]3 (-0.019, 1.563]4 (-1.601, -0.019]Name: data1, dtype: categoryCategories (4, interval[float64]): [(-3.19, -1.601] &lt; (-1.601, -0.019] &lt; (-0.019, 1.563] &lt; (1.563, 3.146]]In [77]: # 由cut返回的Factor对象可直接用于groupbyIn [81]: def get_stats(group): ...: # 返回对应调用的方法和列名 ...: return &#123;'min':group.min(),'max':group.max(), ...: 'count':group.count(),'mean':group.mean()&#125; ...:In [82]: grouped = frame.data2.groupby(factor)In [83]: grouped.apply(get_stats).unstack()Out[83]: count max mean mindata1(-3.19, -1.601] 48.0 2.748015 0.087192 -1.809659(-1.601, -0.019] 452.0 3.046213 -0.007537 -3.326031(-0.019, 1.563] 444.0 2.372145 -0.012882 -3.489221(1.563, 3.146] 56.0 3.598193 0.165933 -2.688040 大小相等的桶 使用qcut根据样本分位数得到大小相等的桶，传入labels=False即可只获取分位数的编号 1234567891011121314In [87]: # 返回分位数编号In [88]: grouping = pd.qcut(frame.data1, 10, labels=False)In [89]: gropuped = frame.data2.groupby(grouping)In [90]: grouped.apply(get_stats).unstack()Out[90]: count max mean mindata1(-3.19, -1.601] 48.0 2.748015 0.087192 -1.809659(-1.601, -0.019] 452.0 3.046213 -0.007537 -3.326031(-0.019, 1.563] 444.0 2.372145 -0.012882 -3.489221(1.563, 3.146] 56.0 3.598193 0.165933 -2.688040 透视表和交叉表透视表透视表根据一个或多个键对数据进行聚合，并根据行和列上的分组键将数据分配到各个矩形区域中。可以通过groupby功能以及(能够使用层次化索引的)重塑运算制作透视表。DataFrame有一个pivot_table方法(默认聚合类型为分组平均数)，还有一个顶层的pandas.pivot_table函数。除了能为groupby提供便利外，pivot_table还能添加分项小计(也叫做margins)，只需要传入margins=True，这会添加标签为All的行和列，其值对应于单个等级中所有数据的分组统计；要使用其他函数通过aggfunc传入；通过使用fill_value填充NA值。 pivot_table的参数 参数名 说明 values 待聚合的列的名称。默认集合所有数值列 index 用于分组的列名或其他分组键，出现在结果透视表的行 columns 用于分组的列名或其他分组键，出现在结果透视表的列 aggfunc 聚合函数或函数列表，默认为’mean’。可以是任何对groupby有效的函数 fill_value 用于替换结果列表中的缺失值 margins 添加行/列小计和总计，默认为False 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869In [97]: #根据smoker和time计算分组平均数In [98]: tips.pivot_table(index=['smoker','time'])Out[98]: size tip tip_pct total_billsmoker timeNo Dinner 2.735849 3.126887 0.158653 20.095660 Lunch 2.511111 2.673778 0.160920 17.050889Yes Dinner 2.471429 3.066000 0.160828 21.859429 Lunch 2.217391 2.834348 0.170404 17.399130In [100]: # 聚合tip_pct和size,根据day进行分组，将smoker放在列上，day放在行上In [101]: tips.pivot_table(['tip_pct','size'],index=['time','day'],columns='smoker')Out[101]: size tip_pctsmoker No Yes No Yestime dayDinner Fri 2.000000 2.222222 0.139622 0.165347 Sat 2.555556 2.476190 0.158048 0.147906 Sun 2.929825 2.578947 0.160113 0.187250 Thur 2.000000 NaN 0.159744 NaNLunch Fri 3.000000 1.833333 0.187735 0.188937 Thur 2.500000 2.352941 0.160311 0.163863In [102]: #添加分项小计，All值为平均数In [103]: tips.pivot_table(['tip_pct','size'],index=['time','day'],columns='smoker',margins=True)Out[103]: size tip_pctsmoker No Yes All No Yes Alltime dayDinner Fri 2.000000 2.222222 2.166667 0.139622 0.165347 0.158916 Sat 2.555556 2.476190 2.517241 0.158048 0.147906 0.153152 Sun 2.929825 2.578947 2.842105 0.160113 0.187250 0.166897 Thur 2.000000 NaN 2.000000 0.159744 NaN 0.159744Lunch Fri 3.000000 1.833333 2.000000 0.187735 0.188937 0.188765 Thur 2.500000 2.352941 2.459016 0.160311 0.163863 0.161301All 2.668874 2.408602 2.569672 0.159328 0.163196 0.160803In [102]: #添加分项小计，All值为平均数In [103]: tips.pivot_table(['tip_pct','size'],index=['time','day'],columns='smoker',margins=True)Out[103]: size tip_pctsmoker No Yes All No Yes Alltime dayDinner Fri 2.000000 2.222222 2.166667 0.139622 0.165347 0.158916 Sat 2.555556 2.476190 2.517241 0.158048 0.147906 0.153152 Sun 2.929825 2.578947 2.842105 0.160113 0.187250 0.166897 Thur 2.000000 NaN 2.000000 0.159744 NaN 0.159744Lunch Fri 3.000000 1.833333 2.000000 0.187735 0.188937 0.188765 Thur 2.500000 2.352941 2.459016 0.160311 0.163863 0.161301All 2.668874 2.408602 2.569672 0.159328 0.163196 0.160803In [102]: #添加分项小计，All值为平均数In [103]: tips.pivot_table(['tip_pct','size'],index=['time','day'],columns='smoker',margins=True)Out[103]: size tip_pctsmoker No Yes All No Yes Alltime dayDinner Fri 2.000000 2.222222 2.166667 0.139622 0.165347 0.158916 Sat 2.555556 2.476190 2.517241 0.158048 0.147906 0.153152 Sun 2.929825 2.578947 2.842105 0.160113 0.187250 0.166897 Thur 2.000000 NaN 2.000000 0.159744 NaN 0.159744Lunch Fri 3.000000 1.833333 2.000000 0.187735 0.188937 0.188765 Thur 2.500000 2.352941 2.459016 0.160311 0.163863 0.161301All 2.668874 2.408602 2.569672 0.159328 0.163196 0.160803 交叉表交叉表(cross-tabulation简称crosstab)是一种用于计算分组频率的特殊透视表。crosstab前两个参数可以是数组、Series或数组列表:1234567891011In [108]: pd.crosstab([tips.time,tips.day],tips.smoker,margins=True)Out[108]:smoker No Yes Alltime dayDinner Fri 3 9 12 Sat 45 42 87 Sun 57 19 76 Thur 1 0 1Lunch Fri 1 6 7 Thur 44 17 61All 151 93 244 1.样本分位数的计算方式为loc= 1+(n-1)p;n是数据个数，p是分位点。loc介于1到n之间。把数据从小到大排列，找到loc两边的值L和R，值为(R-L) (loc-floor(loc))+L，其中floor是向下取整 ↩2.长度相等指的是区间大小相等，大小相等指的是数据点数量相等 ↩]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>聚合和分组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[绘图和可视化]]></title>
    <url>%2F2018%2F03%2F23%2F%E7%BB%98%E5%9B%BE%E5%92%8C%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[matplotlib API入门使用matplotlib时以--pylab模式打开1ipython --pylab matplotlib API的函数都位于matplotlib.pyplot模块之下，通常通过以下语句引用:1import matplotlib.pyplot as plt Figure和Subplotmatplotlib的图像都位于Figure对象中，使用plt.figure创建一个新的Figure；plt.figure的figsize选项用于确保当图片保存到磁盘时具有一定的大小和纵横比；通过plt.gcf()等到当前Figure的引用；不能再空Figure上绘图，必须通过add_subplot创建一个或多个subplot，返回的对象是AxesSubplot对象：12345678In [7]: fig = plt.figure()In [8]: ax1 = fig.add_subplot(2,2,1) #在figure实例上调用add_subplot创建一个2x2的图像，且当前选中的事第一个(编号从1 ...: 开始)In [9]: ax2 = fig.add_subplot(2,2,2)In [10]: ax3 = fig.add_subplot(2,2,4) 带有三个subplot的Figure如果这时发出一条绘图命令，matplotlib会在最后一个用过的subplot(没有则创建一个)上进行绘制,k--是一个线型选项，告诉matplotlib绘制黑色虚线图: 1234In [16]: plt.plot(randn(50).cumsum(),'k--')Out[16]: [&lt;matplotlib.lines.Line2D at 0x26fc86694a8&gt;]In [17]: plt.savefig('Figure_2.png') 绘制一次后的图像对于add_subplot返回AxesSubplot直接调用它们的实例方法就可以在对应的实例上画图了： 123456In [14]: _ = ax1.hist(randn(100),bins=20,color='k',alpha=0.3)In [15]: ax2.scatter(np.arange(30),np.arange(30)+3*randn(30))Out[15]: &lt;matplotlib.collections.PathCollection at 0x2213001c2e8&gt;In [16]: plt.savefig('Figure_3.png') 继续绘制两次之后的图像 plt.subplots创建一个新的Figure，返回一个含有已创建的subplot对象的NumPy数组，可以通过索引获取对应的AxesSubplot对象进行绘图: pyplot.subplots的选项 参数 说明 nrows subplot的行数 ncols subplot的列数 sharex 所有subplot应该使用相同的X轴刻度(调节xlim将会影响所有subplot) sharey 所有subplot应该使用相同的Y轴刻度(调节ylim将会影响所有subplot) subplot_kw 用于创建个subplot的关键字字典 **fig_kw 创建figure的其他关键字如plt.subplots(2,2,figsize=(8,6)) 123456789101112131415161718In [17]: fig,axes = plt.subplots(2,3)In [18]: axesOut[18]:array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000002213099BDD8&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000002213088D940&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000022136CD45F8&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000022136CE7358&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000022136B9E320&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000022136BBB198&gt;]], dtype=object)In [19]: figOut[19]: &lt;matplotlib.figure.Figure at 0x22130a437b8&gt;In [20]: axes[0,1].scatter(np.arange(30),np.arange(30)+3*randn(30))Out[20]: &lt;matplotlib.collections.PathCollection at 0x22136ead278&gt;In [21]: fig.savefig('Figure_4.png') 通过plt.subplots创建的Figure和AxesSubplot数组 调整subplot周围的间距matplotlib会在subplot外围留下一定的边距，并在subplot之间留下一定的间距。间距和图像的高宽有关，只要图像大小调整则间距也会自动调整利用的Figure的subplots_adjust方法可以修改间距，同时它也是个顶级函数；wspace和hspace用于控制宽度和高度的百分比，可以用作subplot之间的间距。matplotlib不会检查标签是否重叠，所以只能自己设定刻度的位置和刻度标签:123In [23]: plt.subplots_adjust(wspace=0,hspace=0)In [24]: fig.savefig('Figure_5.png') 调整间距之后的图像 颜色、标记和线型matplotlib的plot函数接受一组X和Y的坐标，还可以接受一个表示color颜色和linestyle线型的字符串缩写；常用的颜色都有一个缩写词(color=&#39;g&#39;)，如果需要使用其他颜色可以指定其RGB值(‘#CECECE’)；线形图可以加上一些标记marker来强调实际的数据点；标记和颜色都可以放在格式字符串中，但标记类型和线型必须放在颜色后面：1234567891011In [29]: fig = plt.figure()In [30]: axe1 = fig.add_subplot()In [31]: plt.plot(data,'ko--')Out[31]: [&lt;matplotlib.lines.Line2D at 0x22137639198&gt;]In [32]: plt.plot(data,color='k',linestyle='dashed',marker='o')Out[32]: [&lt;matplotlib.lines.Line2D at 0x2213a7bd588&gt;]In [33]: plt.savefig('Figure_6.png') 带有标记的线型图实例非实际数据点默认是按线性方式插值的，可以通过drawstyle选项修改: 12345678In [34]: plt.plot(data,'k--',label='Default')Out[34]: [&lt;matplotlib.lines.Line2D at 0x22134d35198&gt;]In [35]: plt.plot(data,'k--',label='step-post',drawstyle='steps-post')Out[35]: [&lt;matplotlib.lines.Line2D at 0x22134d35b70&gt;]In [37]: plt.legend(loc='best')Out[37]: &lt;matplotlib.legend.Legend at 0x22134b3a240&gt; 使用不同的drawstyle选项的线型图实例 刻度、标签和图例对于大多数图标的装饰项，有两种实现方式，一是使用过程型的pyplot接口，而是使用面向对象的原生matplotlib API。pyplot接口是为了交互式使用，它含有xlim、xticks和xticklabels等方法。分别控制图标的范围、刻度位置、刻度标签等。使用方式有两种： 调用时不带参数，则返回当前的配置值。(plt.xlim()返回当前的X轴绘图范围) 调用时带参数，则是则会参数值。(plt.xlim([0,10])将X轴的范围设置为0到10)所有方法都是对当前或最近创建的AxesSubplot起作用的，它们各自对应subplot对象的两个方法，以xlim为例对应ax.get_xlim和ax.set_xlim 设置标题、轴标签、刻度以及刻度标签要修改X轴的刻度，使用set_xticks和set_xticklabels方法。set_xticks告诉matplotlib要将刻度放在数据范围中的哪些位置，默认情况下这些位置也就是刻度标签。set_xticklabels将任何其他值用作标签；set_xlabel为X轴设置一个名称;set_title设置一个标题：12345678910111213141516171819202122In [39]: fig = plt.figure()In [40]: ax = fig.add_subplot(1,1,1)In [41]: ax.plot(randn(1000).cumsum())Out[41]: [&lt;matplotlib.lines.Line2D at 0x2213dfb8e48&gt;]In [42]: fig.savefig('Figure_8.png')In [43]: ticks = ax.set_xticks([0,250,500,700,1000])In [44]: fig.savefig('Figure_9.png')In [45]: labels = ax.set_xticklabels(['one','two','three','four','five'], rotation=30, fontsize='small')In [46]: ax.set_title('FIRST')Out[46]: &lt;matplotlib.text.Text at 0x2213f03bb70&gt;In [47]: ax.set_xlabel('STAGES')Out[47]: &lt;matplotlib.text.Text at 0x2213ddaf320&gt;In [48]: fig.savefig('Figure_10.png') 用于显示xticks的线型图 添加图例图例(legend)是一种标识图标元素的重要工具，通过在天剑subplot的时候传入label参数，然后调用ax.legend(loc=&#39;best&#39;)；其中legend的loc参数告诉matplotlib要将图例放在哪儿。要从图例中去除一个或多个元素，不传入label或传入label=&#39;_nolegend_&#39;: 1234567891011121314151617In [51]: fig = plt.figure()In [52]: ax = fig.add_subplot(1,1,1)In [53]: ax.plot(randn(1000).cumsum(),'k',label='one')Out[53]: [&lt;matplotlib.lines.Line2D at 0x22136e7f5c0&gt;]In [54]: ax.plot(randn(1000).cumsum(),'k--',label='two')Out[54]: [&lt;matplotlib.lines.Line2D at 0x221404f6be0&gt;]In [55]: ax.plot(randn(1000).cumsum(),'k.',label='three')Out[55]: [&lt;matplotlib.lines.Line2D at 0x2213b9aba58&gt;]In [56]: ax.legend(loc='best')Out[56]: &lt;matplotlib.legend.Legend at 0x2213dffc208&gt;In [57]: fig.savefig('Figure_11.png') 带有三条线及图例的简单线型图 注解以及在Subplot上绘图注解注解可以通过text、arrow和annotate等函数添加。text可以将文本绘制在图标的指定坐标(x,y)，还可以加上一些自定义格式ax.text(x,y,&#39;Hello world!&#39;, family=&#39;monospace&#39;, fontsize=10)，注解中可以既含有文本也哈有箭头：1234567891011121314151617181920212223242526272829303132In [67]: fig = plt.figure()In [68]: ax = fig.add_subplot(1,1,1)In [69]: data = pd.read_csv('D:\Python\ipython\spx.csv',index_col=0, parse_dates=True)In [70]: spx = data['SPX']In [71]: spx.plot(ax=ax, style='k-')Out[71]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x2213f993c50&gt;In [72]: crisis_data = [ ...: (datetime(2007,10,11),'Peak of bull market'), ...: (datetime(2008,3,12),'Bear Stearbs Fails'), ...: (datetime(2008,9,15),'Lehman Bankruptcy') ...: ] ...:In [73]: for date, label in crisis_data: ...: ax.annotate(label, xy=(date,spx.asof(date)+50), ...: xytext=(date, spx.asof(date)+200), ...: arrowprops=dict(facecolor='black'), ...: horizontalalignment='left', verticalalignment='top') ...:In [74]: # 放大到2007-2010In [76]: ax.set_xlim(['1/1/2007','1/1/2011'])Out[76]: (732677.0, 734138.0)In [76]: ax.set_xlim(['1/1/2007','1/1/2011'])Out[76]: (732677.0, 734138.0) 2008-2009年金融危机期间的重要日期1 绘图matplotlib有一些表示常见图形的对象被称为快(patch)，完整的集合位于matplotlib.patches中，有些可以在matplotlib.pyplot中找到(如Rectangle和Circle)。要在图表中添加一个图形，需要先创建一个块对象shp，然后通过ax.add_patch(shp)将其添加到subplot中:1234567891011121314151617181920In [81]: fig = plt.figure()In [82]: ax = fig.add_subplot(1,1,1)In [83]: rect = plt.Rectangle((0.2,0.75),0.4,0.15,color='k',alpha=0.3)In [84]: circ = plt.Circle((0.7,0.2),0.15,color='b',alpha=0.3)In [85]: pgon = plt.Polygon([[0.15,0.15],[0.35,0.4],[0.2,0.6]],color='g',alpha=0.5)In [86]: ax.add_patch(rect)Out[86]: &lt;matplotlib.patches.Rectangle at 0x22142e4a908&gt;In [87]: ax.add_patch(circ)Out[87]: &lt;matplotlib.patches.Circle at 0x22140caa6d8&gt;In [88]: ax.add_patch(pgon)Out[88]: &lt;matplotlib.patches.Polygon at 0x2214117b940&gt;In [89]: fig.savefig('Figure_13.png') 由三块图形组成的图 将图表保存到文件利用plt.savefig可以将当前图表保存到文件，其相当于Figure对象的实例方法savefig。文件类型是通过文件扩展名推断出来的。可以通过dpi参数控制分辨率，通过bbox_inches剪除当前图表周围的空白部分plt.savefig(&#39;filepath.png&#39;, dpi=400,bbox_inches=&#39;tight&#39;); savepig的选项 参数 说明 fname 含有文件路径的字符串或Python的文件型对象。图像格式由文件扩展名推断得出 dpi 图像分辨率(每英寸点数),默认为100 facecolor、edgecolor 图像的背景色，默认为”w”(白色) format 显式设置文件格式(png/pdf/svg/ps….) bbox_inches 图表需要保存的部分。如果设置为”tight”则尝试剪除图表周围的空白部分 matplotlib配置matplotlib自带一些配色方案，几乎所有默认行为都能通过一组全局参数进行自定义，它们可以管理图像大小、subplot边距、配色方案、字体大小、网格类型等。操作matplotlib配置系统可以使用rc方法，rc第一个参数是希望自定义的对象，其后可以跟上一系列的关键字参数，可以将这些选项写成一个字典:123456In [100]: font_options=&#123;'family':'monospace', ...: 'weight':'bold', ...: 'size':10&#125; ...:In [101]: plt.rc('font', **font_options) pandas中的绘图函数matplotlib是一种比较低级的工具，要组装一张图白哦，得使用它的各种基础组建才行：数据展示(即图标类型：线型图、柱状图、盒型图、散布图、等值线图等)、图例、标题、刻度标签以及其他注解型信息。在pandas中因为已经有行标签、列标签以及分组信息，所以能够看利用DataFrame对象数据组织特点来创建标准图表的高级方法 Series.plot方法的餐素 参数 说明 label 用于图例的标签 ax 要在其上进行绘制的matplotlib subplot对象。如果没有设置，则使用当前matplotlib subplot style 将要传给matplotlib的风格字符串(如’ko–’) alpha 图表的填充不透明度(0到1之间) kind 可以是’line’、’bar’、’barh’、’kde’ logy 在Y轴上使用对数标签 use_index 将对象的索引用作刻度标签 rot 旋转刻度标签(0到360) xticks 用作X轴刻度的值 yticks 用作Y轴刻度的值 xlim X轴的界限(例如[0,10]) ylim Y轴的界限 grid 显示轴网格线(默认打开) 专用于DataFrame的plot参数 参数 说明 subplots 将各个DataFrame列绘制到单独的subplot中 sharex 如果subplots=True，则共用同一个X轴，包括刻度和界限 sharey 如果subplots=False，则共用同一个Y轴 figsize 表示图像大小的元组 title 表示图像标题的字符串 legend 添加一个subplot图例(默认为True) sort_columns 以字母顺序绘制各列，默认使用当前列顺序 线型图Series和DataFrame都有一个生成各类图表的plot方法，默认情况下它们生成的是线型图。Series对象的索引会被传给matplotlib，并用以绘制X轴；通过use_index=False禁用该功能；X轴的刻度和界限可以通过xticks和xlim选项进行调节;Y轴用yticks和ylim：1234In [10]: s = Series(np.random.randn(10).cumsum(),index=np.arange(0,100,10))In [11]: s.plot()Out[11]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x10a781588&gt; 简单的Series图表 pandas的大部分绘图方法有一个可选的ax参数，它可以是一个matplotlib的subplot对象。这使得在网格布局中更灵活地处理subplot的位置，DataFrame的plot方法会在一个subplot中为各列绘制一条线，并自动创建图例:1234567In [16]: df = DataFrame(np.random.randn(10,4).cumsum(0), ...: columns=['A','B','C','D'], ...: index=np.arange(0,100,10)) ...:In [17]: df.plot()Out[17]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x10b8704a8&gt; 简单的DataFrame图表 柱状图在生成线型图的代码中加上kind=&#39;bar&#39;(垂直柱状图)或kind=&#39;barh&#39;(水平柱状图)即可生成柱状图。Series和DataFrame的索引会被用作X(bar)或Y(barh)刻度: 1234567891011In [26]: fig, axes = plt.subplots(2,1)In [27]: data = Series(np.random.rand(16),index=list('abcdefghijklmnop'))In [28]: data.plot(kind='bar', ax=axes[0],color='k', alpha=0.7)Out[28]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x1186e90b8&gt;In [29]: data.plot(kind='barh', ax=axes[1],color='k', alpha=0.7)Out[29]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x118bd52e8&gt;In [30]: fig.savefig('Figure_16.png') Series柱状图 对于DataFrame，柱状图会将每一行的值分为一组，使用stacked=True会使每行的值堆积在一起:123456789101112131415161718192021222324In [34]: df = DataFrame(np.random.rand(6,4), ...: index=['r1','r2','r3','r4','r5','r6'], ...: columns=pd.Index(['A','B','C','D'],name='Genus')) ...:In [35]: dfOut[35]:Genus A B C Dr1 0.820633 0.228560 0.550244 0.236735r2 0.968056 0.268256 0.539757 0.453413r3 0.827034 0.905531 0.722537 0.368674r4 0.433393 0.154539 0.223513 0.340216r5 0.037282 0.609635 0.609266 0.172542r6 0.359212 0.399398 0.044828 0.712773In [36]: fig, axes = plt.subplots(2,1)In [37]: df.plot(kind='bar',ax=axes[0])Out[37]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x11eecb198&gt;In [38]: df.plot(kind='barh',ax=axes[1],stacked=True, alpha=0.5)Out[38]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x11e691048&gt;In [39]: fig.savefig('Figure_17.png') DataFrame柱状图 直方图和密度图直方图是一种可以对值频率进行离散化显示的柱状图。数据点被拆分到离散的、间隔均匀的面元中，绘制的是各面元中数据点的数量,通过hist方法绘制“小费占消费总额的百分比”(数据集):123456In [75]: tips = pd.read_csv('/Users/dengxiaojun/Documents/pydata-book-2nd-edition/examples/tips.csv')In [76]: tips['tip_pct'] = tips['tip']/tips['total_bill']In [77]: tips['tip_pct'].hist(bins=50)Out[77]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x10ce1c240&gt; 小费百分比的直方图 与此相关的是密度图，它通过计算“可能会产生观测数据的连续概率分布的估计”而产生。一般的过程是将该分布近似为一组核(即诸如正态(高斯)分布之类的较为简单的分布),t通过调用plot的kind=&#39;kde&#39;生成:12In [91]: tips['tip_pct'].plot(kind='kde')Out[91]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x120178ba8&gt; 小费百分比密度图 这两种图表常常被画在一起。直方图以规格化形式给出(以便给出面元化密度)，然后再在其上绘制核密度估计:1234567891011In [98]: comp1 = np.random.normal(0,1,size=200)In [99]: comp2 = np.random.normal(10,2,size=200)In [100]: values = Series(np.concatenate([comp1,comp2]))In [101]: values.hist(bins=100, alpha=0.3, color='k', density=True)Out[101]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x119e863c8&gt;In [102]: values.plot(kind='kde', style='k--')Out[102]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x119e863c8&gt; 带有密度估计的规格化直方图 散布图散布图是观察两个一维数据序列之间的关系的有效手段。matplotlib的scatter方法是绘制散布图的主要方法，(加载数据集选择其中几列，计算对数差:1234567891011121314151617181920In [114]: macro = pd.read_csv('/Users/dengxiaojun/Documents/pydata-book-2nd-edition/examples/macrodata.csv')In [115]: data = macro[['cpi','m1','tbilrate','unemp']]In [116]: trans_data = np.log(data).diff().dropna()In [117]: trans_data[-5:]Out[117]: cpi m1 tbilrate unemp198 -0.007904 0.045361 -0.396881 0.105361199 -0.021979 0.066753 -2.277267 0.139762200 0.002340 0.010286 0.606136 0.160343201 0.008419 0.037461 -0.200671 0.127339202 0.008894 0.012202 -0.405465 0.042560In [118]: plt.scatter(trans_data['m1'],trans_data['unemp'])Out[118]: &lt;matplotlib.collections.PathCollection at 0x11b24c780&gt;In [119]: plt.title('Changes in log %s vs .log %s' % ('m1', 'unemp'))Out[119]: Text(0.5,1,'Changes in log m1 vs .log unemp') 一张简单的散布图 在探索式数据分析工作中，同时观察一组变量的散布图很有意义，这也被称为散布矩阵。pandas.plotting提供了一个能从DataFrame创建散布图矩阵的scatter_matrix函数，它还支持在对角线上放置各变量的直方图或密度图:12345678910111213141516171819In [121]: pd.plotting.scatter_matrix(trans_data,diagonal='kde',color='k',alpha=0.4)Out[121]:array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x11b3591d0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x11b499dd8&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x11b857f98&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x11b3e7eb8&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x11b383390&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x11b383208&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x11b873da0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x11d0574e0&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x119b73f98&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x119b75f28&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x119afddd8&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x119ae6128&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x119af3128&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1261c6860&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x11ac44b70&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x126938ac8&gt;]], dtype=object) 散布图矩阵 1.数据来源 ↩]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据规整化(二)]]></title>
    <url>%2F2018%2F03%2F22%2F%E6%95%B0%E6%8D%AE%E8%A7%84%E6%95%B4%E5%8C%96-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[重塑和轴向旋转重塑层次化索引层次化索引为DataFrame数据的重排提供了具有良好一致性的方式。主要功能包括： stack:将数据的列”旋转”为行 unstack:将数据的行”旋转”为列 stack对于一个简单的DataFrame使用stack方法会得到一个Series，stack在运算的时候默认会滤除缺失值，指定dropna=False可以保留： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172In [112]: data = DataFrame(np.arange(6).reshape((2,3)), ...: index=pd.Index(['row1','row2'],name='row'), ...: columns=pd.Index(['col1','col2','col3'],name='col')) ...:In [113]: dataOut[113]:col col1 col2 col3rowrow1 0 1 2row2 3 4 5In [114]: resulst = data.stack()In [115]: resulstOut[115]:row colrow1 col1 0 col2 1 col3 2row2 col1 3 col2 4 col3 5dtype: int32In [124]: s1 = Series(np.arange(4),index=list('abcd'))In [125]: s2 = Series([4,5,6],index=list('cde'))In [126]: data2 = pd.concat([s1,s2],keys=['one','two'])In [127]: data2Out[127]:one a 0 b 1 c 2 d 3two c 4 d 5 e 6dtype: int64In [129]: data2.unstack()Out[129]: a b c d eone 0.0 1.0 2.0 3.0 NaNtwo NaN NaN 4.0 5.0 6.0In [130]: data2.unstack().stack()Out[130]:one a 0.0 b 1.0 c 2.0 d 3.0two c 4.0 d 5.0 e 6.0dtype: float64In [132]: data2.unstack().stack(dropna=False)Out[132]:one a 0.0 b 1.0 c 2.0 d 3.0 e NaNtwo a NaN b NaN c 4.0 d 5.0 e 6.0dtype: float64 unstackunstack可以将stack方法得到的Series重排为一个DataFrame；默认情况下，unstack操作的是最内层。传入分层级别的编号或名称即可对其他级别进行unstack操作，如果不是所有级别值都能在各分组中找到的话会引入缺失值；在对DataFrame进行unstack操作时，作为旋转轴的级别将会成为结果中的最低级别: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182In [140]: resulstOut[140]:row colrow1 col1 0 col2 1 col3 2row2 col1 3 col2 4 col3 5dtype: int32In [141]: resulst.unstack()Out[141]:col col1 col2 col3rowrow1 0 1 2row2 3 4 5In [142]: resulst.unstack(0)Out[142]:row row1 row2colcol1 0 3col2 1 4col3 2 5In [143]: resulst.unstack('row')Out[143]:row row1 row2colcol1 0 3col2 1 4col3 2 5In [144]: data2Out[144]:one a 0 b 1 c 2 d 3two c 4 d 5 e 6dtype: int64In [145]: data2.unstack()Out[145]: a b c d eone 0.0 1.0 2.0 3.0 NaNtwo NaN NaN 4.0 5.0 6.0In [151]: df = DataFrame(&#123;'left':resulst,'right':resulst+5&#125;, ...: columns=pd.Index(['left','right'], name='side')) ...:In [152]: dfOut[152]:side left rightrow colrow1 col1 0 5 col2 1 6 col3 2 7row2 col1 3 8 col2 4 9 col3 5 10In [153]: df.unstack('col')Out[153]:side left rightcol col1 col2 col3 col1 col2 col3rowrow1 0 1 2 5 6 7row2 3 4 5 8 9 10In [154]: df.unstack('col').stack('side')Out[154]:col col1 col2 col3row siderow1 left 0 1 2 right 5 6 7row2 left 3 4 5 right 8 9 10 将“长格式”旋转为“宽格式”先预处理实验数据，首先加载数据，使用PeriodIndex生成新的索引，使用Index选取索引然后使用reindex方法根据新的列索引生成数据，然后修改数据的行索引为时间索引，最后生成需要的数据:123456789In [217]: periods = pd.PeriodIndex(year=data.year, quarter=data.quarter,name='date')In [218]: colums = pd.Index(['realgdp','infl','unemp'],name='item')In [219]: data = data.reindex(columns=colums)In [220]: data.index = periods.to_timestamp('D','end')In [221]: ldata = data.stack().reset_index().rename(columns=&#123;0:'value'&#125;) pivot第一个参数节后行索引的列名，第二参数是列索引的列名，最后一个参数值用于填充DataFrame的数据列的列名，如果忽略最后一个参数得到的DataFrame就会带有层次化的列:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364In [233]: ldata[:10]Out[233]: date item value0 1959-03-31 realgdp 2710.3491 1959-03-31 infl 0.0002 1959-03-31 unemp 5.8003 1959-06-30 realgdp 2778.8014 1959-06-30 infl 2.3405 1959-06-30 unemp 5.1006 1959-09-30 realgdp 2775.4887 1959-09-30 infl 2.7408 1959-09-30 unemp 5.3009 1959-12-31 realgdp 2785.204In [234]: pivoted = ldata.pivot('date','item','value')In [235]: pivoted.head()Out[235]:item infl realgdp unempdate1959-03-31 0.00 2710.349 5.81959-06-30 2.34 2778.801 5.11959-09-30 2.74 2775.488 5.31959-12-31 0.27 2785.204 5.61960-03-31 2.31 2847.699 5.2In [236]: ldata['value2'] = np.random.randn(len(ldata))In [237]: ldata[:10]Out[237]: date item value value20 1959-03-31 realgdp 2710.349 0.9445991 1959-03-31 infl 0.000 0.2441792 1959-03-31 unemp 5.800 0.0558303 1959-06-30 realgdp 2778.801 1.1825204 1959-06-30 infl 2.340 0.2663595 1959-06-30 unemp 5.100 -0.8817426 1959-09-30 realgdp 2775.488 0.0070217 1959-09-30 infl 2.740 -1.1717928 1959-09-30 unemp 5.300 0.0073569 1959-12-31 realgdp 2785.204 0.631422In [238]: pivoted = ldata.pivot('date','item')In [239]: pivoted[:5]Out[239]: value value2item infl realgdp unemp infl realgdp unempdate1959-03-31 0.00 2710.349 5.8 0.244179 0.944599 0.0558301959-06-30 2.34 2778.801 5.1 0.266359 1.182520 -0.8817421959-09-30 2.74 2775.488 5.3 -1.171792 0.007021 0.0073561959-12-31 0.27 2785.204 5.6 0.136254 0.631422 -0.8505161960-03-31 2.31 2847.699 5.2 -2.338798 0.897056 0.296124In [240]: pivoted['value2'][:5]Out[240]:item infl realgdp unempdate1959-03-31 0.244179 0.944599 0.0558301959-06-30 0.266359 1.182520 -0.8817421959-09-30 -1.171792 0.007021 0.0073561959-12-31 0.136254 0.631422 -0.8505161960-03-31 -2.338798 0.897056 0.296124 相当于使用set_index创建层次化索引，再用unstack重塑:12345678910In [243]: ldata.set_index(['date','item']).unstack('item')[:5]Out[243]: value value2item infl realgdp unemp infl realgdp unempdate1959-03-31 0.00 2710.349 5.8 0.244179 0.944599 0.0558301959-06-30 2.34 2778.801 5.1 0.266359 1.182520 -0.8817421959-09-30 2.74 2775.488 5.3 -1.171792 0.007021 0.0073561959-12-31 0.27 2785.204 5.6 0.136254 0.631422 -0.8505161960-03-31 2.31 2847.699 5.2 -2.338798 0.897056 0.296124 数据转换前面描述的均为数据重排，而另一类重要操作则是过滤、清理以及其他转换工作。 移除重复数据DataFrame的duplicated方法返回一个布尔型Series，表示各行是否有重复行；drop_duplicates方法用于返回一个移除了重复行的DataFrame。这两个方法默认会判断全部列，可以传入一个列表指定部分列作为重复项判断标准，即根据某些列过滤重复项；两个方法默认保留第一个出现的组合，传入keep=&#39;last&#39;1则会保留最后一个：1234567891011121314151617181920212223242526272829303132333435363738394041In [18]: data = DataFrame(&#123;'k1':['one']*3+['two']*2, ...: 'k2':[1,1,2,3,3,]&#125;) ...:In [19]: dataOut[19]: k1 k20 one 11 one 12 one 23 two 34 two 3In [20]: data.duplicated()Out[20]:0 False1 True2 False3 False4 Truedtype: boolIn [21]: data.drop_duplicates()Out[21]: k1 k20 one 12 one 23 two 3In [22]: data.drop_duplicates(['k1'])Out[22]: k1 k20 one 13 two 3In [23]: data.drop_duplicates(['k2','k1'],keep='last')Out[23]: k1 k21 one 12 one 24 two 3 利用函数或映射进行数据转换Series的map方法可以接受一个函数或含有映射关系的字典型对象，使用map是一种实现元素级转换以及其他数据清理工作的便捷方式。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354In [48]: data = DataFrame(&#123;'food':['bacon','pulled pork','bacon','Pastrami','corned beef', ...: 'Bacon','pastrami','honey ham','nava lox'], ...: 'ounces':[4,3,12,6,7.5,8,3,5,6]&#125;) ...:In [49]: meat_to_animal=&#123; ...: 'bacon':'pig', ...: 'pulled pork':'pig', ...: 'pastrami':'cow', ...: 'corned beef':'cow', ...: 'honey ham':'pig', ...: 'nava lox':'salmon' ...: &#125;In [50]: dataOut[50]: food ounces0 bacon 4.01 pulled pork 3.02 bacon 12.03 Pastrami 6.04 corned beef 7.55 Bacon 8.06 pastrami 3.07 honey ham 5.08 nava lox 6.0In [51]: data['animal']=data['food'].map(str.lower).map(meat_to_animal)In [52]: dataOut[52]: food ounces animal0 bacon 4.0 pig1 pulled pork 3.0 pig2 bacon 12.0 pig3 Pastrami 6.0 cow4 corned beef 7.5 cow5 Bacon 8.0 pig6 pastrami 3.0 cow7 honey ham 5.0 pig8 nava lox 6.0 salmonIn [53]: data['food'].map(lambda x: meat_to_animal[x.lower()])Out[53]:0 pig1 pig2 pig3 cow4 cow5 pig6 cow7 pig8 salmonName: food, dtype: object 替换值replace方法提供了一种实现替换功能的更简单、更灵活的方式；replace支持一次性替换多个值，只需要传入一个由待替换值组成的列表以及一个替换值；如果希望对不同的值进行不同的替换，则传入一个由替换关系组成的列表即可，也可以是字典：123456789101112131415161718192021222324252627282930313233343536373839404142434445In [54]: data = Series([1,0,2,0,3,2,0])In [55]: data.replace(0,-1)Out[55]:0 11 -12 23 -14 35 26 -1dtype: int64In [56]: data.replace([0,2],-1)Out[56]:0 11 -12 -13 -14 35 -16 -1dtype: int64In [57]: data.replace([0,2],[-1,9])Out[57]:0 11 -12 93 -14 35 96 -1dtype: int64In [58]: data.replace(&#123;0:-1,1:9&#125;)Out[58]:0 91 -12 23 -14 35 26 -1dtype: int64 重命名轴索引和Series相同，轴标签也可以通过函数或映射进行转换，从而得到一个新对象。轴还可以被就地修改而无需新建一个数据结构，这些都可以使用map方法实现：1234567891011121314151617181920In [63]: data = DataFrame(np.arange(9).reshape((3,3)), ...: index = ['row1','row2','row4'], ...: columns=['one','two','three']) ...:In [64]: dataOut[64]: one two threerow1 0 1 2row2 3 4 5row4 6 7 8In [65]: data.index = data.index.map(str.upper)In [66]: dataOut[66]: one two threeROW1 0 1 2ROW2 3 4 5ROW4 6 7 8 如果要创建数据集的转换版(而不是修改原始数据)，可以使用rename方法；rename方法可以结合字典型对象实现对部分轴标签的更新；如果希望就地修改可以传入implace=True：12345678910111213141516171819202122In [72]: data.rename(index=str.title, columns=str.upper)Out[72]: ONE TWO THREERow1 0 1 2Row2 3 4 5Row4 6 7 8In [73]: data.rename(index=&#123;'ROW1':'ROW'&#125;, columns=&#123;'three':'col3'&#125;)Out[73]: one two col3ROW 0 1 2ROW2 3 4 5ROW4 6 7 8In [74]: data.rename(index=&#123;'ROW1':'ROW'&#125;, columns=&#123;'three':'col3'&#125;,inplace=True)In [75]: dataOut[75]: one two col3ROW 0 1 2ROW2 3 4 5ROW4 6 7 8 离散化和面元划分为了便于分析，连续的数据常常被离散化或拆分为“面元”。cut函数可以实现将数据划分为面元；其返回的是一个特殊的Categorical对象，相当于一组表示面元名称的字符串。其中categories表示不同分类的名称,codes属性表示各个数据所属分组的标号。和“区间”的数学符号一样，圆括号表示开端，而方括号则被考试闭端(包括)，哪边是闭端可以使用right=True来确定。可以通过labels参数设置自己的面元名称。如果向cut传入的是面元的数量而不是确切的面元边界，则会根据最大值和最小值来计算等长面元：12345678910111213141516171819202122232425262728293031323334353637383940414243444546In [96]: ages = [20,22,25,27,21,23,47,54,35,37,32]In [97]: bins = [18,25,35,60,100]In [98]: cats = pd.cut(ages,bins)In [99]: catsOut[99]:[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (35, 60], (35, 60], (25, 35], (35, 60], (25, 35]]Length: 11Categories (4, interval[int64]): [(18, 25] &lt; (25, 35] &lt; (35, 60] &lt; (60, 100]]In [100]: cats.categoriesOut[100]:IntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]] closed='right', dtype='interval[int64]')In [101]: cats.codesOut[101]: array([0, 0, 0, 1, 0, 0, 2, 2, 1, 2, 1], dtype=int8)In [102]: cats = pd.cut(ages,bins,right=False)In [103]: catsOut[103]:[[18, 25), [18, 25), [25, 35), [25, 35), [18, 25), ..., [35, 60), [35, 60), [35, 60), [35, 60), [25, 35)]Length: 11Categories (4, interval[int64]): [[18, 25) &lt; [25, 35) &lt; [35, 60) &lt; [60, 100)]In [104]: group_names=['Youth','YoungAdult','MiddleAged','Senior']In [105]: cats = pd.cut(ages,bins,labels=group_names,right=False)In [106]: catsOut[106]:[Youth, Youth, YoungAdult, YoungAdult, Youth, ..., MiddleAged, MiddleAged, MiddleAged, MiddleAged, YoungAdult]Length: 11Categories (4, object): [Youth &lt; YoungAdult &lt; MiddleAged &lt; Senior]In [107]: data = np.random.rand(20)In [108]: pd.cut(data,4,precision=2)Out[108]:[(0.75, 0.98], (0.75, 0.98], (0.75, 0.98], (0.52, 0.75], (0.52, 0.75], ..., (0.29, 0.52], (0.061, 0.29], (0.061, 0.29], (0.52, 0.75], (0.52, 0.75]]Length: 20Categories (4, interval[float64]): [(0.061, 0.29] &lt; (0.29, 0.52] &lt; (0.52, 0.75] &lt; (0.75, 0.98]] qcut是一个类似于cut的函数，它可以根据样本分位数对数据进行面元划分，可以得到大小基本相等的面元，和cut相同它可以自定义分位数：1234567891011121314151617181920212223In [109]: data = np.random.rand(1000)In [110]: cats = pd.qcut(data,4) #按四分位数进行切割In [111]: catsOut[111]:[(0.499, 0.749], (0.263, 0.499], (0.263, 0.499], (0.499, 0.749], (0.263, 0.499], ..., (0.263, 0.499], (0.499, 0.749], (-0.000892, 0.263], (0.749, 0.999], (0.263, 0.499]]Length: 1000Categories (4, interval[float64]): [(-0.000892, 0.263] &lt; (0.263, 0.499] &lt; (0.499, 0.749] &lt; (0.749, 0.999]]In [112]: pd.value_counts(cats)Out[112]:(0.749, 0.999] 250(0.499, 0.749] 250(0.263, 0.499] 250(-0.000892, 0.263] 250dtype: int64In [113]: pd.qcut(data,[0,0.1,0.5,0.9,1])Out[113]:[(0.499, 0.909], (0.104, 0.499], (0.104, 0.499], (0.499, 0.909], (0.104, 0.499], ..., (0.104, 0.499], (0.499, 0.909], (0.104, 0.499], (0.499, 0.909], (0.104, 0.499]]Length: 1000Categories (4, interval[float64]): [(-0.000892, 0.104] &lt; (0.104, 0.499] &lt; (0.499, 0.909] &lt; (0.909, 0.999]] 检测和过滤异常值异常值(孤立点或离群值)的过滤或变换运算在很大程度上其实就是数组运算,使用数组运算的方法来进行过滤：1234567891011121314151617181920212223242526272829303132333435363738394041In [123]: np.random.seed(12345)In [124]: data = DataFrame(np.random.randn(1000,4))In [125]: col = data[3]In [126]: col[np.abs(col)&gt;3] #选出绝对值大小超过3的值Out[126]:97 3.927528305 -3.399312400 -3.745356Name: 3, dtype: float64In [127]: data[(np.abs(data)&gt;3).any(1)]#选出超过3或-3的行Out[127]: 0 1 2 35 -0.539741 0.476985 3.248944 -1.02122897 -0.774363 0.552936 0.106061 3.927528102 -0.655054 -0.565230 3.176873 0.959533305 -2.315555 0.457246 -0.025907 -3.399312324 0.050188 1.951312 3.260383 0.963301400 0.146326 0.508391 -0.196713 -3.745356499 -0.293333 -0.242459 -3.056990 1.918403523 -3.428254 -0.296336 -0.439938 -0.867165586 0.275144 1.179227 -3.184377 1.369891808 -0.362528 -3.548824 1.553205 -2.186301900 3.366626 -2.372214 0.851010 1.332846In [128]: data[np.abs(data)&gt;3] = np.sign(data)*3#将值限制在区间-3到3，sign返回的是一个1和-1组成的数组，表示原始值的符号In [129]: data.describe()Out[129]: 0 1 2 3count 1000.000000 1000.000000 1000.000000 1000.000000mean -0.067623 0.068473 0.025153 -0.002081std 0.995485 0.990253 1.003977 0.989736min -3.000000 -3.000000 -3.000000 -3.00000025% -0.774890 -0.591841 -0.641675 -0.64414450% -0.116401 0.101143 0.002073 -0.01361175% 0.616366 0.780282 0.680391 0.654328max 3.000000 2.653656 3.000000 3.000000 排列和随机采样利用numpy.random.permutation函数实现对Series或DataFrame的列的排列工作(即随机重排序)。通过需要排列的轴的长度调用permitation，可产生一个表示新顺序的整数数组；如果不想用替换的方式选取随机自己可以使用permitation，其返回的数组中切下前k个元素；而要通过替换的方式产生样本，最快的方式是通过np.random.randint得到一组随机整数：12345678910111213141516171819202122232425262728293031323334353637383940In [130]: df = DataFrame(np.arange(5*4).reshape(5,4))In [131]: sample = np.random.permutation(5)In [132]: sampleOut[132]: array([1, 0, 2, 3, 4])In [133]: dfOut[133]: 0 1 2 30 0 1 2 31 4 5 6 72 8 9 10 113 12 13 14 154 16 17 18 19In [134]: df.take(sample)Out[134]: 0 1 2 31 4 5 6 70 0 1 2 32 8 9 10 113 12 13 14 154 16 17 18 19In [135]: df.take(np.random.permutation(len(df))[:3])Out[135]: 0 1 2 31 4 5 6 73 12 13 14 154 16 17 18 19In [136]: bag = np.array([5,3,25,-1,2])In [137]: sampler = np.random.randint(0,len(bag),size=10)In [138]: draws = bag.take(sampler)In [139]: drawsOut[139]: array([ 2, 2, 25, 25, 25, 5, -1, 5, 2, 3]) 计算指标/哑变量将分类变量转换为哑变量或指标矩阵是常用于统计建模或机器学习的转换方式。pandas的get_dummies函数可以实现如果DataFrame的某一列中含有k个不同的值来派生出一个k列矩阵或DataFrame(其值全为0或1)；如果需要个指标DataFrame的列加上一个前缀以便和其他数据进行合并可以使用prefix参数:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647In [152]: df = DataFrame(&#123;'key':list('bbacab'), ...: 'data':range(6)&#125;) ...:In [153]: dfOut[153]: data key0 0 b1 1 b2 2 a3 3 c4 4 a5 5 bIn [154]: pd.get_dummies(df['key'])Out[154]: a b c0 0 1 01 0 1 02 1 0 03 0 0 14 1 0 05 0 1 0In [155]: dummies = pd.get_dummies(df['key'],prefix='key')In [156]: dummiesOut[156]: key_a key_b key_c0 0 1 01 0 1 02 1 0 03 0 0 14 1 0 05 0 1 0In [157]: df_with_dummies = df[['data']].join(dummies)In [158]: df_with_dummiesOut[158]: data key_a key_b key_c0 0 0 1 01 1 0 1 02 2 1 0 03 3 0 0 14 4 1 0 05 5 0 1 0 字符串操作字符串对象方法 Python内置的字符串方法 方法 说明 count 返回子串在字符串中的出现次数(非重叠) endswith、startswith 如果字符串以某个后缀结尾(以某个前缀开头)，则返回True join 将字符串用作连接其他字符串序列的分隔符 index 如果在字符串中找到子串，则返回子串第一个字符所在的位置。如果没有找到，则引发ValueError find 如果在字符串中找到子串，则返回第一个发现的子串的第一个字符所在的位置。如果没有找到返回-1 rfind 如果在字符串中找到子串，则返回最后一个发现的子串的第一个字符所在的位置。如果没有找到，则返回-1 replace 用另一个字符串替换指定子串 strip、rstrip、lstrip 去除空白符(包括换行符)。 split 通过指定的分隔符将字符串拆分为一组子串 lower、upper 分别将字母字符转换为小写或大写 ljust、rjust 用空格(或其他字符)填充字符串的空白侧以返回符合最低宽度的字符串 12345678910111213141516171819202122232425262728293031323334In [2]: var = 'a, ,b, c'In [3]: var.split(',')Out[3]: ['a', ' ', 'b', ' c']In [5]: pieces = [x.strip() for x in var.split(',')]In [6]: piecesOut[6]: ['a', '', 'b', 'c']In [7]: first,sencond,third,fourth = piecesIn [8]: first+'::'+sencond+'::'+third+'::'+fourthOut[8]: 'a::::b::c'In [9]: '::'.join(pieces)Out[9]: 'a::::b::c'In [10]: var.index(':')---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-10-d73873441320&gt; in &lt;module&gt;()----&gt; 1 var.index(':')ValueError: substring not foundIn [11]: var.count(',')Out[11]: 3In [12]: var.replace(',','::')Out[12]: 'a:: ::b:: c'In [13]: var.replace(',','')Out[13]: 'a b c' 正则表达式见正则表达式部分 pandas中矢量化的字符串函数 矢量化的字符串方法 方法 说明 cat 实现元素级的字符串连接操作，可指定分隔符 contains 返回表示各字符串是否含有指定模式的布尔型数组 count 模式的出现次数 endswith、startswith 相当于对各个元素执行x.endswith(patten)或x.startswith(pattern) findall 计算各字符串的模式列表 get 获取各元素的第i个字符 join 根据指定的分隔符将Series中各元素的字符串连接起来 len 计算各字符串的长度 lower、upper 转换大小写。相当于对各个元素执行x.lower()或x.upper() match 根据指定的正则表达式对各个元素执行re.match pad 在字符串的左边、右边或左右两边添加空白符 center 相当于pad(side=’both’) repeat 重复值。例如x.str.repeat(3)相当于对各个字符串执行x*3 slice 对Series中的各个字符串进行子串截取 split 根据分隔符或正则表达式对字符串进行拆分 strip、rstrip、lstrip 去除空白符，包括换行符。相当于对各个元素执行x.strip()、x.rstrip()、x.lstrip() 为了解决map方法应用于pandas对象时遇到NA值报错的问题，Series可以通过str属性访问跳过NA的字符串操作方法,可以执行正则表达式:1234567891011121314151617181920212223242526272829In [32]: data = &#123;'Jone':'123@qq.com','bob':'asd@163.com','jim':'jim@gmail.com','tom':np.nan&#125;In [33]: data = Series(data)In [34]: data.isnull()Out[34]:Jone Falsebob Falsejim Falsetom Truedtype: boolIn [35]: data.str.contains('gmail')Out[35]:Jone Falsebob Falsejim Truetom NaNdtype: objectIn [36]: pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]&#123;2,4&#125;)'In [37]: data.str.findall(pattern,flags=re.I)Out[37]:Jone [(123, qq, com)]bob [(asd, 163, com)]jim [(jim, gmail, com)]tom NaNdtype: object 示例处理食品数据集 1.keep可以取‘first’、‘last’、False分别表示保留第一个，保留最后一个，全部删除。详细可以查看文档。 ↩]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据清洗</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据规整化(一)]]></title>
    <url>%2F2018%2F03%2F21%2F%E6%95%B0%E6%8D%AE%E8%A7%84%E6%95%B4%E5%8C%96-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[合并数据集pandas对象中的数据可以通过内置的方式进行合并: pandas.merge可根据一个或多个键讲不通DataFrame中的行连接起来(数据库连接操作)1 pandas.concat可以沿着一条轴将多个对象堆叠到一起 实例方法combine_first可以将重复数据编接在一起，用一个对象中的值填充另一个对象的中的缺失值(先从第一个对象选值，不行就去第二个对象中选值) merge函数的参数 参数 说明 left 参数合并的左侧DataFrame right 参与合并的右侧DataFrame how “inner”、”outer”、”left”、”right”。默认为”inner” on 用于连接的列名。必须存在于左右两个DataFrame对象中。如果未指定，且其他连接键也未指定，则以left和right列名的交集作为连接键 left_on 左侧DataFrame中用作连接键的列 right_on 右侧DataFrame中用作连接键的列 left_index 将左侧的行索引用作其连接键 right_index 将右侧的行索引用作其连接键 sort 根据连接键合并后的数据进行排序，默认为True。处理大数据集时，禁用会获得更好的性能 suffixes 字符串值元组，用于追加到重叠列名的末尾，默认为(‘_x’,’_y’)。(如果左右两个DataFrame中都有data，则结果会出现”data_x”和”data_y”) copy 设置为False，可以在某些特殊情况下避免将数据复制到结果数据结构中。默认总是复制 数据库风格的DataFrame合并数据集的合并(merge)或链接(join)运算是通过一个或多个键将行链接起来。 多对一df1中的数据key列中有多个被标记为a,b的行，而df2中key列的每个值仅对应一行。如果没有指定要用哪个列进行链接，merge就会将重叠列的列名当做键，最好通过on显式指定；如果两个列的列名不同可以分别使用left_on和right_on指定；默认情况下merge做的是inner链接，即结果是键的交集，所以c的数据被剔除了；外链接outer求的是并集，结合了左链接left和右链接right的效果，通过how来指定链接方式:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677In [14]: df1 = DataFrame(&#123;&apos;key&apos;:list(&apos;aaccbbc&apos;), ...: &apos;data1&apos;:range(7)&#125;) ...:In [15]: df2 = DataFrame(&#123;&apos;key&apos;:list(&apos;abc&apos;), ...: &apos;data2&apos;:range(3)&#125;) ...:In [16]: df1Out[16]: data1 key0 0 a1 1 a2 2 c3 3 c4 4 b5 5 b6 6 cIn [17]: df2Out[17]: data2 key0 0 a1 1 b2 2 cIn [18]: pd.merge(df1,df2)Out[18]: data1 key data20 0 a 01 1 a 02 2 c 23 3 c 24 6 c 25 4 b 16 5 b 1In [19]: df1.merge(df2,on=&apos;key&apos;)Out[19]: data1 key data20 0 a 01 1 a 02 2 c 23 3 c 24 6 c 25 4 b 16 5 b 1In [20]: df3 = DataFrame(&#123;&apos;lkey&apos;:list(&apos;aaccbbc&apos;), ...: &apos;data1&apos;:range(7)&#125;) ...:In [21]: df4 = DataFrame(&#123;&apos;rkey&apos;:list(&apos;abc&apos;), ...: &apos;data2&apos;:range(3)&#125;) ...:In [22]: pd.merge(df3,df4,left_on=&apos;lkey&apos;,right_on=&apos;rkey&apos;)Out[22]: data1 lkey data2 rkey0 0 a 0 a1 1 a 0 a2 2 c 2 c3 3 c 2 c4 6 c 2 c5 4 b 1 b6 5 b 1 bIn [23]: df1.merge(df2,on=&apos;key&apos;,how=&apos;outer&apos;)Out[23]: data1 key data20 0 a 01 1 a 02 2 c 23 3 c 24 6 c 25 4 b 16 5 b 1 多对多多对多链接产生的是行的笛卡尔积，链接方式只影响出现在结果中的键；要根据多个键进行合并，传入一个由列名组成的列表即可(可以看成组合外键)；对于列名重复的问题可以通过设置suffixes选项指定附加到左右两个DataFrame对象列名上的字符串：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192In [29]: df1 = DataFrame(&#123;&apos;key&apos;:list(&apos;aaccbbc&apos;), ...: &apos;data1&apos;:range(7)&#125;) ...:In [30]: df2 = DataFrame(&#123;&apos;key&apos;:list(&apos;abacd&apos;), ...: &apos;data2&apos;:range(5)&#125;) ...:In [31]: df1Out[31]: data1 key0 0 a1 1 a2 2 c3 3 c4 4 b5 5 b6 6 cIn [32]: df2Out[32]: data2 key0 0 a1 1 b2 2 a3 3 c4 4 dIn [33]: pd.merge(df1,df2,on=&apos;key&apos;,how=&apos;left&apos;)Out[33]: data1 key data20 0 a 01 0 a 22 1 a 03 1 a 24 2 c 35 3 c 36 4 b 17 5 b 18 6 c 3In [42]: left = DataFrame(&#123;&apos;key1&apos;:[&apos;foo&apos;,&apos;foo&apos;,&apos;bar&apos;], ...: &apos;key2&apos;:[&apos;one&apos;,&apos;two&apos;,&apos;one&apos;], ...: &apos;lval&apos;:range(3)&#125;) ...:In [43]: right = DataFrame(&#123;&apos;key1&apos;:[&apos;bar&apos;,&apos;foo&apos;,&apos;bar&apos;,&apos;bar&apos;], ...: &apos;key2&apos;:[&apos;one&apos;,&apos;two&apos;,&apos;one&apos;,&apos;two&apos;], ...: &apos;lval&apos;:range(4)&#125;) ...:In [44]: leftOut[44]: key1 key2 lval0 foo one 01 foo two 12 bar one 2In [45]: rightOut[45]: key1 key2 lval0 bar one 01 foo two 12 bar one 23 bar two 3In [46]: left.merge(right,on=[&apos;key1&apos;,&apos;key2&apos;],how=&apos;outer&apos;)Out[46]: key1 key2 lval_x lval_y0 foo one 0.0 NaN1 foo two 1.0 1.02 bar one 2.0 0.03 bar one 2.0 2.04 bar two NaN 3.0In [47]: left.merge(right,on=&apos;key1&apos;,how=&apos;outer&apos;)Out[47]: key1 key2_x lval_x key2_y lval_y0 foo one 0 two 11 foo two 1 two 12 bar one 2 one 03 bar one 2 one 24 bar one 2 two 3In [48]: left.merge(right,on=&apos;key1&apos;,how=&apos;outer&apos;,suffixes=[&apos;_left&apos;,&apos;_right&apos;])Out[48]: key1 key2_left lval_left key2_right lval_right0 foo one 0 two 11 foo two 1 two 12 bar one 2 one 03 bar one 2 one 24 bar one 2 two 3 索引上的合并当DataFrame中的连接键位于其索引上可以通过传入left_index=True和right_index=True来说明索引应该被用作连接键，对于层次化的索引必须以列表的形式指明用作合并键的多个列，同样可以合并双方的索引：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104In [3]: left1 = DataFrame(&#123;'key':list('abaacb'), ...: 'value':range(6)&#125;) ...:In [4]: right1 = DataFrame(&#123;'group_val':[1,2]&#125;,index=['a','b'])In [5]: left1Out[5]: key value0 a 01 b 12 a 23 a 34 c 45 b 5In [6]: right1Out[6]: group_vala 1b 2In [7]: pd.merge(left1,right1,left_on='key',right_index=True)Out[7]: key value group_val0 a 0 12 a 2 13 a 3 11 b 1 25 b 5 2In [8]: pd.merge(left1,right1,left_on='key',right_index=True,how='outer')Out[8]: key value group_val0 a 0 1.02 a 2 1.03 a 3 1.01 b 1 2.05 b 5 2.04 c 4 NaNIn [24]: lefth = DataFrame(&#123;'key1':['row1','row1','row1','row2','row2'], ...: 'key2':[2001,2001,2002,2001,2002], ...: 'data':range(5)&#125;) ...:In [25]: righth = DataFrame(np.arange(12).reshape((4,3)), ...: index=[['row1','row1','row2','row2'],[2001,2002,2001,2001]], ...: columns=['col1','col2','col3']) ...:In [26]: lefthOut[26]: data key1 key20 0 row1 20011 1 row1 20012 2 row1 20023 3 row2 20014 4 row2 2002In [27]: righthOut[27]: col1 col2 col3row1 2001 0 1 2 2002 3 4 5row2 2001 6 7 8 2001 9 10 11In [28]: pd.merge(lefth,righth,left_on=['key1','key2'],right_index=True)Out[28]: data key1 key2 col1 col2 col30 0 row1 2001 0 1 21 1 row1 2001 0 1 22 2 row1 2002 3 4 53 3 row2 2001 6 7 83 3 row2 2001 9 10 11In [29]: left2 = DataFrame(np.arange(6).reshape((3,2)),index=list('ace'),columns=['col1','col2'])In [30]: right2 = DataFrame(np.arange(8).reshape((4,2)),index=list('bcde'),columns=['col_1','col_2'])In [31]: left2Out[31]: col1 col2a 0 1c 2 3e 4 5In [32]: right2Out[32]: col_1 col_2b 0 1c 2 3d 4 5e 6 7In [33]: pd.merge(left2,right2,how='outer',left_index=True,right_index=True)Out[33]: col1 col2 col_1 col_2a 0.0 1.0 NaN NaNb NaN NaN 0.0 1.0c 2.0 3.0 2.0 3.0d NaN NaN 4.0 5.0e 4.0 5.0 6.0 7.0 DataFrame有一个join方法，它能更为方便地实现按索引合并。它还可以合并多个带有相同或相似索引的DataFrame对象，而不管它们之间有没有重叠的列；同时它也支持参数DataFrame的索引跟调用者DataFrame的某个列之间的连接，队友索引的简单合并，可以向join传入一组DataFrame：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768In [42]: left1Out[42]: key value0 a 01 b 12 a 23 a 34 c 45 b 5In [43]: left2Out[43]: col1 col2a 0 1c 2 3e 4 5In [44]: left2.join(right2,how='outer')Out[44]: col1 col2 col_1 col_2a 0.0 1.0 NaN NaNb NaN NaN 0.0 1.0c 2.0 3.0 2.0 3.0d NaN NaN 4.0 5.0e 4.0 5.0 6.0 7.0In [45]: left1Out[45]: key value0 a 01 b 12 a 23 a 34 c 45 b 5In [46]: right1Out[46]: group_vala 1b 2In [47]: left1.join(right1,on='key')Out[47]: key value group_val0 a 0 1.01 b 1 2.02 a 2 1.03 a 3 1.04 c 4 NaN5 b 5 2.0In [48]: anote =DataFrame(np.arange(8).reshape((4,2)),index=['a','c','b','f'],columns=['col3','col4'])In [49]: anoteOut[49]: col3 col4a 0 1c 2 3b 4 5f 6 7In [50]: left2.join([right2,anote])Out[50]: col1 col2 col_1 col_2 col3 col4a 0 1 NaN NaN 0.0 1.0c 2 3 2.0 3.0 2.0 3.0e 4 5 6.0 7.0 NaN NaN 轴向连接另一种数据合并运算称作连接(concatenation)、绑定(binding)或堆叠(stacking)。NumPy提供了一个用于合并原始NumPy数组的concatenation函数:1234567891011121314In [54]: np.concatenate([arr,arr], axis=1)Out[54]:array([[ 0, 1, 2, 3, 0, 1, 2, 3], [ 4, 5, 6, 7, 4, 5, 6, 7], [ 8, 9, 10, 11, 8, 9, 10, 11]])In [55]: np.concatenate([arr,arr], axis=0)Out[55]:array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 对于pandas对象(如Series和DataFrame)，带有标签的轴能进一步推广数组的连接运算: 如果个对象其他轴上的索引不同，那些轴应该做并集还是交集 结果对象中的分组需要是否各不相同 用于连接的轴是否重要 concat函数的参数 参数 说明 obj 参与连接的pandas对象的列表或字典。唯一必需的参数 axis 指明连接的轴向,默认为0 join “inner”、”outer”其中之一，默认为”outer”。指明其他轴向上的索引时按交集(inner)还是并集(outer)进行合并 join_axes 指明用于其他n-1条轴的索引，不执行并集/交集运算 keys 与连接对象有关的值，用于形成连接轴向上的层次化索引。可以是任意值的列表或数组、元组数组、列表数组(如果将levels设置成多级数组的话) levels 指定用作层次化索引各级别上的索引，如果设置了keys的话 names 用于创建分层级别的名称，如果设置了keys和levels的话 verify_integrity 检查结果对象新轴上的重复情况，如果发现则引发异常。默认(False)允许重复 ignore_index 不保留连接轴上的索引，产生一组新索引range(total_length) pandas的concat函数提供了解决以上问题的可靠方式，对没有重叠索引的Series调用concat可以将值和索引粘合在一起;默认情况是在axis=0上工作，最后产生一个新的Series。如果传入axis=1将会得到一个DataFrame，这种情况下从索引的有序并集可以看出另一条轴上没有重叠，可以传入join=&#39;inner&#39;得到交集:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455In [56]: s1 = Series([0,1],index=list('ab'))In [57]: s2 = Series([2,3,4],index=list('cde'))In [58]: s3 = Series([5,6,7],index=list('fgh'))In [59]: pd.concat([s1,s2,s3])Out[59]:a 0b 1c 2d 3e 4f 5g 6h 7dtype: int64In [60]: pd.concat([s1,s2,s3],axis=1)Out[60]: 0 1 2a 0.0 NaN NaNb 1.0 NaN NaNc NaN 2.0 NaNd NaN 3.0 NaNe NaN 4.0 NaNf NaN NaN 5.0g NaN NaN 6.0h NaN NaN 7.0In [62]: s4 = pd.concat([s1*5,s3])In [63]: s4Out[63]:a 0b 5f 5g 6h 7dtype: int64In [64]: pd.concat([s1,s4],axis=1)Out[64]: 0 1a 0.0 0b 1.0 5f NaN 5g NaN 6h NaN 7In [65]: pd.concat([s1,s4],axis=1,join='inner')Out[65]: 0 1a 0 0b 1 5 可以通过join_axes指定要在其他轴上使用的索引，使用keys可以在连接轴上创建一个层次化索引：123456789101112131415161718In [69]: pd.concat([s1,s4],axis=1,join_axes=[['a','c','b','e']])Out[69]: 0 1a 0.0 0.0c NaN NaNb 1.0 5.0e NaN NaNIn [71]: pd.concat([s1,s1,s3],keys=['one','two','three'])Out[71]:one a 0 b 1two a 0 b 1three f 5 g 6 h 7dtype: int64 若果沿着axis=1对Series进行合并，则keys就会成为DataFrame的列头，对于DataFrame效果一样；如果传入的不是列表而是一个字典，则字典的键就会被当做keys选项的值;names可以创建分层级别：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657In [73]: df1 = DataFrame(np.arange(6).reshape(3,2),index=['a','b','c'],columns=['one','two'])In [74]: df2 = DataFrame(2+np.arange(4).reshape(2,2),index=['a','c'],columns=['three','four'])In [75]: df1Out[75]: one twoa 0 1b 2 3c 4 5In [76]: df2Out[76]: three foura 2 3c 4 5In [77]: pd.concat([df1,df2],axis=1,keys=['level1','level2'])Out[77]: level1 level2 one two three foura 0 1 2.0 3.0b 2 3 NaN NaNc 4 5 4.0 5.0In [73]: df1 = DataFrame(np.arange(6).reshape(3,2),index=['a','b','c'],columns=['one','two'])In [74]: df2 = DataFrame(2+np.arange(4).reshape(2,2),index=['a','c'],columns=['three','four'])In [75]: df1Out[75]: one twoa 0 1b 2 3c 4 5In [76]: df2Out[76]: three foura 2 3c 4 5In [77]: pd.concat([df1,df2],axis=1,keys=['level1','level2'])Out[77]: level1 level2 one two three foura 0 1 2.0 3.0b 2 3 NaN NaNc 4 5 4.0 5.0In [79]: pd.concat(&#123;'level1':df1,'level2':df2&#125;,axis=1,names=['upper','down'])Out[79]:upper level1 level2down one two three foura 0 1 2.0 3.0b 2 3 NaN NaNc 4 5 4.0 5.0 需要排除与分析无关的行索引，传入ignore_index=True：123456789101112131415161718192021In [83]: df1Out[83]: one twoa 0 1b 2 3c 4 5In [84]: df2Out[84]: three foura 2 3c 4 5In [85]: pd.concat([df1,df2],ignore_index=True)Out[85]: four one three two0 NaN 0.0 NaN 1.01 NaN 2.0 NaN 3.02 NaN 4.0 NaN 5.03 3.0 NaN 2.0 NaN4 5.0 NaN 4.0 NaN 合并重叠数据如果数据集的索引全部或部分重叠就不能拿用简单的合并(merge)或连接(concatenation)运算来处理了。combine_first实现了相同索引择一选择的功能,满足条件则选1否则选2，类似于np.where(pd.isnull(a),b,a)：1234567891011121314151617181920212223242526272829303132333435363738In [91]: a = Series([np.nan,2,np.nan,3,4,np.nan],index=list('fedcba'))In [92]: b = Series(np.arange(len(a)),dtype=np.float64,index=list('fedcba'))In [93]: b[2:3] = np.nanIn [94]: aOut[94]:f NaNe 2.0d NaNc 3.0b 4.0a NaNdtype: float64In [95]: bOut[95]:f 0.0e 1.0d NaNc 3.0b 4.0a 5.0dtype: float64In [96]: np.where(pd.isnull(a),b,a)Out[96]: array([ 0., 2., nan, 3., 4., 5.])In [97]: b[:-2].combine_first(a[2:])Out[97]:a NaNb 4.0c 3.0d NaNe 1.0f 0.0dtype: float64 对于DataFrame，combine_first会在列上做同样的事，可以看做参数对象中的数据为调用者对象的缺失数据”打补丁”:12345678910111213141516171819202122232425262728293031323334In [107]: df1 = DataFrame(&#123;'a':[1,np.nan,5,np.nan], ...: 'b':[np.nan,2,np.nan,6], ...: 'c':range(2,18,4)&#125;) ...:In [108]: df2 = DataFrame(&#123;'a':[5,4,np.nan,3,7], ...: 'b':[np.nan,3,4,5,9]&#125;) ...:In [109]: df1Out[109]: a b c0 1.0 NaN 21 NaN 2.0 62 5.0 NaN 103 NaN 6.0 14In [110]: df2Out[110]: a b0 5.0 NaN1 4.0 3.02 NaN 4.03 3.0 5.04 7.0 9.0In [111]: df1.combine_first(df2)Out[111]: a b c0 1.0 NaN 2.01 4.0 2.0 6.02 5.0 4.0 10.03 3.0 6.0 14.04 7.0 9.0 NaN 1.可用做实例方法df1.merge(df2),df1想当于left，df2相当于right ↩]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据清洗</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据加载、存储与文件格式]]></title>
    <url>%2F2018%2F03%2F21%2F%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E3%80%81%E5%AD%98%E5%82%A8%E4%B8%8E%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[读写文本格式的数据pandas提供了一些用于将表格型数据读取为DataFrame对象的函数 pandas中的解析函数 函数 说明 read_csv 从文件、URL、文件型对象中加载带分隔符的数据。默认分隔符为逗号 read_table 从文件、URL、文件型对象中加载带分隔符的数据。默认分隔符为制表符(“\t”) read_fwf 读取定宽列格式数据(没有分隔符) read_clipboard 读取剪贴板中的数据，可以看做read_table的剪贴板版。将网页转换为表格时很有用 这些函数的选项可以划分为几个大类： 索引：将一个或多个列当做返回的DataFrame处理，以及是否从文件、用户获取列名 类型推断和数据转换：包括用户定义值的转换、缺失值标记列表等 日期解析： 包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列 迭代：支持对大文件进行逐块迭代 不规整数据问题：跳过一些行、页脚、注释或其他一些不重要的东西 read_csv/read_table函数的参数 参数 说明 filepath_or_buffer 表示文件系统位置、URL、文件型对象的字符串或任何有read()函数的对象(file handle或StringIO) sep/delimiter 用于对行中各字段进行拆分的字符序列或正则表达式 header 用作列名的行号。默认为0(第一行)，如果没有header行就应该设置为None index_col 用作行索引的列编号或列名。可以是单个名称/数字或由多个名称/数字组成的列表(层次化索引) names 用于结果的列名列表，结合header=None skiprows 需要忽略的行数(从文件开始处算起)，或需要跳过的行号列表(从0开始) na_values 一组用于替换NA的值 comment 用于将注释信息从行尾拆分出去的字符(一个或多个) parse_dates 尝试将数据解析为日期，默认为False。如果为True，则尝试解析所有列。此外，还可以指定需要解析的一组列号或列名。如果列表的元素为列表或元组，就会将多个列组合到一起再进行日期解析工作(日期/时间分别位于两个列中) keep_data_col 如果连接多列解析日期，则保持参加连接的列。默认为False dayfirst 当解析有歧义的日期时，将其看做国际格式(7/6/2018 -&gt; June 7,2018)。默认为False date_parser 用于解析日期的函数 nrows 需要读取的行数(从文件开始处算起) iterator 返回一个TextParser以便逐块读取文件 chunksize 文件快的大小(用于迭代) skip_footer 需要忽略的行数(从文件末尾处算起) verbose 打印各种解析器输出信息，比如“非数值列中缺失值的数量” encoding 用于unicode的文本编码格式。“utf-8”表示用UTF-8编码的文本 squeeze 如果数据经解析后仅含一列，则返回Series thousands 千分位分隔符，如“，”或“.” 可以使用read_csv和read_table读取一个以逗号分隔的(CSV)文本文件，使用read_table是指定分隔符sep=&#39;,&#39;；当未指定列名时，会使用第一行数据当做列名，可以通过设置header=None使用默认的列名，也可以使用names=[]自己定义列名:123456789101112131415161718192021222324252627282930313233343536373839404142In [12]: !type ex1.csva,b,c,d,message1,2,3,4,hello5,6,7,8,world9,10,11,12,fooIn [13]: pd.read_csv('ex1.csv')Out[13]: a b c d message0 1 2 3 4 hello1 5 6 7 8 world2 9 10 11 12 fooIn [14]: pd.read_table('ex1.csv',sep=',')Out[14]: a b c d message0 1 2 3 4 hello1 5 6 7 8 world2 9 10 11 12 fooIn [15]: pd.read_csv('ex1.csv',header=None)Out[15]: 0 1 2 3 40 a b c d message1 1 2 3 4 hello2 5 6 7 8 world3 9 10 11 12 fooIn [16]: pd.read_csv('ex1.csv',names=['col1','col2','col3','col4'])Out[16]: col1 col2 col3 col4a b c d message1 2 3 4 hello5 6 7 8 world9 10 11 12 fooIn [17]: pd.read_csv('ex1.csv',names=['col1','col2','col3','col4','col5'])Out[17]: col1 col2 col3 col4 col50 a b c d message1 1 2 3 4 hello2 5 6 7 8 world3 9 10 11 12 foo 如果需要将数据指定为索引列，可以通过设置index_col参数指定索引列，而希望将多个列做成一个层次化索引，只需要传入列编号或列名组成的列表即可：123456789101112131415161718192021222324252627282930313233343536In [21]: !type csv_mindex.csvkey1,key2,value1,value2one,a,1,2one,b,3,4one,c,5,6one,d,7,8two,a,9,10two,b,11,12two,c,13,14two,d,15,16In [22]: pd.read_csv('csv_mindex.csv',index_col='key1')Out[22]: key2 value1 value2key1one a 1 2one b 3 4one c 5 6one d 7 8two a 9 10two b 11 12two c 13 14two d 15 16In [23]: pd.read_csv('csv_mindex.csv',index_col=['key1','key2'])Out[23]: value1 value2key1 key2one a 1 2 b 3 4 c 5 6 d 7 8two a 9 10 b 11 12 c 13 14 d 15 16 有些表格可能不是固定的分隔符去分隔字段的，对此可以编写一个正则表达式来作为read_table的分隔符:123456789101112131415In [26]: list(open('ex3.txt'))Out[26]:[' A B C\n', 'aaa -0.264438 -1.026059 -0.619500\n', 'bbb 0.927272 0.302904 -0.032399\n', 'ccc -0.264273 -0.386314 -0.217601\n', 'ddd -0.871858 -0.348382 1.100491\n']In [27]: pd.read_table('ex3.txt',sep='\s+')Out[27]: A B Caaa -0.264438 -1.026059 -0.619500bbb 0.927272 0.302904 -0.032399ccc -0.264273 -0.386314 -0.217601ddd -0.871858 -0.348382 1.100491 同时可以使用skiprows跳过指定的行：1234567891011121314In [28]: !type ex4.csv# hey!a,b,c,d,message# just wanted to make things more difficult for you# who reads CSV files with computers, anyway?1,2,3,4,hello5,6,7,8,world9,10,11,12,fooIn [29]: pd.read_csv('ex4.csv',skiprows=[0,2,3])Out[29]: a b c d message0 1 2 3 4 hello1 5 6 7 8 world2 9 10 11 12 foo 默认情况pandas会用一组经常出现的标记值识别缺失值，如NA、-1.#IND以及NULL，可以使用na_values指定一组用于表示缺失值的字符串，可以使用一个字典为各列指定不同的NA标记值:12345678910111213141516171819202122232425In [30]: !type ex5.csvsomething,a,b,c,d,messageone,1,2,3,4,NAtwo,5,6,,8,worldthree,9,10,11,12,fooIn [31]: pd.read_csv('ex5.csv')Out[31]: something a b c d message0 one 1 2 3.0 4 NaN1 two 5 6 NaN 8 world2 three 9 10 11.0 12 fooIn [32]: pd.read_csv('ex5.csv',na_values=['NULL'])Out[32]: something a b c d message0 one 1 2 3.0 4 NaN1 two 5 6 NaN 8 world2 three 9 10 11.0 12 fooIn [33]: pd.read_csv('ex5.csv',na_values=&#123;'message':['foo','NA'],'something':['two']&#125;)Out[33]: something a b c d message0 one 1 2 3.0 4 NaN1 NaN 5 6 NaN 8 world2 three 9 10 11.0 12 NaN 逐块读取文本文件在读取大文件中的参数时，只想读取文件的一小部分或逐块对文件进行迭代;nrows用于指定读取几行;chunksize用于逐块读取文件时设置行数，read_csv返回的TextParse对象可以根据chunksize对文件进行逐块迭代：1234567891011121314151617181920212223242526272829303132333435In [46]: pd.read_csv('ex6.csv')Out[46]: one two three four key0 0.467976 -0.038649 -0.295344 -1.824726 L1 -0.358893 1.404453 0.704965 -0.200638 B2 -0.501840 0.659254 -0.421691 -0.057688 G... ... ... ... ... ..9998 -0.362559 0.598894 -1.843201 0.887292 G9999 -0.096376 -1.012999 -0.657431 -0.573315 0[10000 rows x 5 columns]In [47]: chunk = pd.read_csv('ex6.csv',chunksize=1000)In [48]: tot = Series([])In [49]: for piece in chunk: ...: tot = tot.add(piece['key'].value_counts(),fill_value=0) ...:In [50]: tot = tot.sort_values(ascending=False)In [51]: tot[:10]Out[51]:E 368.0X 364.0L 346.0O 343.0Q 340.0M 338.0J 337.0F 335.0K 334.0H 330.0dtype: float64 将数据写出到文本格式利用DataFrame的to_csv方法可以将数据写到一个以逗号分隔的文件中，可以是sep参数指定其他的分隔符；缺失值在输出结果空会被表示为空字符串，可以使用na_rep设置别的标记值；如果没有设置其他选项，则会写出行和列的标签，可以通过index=False和header=False设置禁用；可以通过设置columns来指定顺序排列：123456789101112131415161718192021222324252627282930313233343536373839In [52]: data = pd.read_csv('ex5.csv')In [53]: dataOut[53]: something a b c d message0 one 1 2 3.0 4 NaN1 two 5 6 NaN 8 world2 three 9 10 11.0 12 fooIn [54]: data.to_csv('out.csv')In [55]: !type out.csv,something,a,b,c,d,message0,one,1,2,3.0,4,1,two,5,6,,8,world2,three,9,10,11.0,12,fooIn [56]: data.to_csv(sys.stdout,sep='|')|something|a|b|c|d|message0|one|1|2|3.0|4|1|two|5|6||8|world2|three|9|10|11.0|12|fooIn [57]: data.to_csv(sys.stdout,na_rep='NULL'),something,a,b,c,d,message0,one,1,2,3.0,4,NULL1,two,5,6,NULL,8,world2,three,9,10,11.0,12,fooIn [58]: data.to_csv(sys.stdout,index=False,header=False)one,1,2,3.0,4,two,5,6,,8,worldthree,9,10,11.0,12,fooIn [60]: data.to_csv(sys.stdout,index=False,columns=['a','b','c'])a,b,c1,2,3.05,6,9,10,11.0 Series也有ro_csv方法，同时Series可以使用from_csv读取数据12345678910In [61]: Series.from_csv('tseries.csv',parse_dates=True)Out[61]:2000-01-01 02000-01-02 12000-01-03 22000-01-04 32000-01-05 42000-01-06 52000-01-07 6dtype: int64 手工处理分隔符格式 CSV语支选项 参数 说明 delimiter 用于分隔字段的单字符字符串。默认为”,” lineterminator 用于写操作的行结束符，默认为”\r\n”。读操作将忽略此选项，它能认出跨平台的行结束符 quotechar 用于带有特殊字符(如分隔符)的字段的引用符号。默认为“”” quoting 引用约定。可选值包括csv.QUOTE_ALL(引用所有字段)、csv.QUOTE_MINIMAL(只应用带有诸如分隔符之类的特殊字符的字段)、csv.QUOTE_NONNUMERIC以及csv.QUOTE_NON(不引用)。默认为QUOTE_MINIMAL skipinitialspace 忽略分隔符后面的空白符。默认为False doublequote 如何处理字段内的引用符号。如果为True，则双写。 escapechar 用于调分隔符进行转义的字符串(如果quoting被设置为csv.QUOIE_NONE)。默认禁用 对于单字符分隔符文件，可以使用Python内置csv模块，将任意已打开的文件或文件型对象传给csv.reader,对这个reader进行迭代将会为每一行产生去除引号的列表，为了是数据合乎要求，可以做一些整理:1234567891011121314151617181920212223242526272829303132333435In [66]: !type ex7.csv"a","b","c""1","2","3""1","2","3"In [67]: import csvIn [68]: f = open('ex7.csv')In [69]: reader=csv.reader(f)In [70]: for line in reader: ...: print(line) ...:['a', 'b', 'c']['1', '2', '3']['1', '2', '3']In [66]: !type ex7.csv"a","b","c""1","2","3""1","2","3"In [67]: import csvIn [68]: f = open('ex7.csv')In [69]: reader=csv.reader(f)In [70]: for line in reader: ...: print(line) ...:['a', 'b', 'c']['1', '2', '3']['1', '2', '3'] csv的文件有很多，可以定义csv.Dialect的子类定义出新格式(专门的分隔符、字符串引用约定、行结束符等)，CSV语支的参数也可以以关键字的形式提供给csv.reader：12345678910In [84]: class my_dialect(csv.Dialect): ...: lineterminator = '\n' ...: delimiter = ';' ...: quotechar = '"' ...: quoting = csv.QUOTE_MINIMAL ...:In [85]: reader = csv.reader(f, dialect=my_dialect)In [86]: reader = csv.reader(f,delimiter='|') JSON、XML和HTML关于此类文件解析可查看Python文本处理 二进制数据格式可以使用Python内置的pickle序列化来实现数据的二进制存储可以使用pandas.read_pickle函数将数据读回到Python：12345678In [91]: frame.to_pickle('frame')In [92]: pd.read_pickle('frame')Out[92]: a b c d message0 1 2 3 4 hello1 5 6 7 8 world2 9 10 11 12 foo 使用HDF5格式HDF5能实现高效读取磁盘上以二进制格式存储的科学依据。HDF5中HDF指的是层次性数据格式。每个HDF5文件都含有一个文件系统式的节点结构，能够存储多个数据集并支持元数据。HDF5支持多种压缩器的及时压缩，还能更高效地存储重复模式数据。对于那些非常大的无法直接放入内存的数据集，它可以高效地分块读写。Python的HDF5库有两个接口(PyTables和h5py)。 PyTables PyTables抽象了HDF5的许多细节以提供多种灵活的数据容器、表索引、查询功能以及对核外计算技术的支持。 h5py h5py提供了一种直接而高级的HDF5 API访问接口。 使用SDFStore类需要先下载tables：1pip3 install tables 然后通过PyTables存储pandas对象，HDF5文件中的对象可以通过与字典一样的方式进行获取:1234567891011121314In [101]: store['obj1'] = frameIn [102]: storeOut[102]:&lt;class 'pandas.io.pytables.HDFStore'&gt;File path: mydata.h5/obj1 frame (shape-&gt;[3,5])In [103]: store['obj1']Out[103]: a b c d message0 1 2 3 4 hello1 5 6 7 8 world2 9 10 11 12 foo 读取Microsoft Excel文件pandas的ExcelFile类支持读取存储在Excel 2003(或更高版本)中的表格型数据。由于ExcelFile用到了xlrd和openpyxl包，所以需要安装它们:12In [104]: !pip3 install xlrdIn [105]: !pip3 install openpyxl 通过传入一个xls或xlsx的路径创建一个ExcelFile实例然后将存放在工作表中的数据读取到DataFrame中：12345678910In [112]: xls_file = pd.ExcelFile('ex1.xlsx')In [113]: table = xls_file.parse('Sheet1')In [114]: tableOut[114]: a b c d message0 1 2 3 4 hello1 5 6 7 8 world2 9 10 11 12 foo HTML和Web APIHTML和Web API相关内容查看Python-We客户端和服务器 数据库数据库相关内容查看Python数据库编程]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>输入输出</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas入门(四)]]></title>
    <url>%2F2018%2F03%2F20%2Fpandas%E5%85%A5%E9%97%A8-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[层次化索引层次化索引能在一个轴上拥有多个(两个以上)索引级别，能以低纬度形式处理高纬度数据。在创建Series时，可以使用一个由列表或数组组成的列表作为索引。对于一个层次化索引的对象，选取数据子集的操作同样很简单，有时可以在”内层”中进行选取：12345678910111213141516171819202122232425262728293031In [206]: data = Series(np.random.randn(10),index=[list('aaabbbvvdd'), ...: ['in1','in2','in3','in1','in2','in3','in1','in2','in2','in3']]) ...:In [207]: dataOut[207]:a in1 0.837994 in2 0.360445 in3 -0.657047b in1 0.017681 in2 -0.577803 in3 0.080992v in1 -0.158913 in2 -0.011517d in2 0.632189 in3 -1.181628dtype: float64In [208]: data['a']Out[208]:in1 0.837994in2 0.360445in3 -0.657047dtype: float64In [209]: data[:,'in1']Out[209]:a 0.837994b 0.017681v -0.158913dtype: float64 层次化索引在数据重塑和基于分组的操作中非常重要，使用unstack方法可以将Series多层索引安排到一个DataFrame中,statck是其逆运算:123456789101112131415161718192021In [210]: data.unstack()Out[210]: in1 in2 in3a 0.837994 0.360445 -0.657047b 0.017681 -0.577803 0.080992d NaN 0.632189 -1.181628v -0.158913 -0.011517 NaNIn [211]: data.unstack().stack()Out[211]:a in1 0.837994 in2 0.360445 in3 -0.657047b in1 0.017681 in2 -0.577803 in3 0.080992d in2 0.632189 in3 -1.181628v in1 -0.158913 in2 -0.011517dtype: float64 对于一个DataFrame，每条轴都可以有分层索引，各层都可以有名字；有了列索引后可以通过其选取列分组：123456789101112131415161718192021222324252627282930313233343536In [213]: df = DataFrame(np.arange(16).reshape(4,4), ...: index = [['row1','row1','row2','row2'],[1,2,1,2]], ...: columns=[['col1','col1','col2','col2'],['red','blue','red','blue']]) ...:In [214]: dfOut[214]: col1 col2 red blue red bluerow1 1 0 1 2 3 2 4 5 6 7row2 1 8 9 10 11 2 12 13 14 15In [215]: df.index.names=['rowname1','rowname2']In [216]: df.columns.names=['colname1','colname2']In [217]: dfOut[217]:colname1 col1 col2colname2 red blue red bluerowname1 rowname2row1 1 0 1 2 3 2 4 5 6 7row2 1 8 9 10 11 2 12 13 14 15In [218]: df['col1']Out[218]:colname2 red bluerowname1 rowname2row1 1 0 1 2 4 5row2 1 8 9 2 12 13 重排分级顺序 swaplevelswaplevel接收两个级别编号或名称，并返回一个互换了级别的新对象： 12345678910111213141516171819In [219]: dfOut[219]:colname1 col1 col2colname2 red blue red bluerowname1 rowname2row1 1 0 1 2 3 2 4 5 6 7row2 1 8 9 10 11 2 12 13 14 15In [220]: df.swaplevel('rowname1','rowname2')Out[220]:colname1 col1 col2colname2 red blue red bluerowname2 rowname11 row1 0 1 2 32 row1 4 5 6 71 row2 8 9 10 112 row2 12 13 14 15 sort_index(level=)sort_index(level=)根据单个级别中的值对数据进行排序(稳定的): 12345678910111213141516171819In [225]: df.sort_index(level=1)Out[225]:colname1 col1 col2colname2 red blue red bluerowname1 rowname2row1 1 0 1 2 3row2 1 8 9 10 11row1 2 4 5 6 7row2 2 12 13 14 15In [226]: df.swaplevel(0,1).sort_index(level=0)Out[226]:colname1 col1 col2colname2 red blue red bluerowname2 rowname11 row1 0 1 2 3 row2 8 9 10 112 row1 4 5 6 7 row2 12 13 14 15 根据级别汇总统计许多对于DataFrame和Series的描述和汇总统计都有一个level选项，用于指定在某条轴上求和的级别：12345678910111213141516171819In [225]: df.sort_index(level=1)Out[225]:colname1 col1 col2colname2 red blue red bluerowname1 rowname2row1 1 0 1 2 3row2 1 8 9 10 11row1 2 4 5 6 7row2 2 12 13 14 15In [226]: df.swaplevel(0,1).sort_index(level=0)Out[226]:colname1 col1 col2colname2 red blue red bluerowname2 rowname11 row1 0 1 2 3 row2 8 9 10 112 row1 4 5 6 7 row2 12 13 14 15 使用DataFrame的列 set_indexset_index函数将一个或多个列转换为行索引，并创建一个新的DataFrame，默认情况下用于创建索引的列会被移除，可以通过设置drop=False保留： 123456789101112131415161718192021222324252627282930313233343536373839In [231]: frame = DataFrame(&#123;'a':range(7),'b':range(7,0,-1), ...: 'c':['one','one','one','two','two','two','two'], ...: 'd':[0,1,2,0,1,2,3]&#125;) ...:In [232]: frameOut[232]: a b c d0 0 7 one 01 1 6 one 12 2 5 one 23 3 4 two 04 4 3 two 15 5 2 two 26 6 1 two 3In [233]: frame.set_index(['c','d'])Out[233]: a bc done 0 0 7 1 1 6 2 2 5two 0 3 4 1 4 3 2 5 2 3 6 1In [234]: frame.set_index(['c','d'],drop=False)Out[234]: a b c dc done 0 0 7 one 0 1 1 6 one 1 2 2 5 one 2two 0 3 4 two 0 1 4 3 two 1 2 5 2 two 2 3 6 1 two 3 reset_indexreset_index将层次化索引的级别转移到列里面，和set_index相反: 12345678910111213141516171819202122In [236]: frame2Out[236]: a bc done 0 0 7 1 1 6 2 2 5two 0 3 4 1 4 3 2 5 2 3 6 1In [237]: frame2.reset_index()Out[237]: c d a b0 one 0 0 71 one 1 1 62 one 2 2 53 two 0 3 44 two 1 4 35 two 2 5 26 two 3 6 1 整数索引当一个pandas对象含有类似0、1、2的索引时，很难推断出需要的是基于标签或位置的索引，为了保证良好的一致性，如果轴索引含有索引器，那么根据整数进行数据选取的操作将总是面向标签的；如果需要可靠地、不考虑索引类型的、基于位置的索引，可以使用loc:1234567891011121314151617181920212223In [271]: obj = Series(np.arange(3))In [272]: obj.loc[:1]Out[272]:0 01 1dtype: int32In [273]: frame = DataFrame(np.arange(9).reshape(3,3),index=[2,0,1])In [274]: frame.loc[0,:]Out[274]:0 31 42 5Name: 0, dtype: int32In [275]: frame.loc[:,0]Out[275]:2 00 31 6Name: 0, dtype: int32]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas入门(三)]]></title>
    <url>%2F2018%2F03%2F20%2Fpandas%E5%85%A5%E9%97%A8-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[汇总和计算描述统计pandas对象拥有一组常用的数学和统计方法。她们大部分属于约简和汇总统计，用于从Series中提取单个值(如sum或mean)或从DataFrame的行或列中提取一个Series，他们都是基于没有缺失数据的假设构建的。 约简方法的选项 选项 说明 axis 约简的轴。DataFrame的行用0，列用1 skipna 排除缺失值，默认值为True level 如果轴是层次化索引的(即MultiIndex)，则根据level分组约简 描述和汇总统计 方法 说明 count 非NA值的数量 describe 针对Series或各DataFrame列计算汇总统计 min、max 计算最小值和最大值 argmin、argmax 计算能够获取到最小值和最大值的索引位置(整数) idxmin、idmax 计算能够获取到最小值和最大值的索引值 quantile 计算样本的分位数(0到1) sum 值的总和 mean 值的平均值 median 指的算术中位数 mad 根据平均值计算平均绝对离差 var 样本值的方差 std 样本值的标准差 skew 样本值的偏度(三阶矩) kurt 样本值的峰度(四阶矩) cumsum 样本值的累计和 cummin、cummax 样本值的累计最小值和累计最大值 cumprod 样本值的累计积 diff 计算一阶差分(对时间序列有用)_ pct_change 计算百分数变化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748In [33]: df = DataFrame([[1,np.nan],[2,3],[np.nan,np.nan],[4,5]], ...: index=list('abcd'), ...: columns=['one','two']) ...:In [34]: dfOut[34]: one twoa 1.0 NaNb 2.0 3.0c NaN NaNd 4.0 5.0In [35]: df.sum()Out[35]:one 7.0two 8.0dtype: float64In [36]: df.sum(axis=1)Out[36]:a 1.0b 5.0c NaNd 9.0dtype: float64In [37]: df.mean(axis=1,skipna=False)Out[37]:a NaNb 2.5c NaNd 4.5dtype: float64In [38]: df.idxmax()Out[38]:one dtwo ddtype: objectIn [39]: df.cumsum()Out[39]: one twoa 1.0 NaNb 3.0 3.0c NaN NaNd 7.0 8.0 describe用于一次性产生多个汇总统计，对于非数值类型会产生另外一种汇总统计：123456789101112131415161718192021In [40]: df.describe()Out[40]: one twocount 3.000000 2.000000mean 2.333333 4.000000std 1.527525 1.414214min 1.000000 3.00000025% 1.500000 3.50000050% 2.000000 4.00000075% 3.000000 4.500000max 4.000000 5.000000In [41]: obj =Series(list('aabc')*4)In [42]: obj.describe()Out[42]:count 16unique 3top afreq 8dtype: object 相关系数和协方差Series的corr方法用于计算两个Series中重叠的、非NAN的、按索引对齐的相关系数；使用cov计算协方差：123456789In [46]: obj = Series([1,2,3,4],index=list('abcd'))In [47]: obj2 = Series([1,np.nan,5,6,7],index=list('acdse'))In [48]: obj.corr(obj2)Out[48]: 1.0In [49]: obj.cov(obj2)Out[49]: 6.0 DataFrame的corr和cov方法将以DataFrame的形式返回完整的相关系数或协方差矩阵：12345678910111213141516171819202122232425262728293031323334353637383940414243In [60]: df = DataFrame(np.arange(16).reshape(4,4), ...: index=list('abcd'), ...: columns=['col1','col2','col3','col4']) ...:In [61]: df2 = DataFrame(np.arange(25).reshape(5,5), ...: index=list('abcde'), ...: columns=['col1','col2','col3','col4','col5']) ...: ...:In [62]: dfOut[62]: col1 col2 col3 col4a 0 1 2 3b 4 5 6 7c 8 9 10 11d 12 13 14 15In [63]: df2Out[63]: col1 col2 col3 col4 col5a 0 1 2 3 4b 5 6 7 8 9c 10 11 12 13 14d 15 16 17 18 19e 20 21 22 23 24In [64]: df.corr()Out[64]: col1 col2 col3 col4col1 1.0 1.0 1.0 1.0col2 1.0 1.0 1.0 1.0col3 1.0 1.0 1.0 1.0col4 1.0 1.0 1.0 1.0In [65]: df.cov()Out[65]: col1 col2 col3 col4col1 26.666667 26.666667 26.666667 26.666667col2 26.666667 26.666667 26.666667 26.666667col3 26.666667 26.666667 26.666667 26.666667col4 26.666667 26.666667 26.666667 26.666667 利用DataFrame的corrwith方法可以计算其列或行跟另一个Series或DataFrame之间的相关系数；传入一个Series将会返回一个相关系数值Series，传入一个DataFrame则会计算按列名配对的相关系数(传入axis=1按行计算)：12345678910111213141516In [66]: df.corrwith(df2)Out[66]:col1 1.0col2 1.0col3 1.0col4 1.0col5 NaNdtype: float64In [69]: df.corrwith(df2.col1)Out[69]:col1 1.0col2 1.0col3 1.0col4 1.0dtype: float64 ###唯一值、值计数以及成员资格 唯一值、值计数、成员资格方法 方法 说明 isin 计算一个表示“Series各值是否包含于传入的值序列中”的布尔型数组 unique 计算Series中的唯一值数组，按发现顺序返回 value_counts 返回一个Series，其索引为唯一值，其值为频率，按计数值降序排列 unique可以从Series中获取唯一值数组，返回的唯一值是未排序的，可以对结果进行排序(unique().sort())。value_counts用于计算一个Series中各值出现的频率，结果Series是按值频率降序排列的。value_counts是一个顶级pandas方法，可以用于任何数组或序列；isin用于判断矢量化集合的成员资格，可用于选取Series中或DataFrame列中数据的子集：123456789101112131415161718192021222324252627282930313233343536373839404142434445In [78]: obj = Series(list('abbddc'))In [79]: sor = obj.unique()In [80]: sorOut[80]: array(['a', 'b', 'd', 'c'], dtype=object)In [81]: sor.sort()In [82]: sorOut[82]: array(['a', 'b', 'c', 'd'], dtype=object)In [83]: obj.value_counts()Out[83]:b 2d 2c 1a 1dtype: int64In [84]: pd.value_counts(obj.values, sort=False)Out[84]:d 2a 1b 2c 1dtype: int64In [85]: mask = obj.isin(['a','c'])In [86]: maskOut[86]:0 True1 False2 False3 False4 False5 Truedtype: boolIn [87]: obj[mask]Out[87]:0 a5 cdtype: object 可以将pandas.value_counts传递给DataFrame的aplly函数得到DataFrame中多个相关列的柱状图：12345678910111213141516171819202122232425In [89]: data = DataFrame(&#123;'Q1':[1,3,4,4,5], ...: 'Q2':[2,3,4,2,1], ...: 'Q3':[4,1,4,5,6]&#125;) ...:In [90]: dataOut[90]: Q1 Q2 Q30 1 2 41 3 3 12 4 4 43 4 2 54 5 1 6In [91]: result = data.apply(pd.value_counts).fillna(0)In [92]: resultOut[92]: Q1 Q2 Q31 1.0 1.0 1.02 0.0 2.0 0.03 1.0 1.0 0.04 2.0 1.0 2.05 1.0 0.0 1.06 0.0 0.0 1.0 处理缺失数据缺失数据在大部分数据分析应用中都很常见。pandas使用浮点值NaN(Not a Number)表示浮点和非浮点数组中的缺失数据，它只是一个便于检测的标记。Python内置的None值也会被当做NA处理 NA处理方法 方法 说明 dropna 根据各标签中是否存在缺失数据对轴标签进行过滤，可通过阈值调节对缺失值的容忍度 fillna 用指定值或插值方法(如ffill或bfill)填充缺失数据 isnull 返回一个含有布尔值的对象，这些布尔值表示哪些值是缺失值/NA，该对象的类型与源类型一样 notnull isnull的否定式 123456789101112131415161718192021In [99]: obj = Series([1,np.nan,2,np.nan,4])In [100]: obj.isnull()Out[100]:0 False1 True2 False3 True4 Falsedtype: boolIn [101]: obj[0]=NoneIn [102]: obj.isnull()Out[102]:0 True1 True2 False3 True4 Falsedtype: bool 滤除缺失数据对于Series，dropna返回一个仅含有非空数据和索引值的Series(通过布尔型索引达到一样的效果)：1234567891011121314151617181920In [104]: objOut[104]:0 NaN1 NaN2 2.03 NaN4 4.0dtype: float64In [105]: obj.dropna()Out[105]:2 2.04 4.0dtype: float64In [106]: obj[obj.notnull()]Out[106]:2 2.04 4.0dtype: float64 对于DataFrame对象，dropna默认丢弃任何含有缺失值的行，传入how=&#39;all&#39;将只丢弃全为NA的那些行，要丢弃列需要传入axis=1123456789101112131415161718192021222324252627282930313233343536373839In [108]: data = DataFrame([[1,4,5],[1,np.nan,np.nan],[np.nan,np.nan,np.nan],[np.nan,2,3]])In [109]: dataOut[109]: 0 1 20 1.0 4.0 5.01 1.0 NaN NaN2 NaN NaN NaN3 NaN 2.0 3.0In [110]: data.dropna()Out[110]: 0 1 20 1.0 4.0 5.0In [111]: data.dropna(how='all')Out[111]: 0 1 20 1.0 4.0 5.01 1.0 NaN NaN3 NaN 2.0 3.0In [112]: data[3]=np.nanIn [113]: dataOut[113]: 0 1 2 30 1.0 4.0 5.0 NaN1 1.0 NaN NaN NaN2 NaN NaN NaN NaN3 NaN 2.0 3.0 NaNIn [114]: data.dropna(axis=1,how='all')Out[114]: 0 1 20 1.0 4.0 5.01 1.0 NaN NaN2 NaN NaN NaN3 NaN 2.0 3.0 thresh参数移除非NA个数小于设定值的行：12345678910111213In [123]: df = DataFrame(np.random.randn(7,3))In [124]: df.loc[:3,1] = np.nanIn [125]: df.loc[:2,2] = np.nanIn [126]: df.dropna(thresh=2)Out[126]: 0 1 23 0.620445 NaN -0.3796384 -0.642811 0.033634 0.7000095 0.510774 1.458027 1.2476876 0.614596 -1.986715 -0.378179 填充缺失数据fillna方法是填充缺失数据的主要函数。通过一个常数调用fillna将会将缺失值替换为那个常数值；通过字典调用fillna可以实现对不同的列填充不同的值；fillna默认会返回新对象，通过设置inplace=True可以对现有对象进行就地修改，对reindex有效的插值方法也可用于fillna: fillna函数的参数 参数 说明 value 用于填充缺失值的标量值或字典对象 method 插值方式。如果函数调用时未指定其他参数的话，默认为“ffill” axis 待填充的轴，默认axis=0 inplace 修改调用者对象而不产生副本 limit (对于前向和后向填充)可以连续填充的最大数量 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273In [127]: dfOut[127]: 0 1 20 -0.293799 NaN NaN1 0.728953 NaN NaN2 0.573023 NaN NaN3 0.620445 NaN -0.3796384 -0.642811 0.033634 0.7000095 0.510774 1.458027 1.2476876 0.614596 -1.986715 -0.378179In [128]: df.fillna(0)Out[128]: 0 1 20 -0.293799 0.000000 0.0000001 0.728953 0.000000 0.0000002 0.573023 0.000000 0.0000003 0.620445 0.000000 -0.3796384 -0.642811 0.033634 0.7000095 0.510774 1.458027 1.2476876 0.614596 -1.986715 -0.378179In [129]: df.fillna(&#123;1:0.5, 3:-1&#125;)Out[129]: 0 1 20 -0.293799 0.500000 NaN1 0.728953 0.500000 NaN2 0.573023 0.500000 NaN3 0.620445 0.500000 -0.3796384 -0.642811 0.033634 0.7000095 0.510774 1.458027 1.2476876 0.614596 -1.986715 -0.378179In [130]: _ = df.fillna(0,inplace=True)In [131]: dfOut[131]: 0 1 20 -0.293799 0.000000 0.0000001 0.728953 0.000000 0.0000002 0.573023 0.000000 0.0000003 0.620445 0.000000 -0.3796384 -0.642811 0.033634 0.7000095 0.510774 1.458027 1.2476876 0.614596 -1.986715 -0.378179In [138]: df = DataFrame(np.random.randn(7,3))In [139]: df.loc[3:,1] = np.nanIn [140]: df.loc[2:,2] = np.nanIn [141]: dfOut[141]: 0 1 20 -1.741073 -0.993316 -1.0300551 0.139948 -1.446029 0.7978562 -0.373251 0.505183 NaN3 1.179879 NaN NaN4 0.764752 NaN NaN5 1.405856 NaN NaN6 -1.053222 NaN NaNIn [142]: df.fillna(method='ffill')Out[142]: 0 1 20 -1.741073 -0.993316 -1.0300551 0.139948 -1.446029 0.7978562 -0.373251 0.505183 0.7978563 1.179879 0.505183 0.7978564 0.764752 0.505183 0.7978565 1.405856 0.505183 0.7978566 -1.053222 0.505183 0.797856]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas入门(二)]]></title>
    <url>%2F2018%2F03%2F19%2Fpandas%E5%85%A5%E9%97%A8-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[基本功能重新索引 reindex的(插值)method选项 参数 说明 fffill或pad 前向填充(或搬运)值 bfill或backfill 后向填充(或搬运)值 reindex函数的参数 参数 说明 index 用作索引的新序列。既可以是Index实例，也可以是其他序列型的Python数据结构。Index会被完全使用，就像没有任何复制一样 method 插值(填充)方式 fill_value 再重新索引的过程中，需要引入缺失值时使用的替代值 limit 前向或后向填充时的最大填充量 level 在MultiIndex的指定级别上匹配简单索引，否则选取其子集 copy 默认为True，无论如何都复制；如果为False，则新旧相等就不复制 pandas对象的reindex方法用于创建一个适应新索引的新对象，reindex将会根据新索引进行重排。如果某个索引值当前不存在，就引入缺失值。method选项可以在重新索引时做一些插值处理：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253In [86]: obj = Series([1,2,3,4],index=['a','b','c','d'])In [87]: objOut[87]:a 1b 2c 3d 4dtype: int64In [88]: obj2 = obj.reindex(['q','w','e','r'])In [89]: obj2Out[89]:q NaNw NaNe NaNr NaNdtype: float64In [90]: obj2 = obj.reindex(['a','b','c','d','e'])In [91]: obj2Out[91]:a 1.0b 2.0c 3.0d 4.0e NaNdtype: float64In [94]: obj2 = obj.reindex(['a','b','c','d','e'],fill_value=0)In [95]: obj2Out[95]:a 1b 2c 3d 4e 0dtype: int64In [98]: obj3 = obj.reindex(['a','b','e','f','c','d'],method='ffill')In [99]: obj3Out[99]:a 1b 2e 4f 4c 3d 4dtype: int64 对于DataFrame,reindex可以修改(行)索引、列、或两个都修改。如果仅传入一个序列，则会重新索引行，使用columns关键字可以重新索引列,也可以同时对行和列进行重新索引，但插值只能按行应用(即轴0):1234567891011121314151617181920212223242526In [105]: frame = DataFrame(np.arange(9).reshape((3,3)),index=['a','b','c'],columns=['col1','col2','col3'])In [106]: frame2 = frame.reindex(['a','b','c','d'])In [107]: frame2Out[107]: col1 col2 col3a 0.0 1.0 2.0b 3.0 4.0 5.0c 6.0 7.0 8.0d NaN NaN NaNIn [108]: frame.reindex(columns=['col_a','col1','col2','col3'])Out[108]: col_a col1 col2 col3a NaN 0 1 2b NaN 3 4 5c NaN 6 7 8In [109]: frame.reindex(index=['a','b','c','d'],method='ffill',columns=['col_a','col1','col2','col3'])Out[109]: col_a col1 col2 col3a 2 0 1 2b 5 3 4 5c 8 6 7 8d 8 6 7 8 利用ix的标签索引功能重新索引：1234567In [111]: frame.ix[['a','b','c','d'],['col_a','col1','col2','col3']]Out[111]: col_a col1 col2 col3a NaN 0.0 1.0 2.0b NaN 3.0 4.0 5.0c NaN 6.0 7.0 8.0d NaN NaN NaN NaN 丢弃指定轴上的项使用drop方法删除指定轴上的项，只需要传入一个索引数组或列表，对于DataFrame可以传入指定的轴(axis)来进行删除,返回的都是删除轴之后的新对象:12345678910111213141516171819202122232425262728In [112]: obj = Series([1,2,3,4],index=['a','b','c','d'])In [113]: obj.drop('a')Out[113]:b 2c 3d 4dtype: int64In [114]: obj.drop(['a','b'])Out[114]:c 3d 4dtype: int64In [115]: frame = DataFrame(np.arange(9).reshape((3,3)),index=['a','b','c'],columns=['col1','col2','col3'])In [116]: frame.drop(['a','b'])Out[116]: col1 col2 col3c 6 7 8In [117]: frame.drop(['col1','col2'],axis=1)Out[117]: col3a 2b 5c 8 索引、选取和过滤Series索引(obj[……])的工作方式类似于NumPy数组的索引，并且可以使用非整数；而利用切片运算其 末端时包含的(封闭)：12345678910111213141516171819202122232425262728293031323334353637383940In [3]: obj = Series(np.arange(4), index=['a','b','c','d'])In [4]: objOut[4]:a 0b 1c 2d 3dtype: int64In [5]: obj['a']Out[5]: 0In [6]: obj[2:4]Out[6]:c 2d 3dtype: int64In [7]: obj['c':'d']Out[7]:c 2d 3dtype: int64In [8]: obj[['a','d']]Out[8]:a 0d 3dtype: int64In [9]: obj['b':'c']=5In [10]: objOut[10]:a 0b 5c 5d 3dtype: int64 对DataFrame进行索引是获取一个或多个列，可以通过切片或布尔型数组选取行，也可以使用布尔型DataFrame进行索引：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859In [15]: data = DataFrame(np.arange(16).reshape(4,4), ...: index=['a','b','c','d'], ...: columns=['col1','col2','col3','col4']) ...:In [16]: dataOut[16]: col1 col2 col3 col4a 0 1 2 3b 4 5 6 7c 8 9 10 11d 12 13 14 15In [17]: data['col1']Out[17]:a 0b 4c 8d 12Name: col1, dtype: int64In [18]: data[['col1','col4']]Out[18]: col1 col4a 0 3b 4 7c 8 11d 12 15In [19]: data[:2]Out[19]: col1 col2 col3 col4a 0 1 2 3b 4 5 6 7In [20]: data[data['col3']&gt;5]Out[20]: col1 col2 col3 col4b 4 5 6 7c 8 9 10 11d 12 13 14 15In [21]: data&lt;5Out[21]: col1 col2 col3 col4a True True True Trueb True False False Falsec False False False Falsed False False False FalseIn [22]: data[data&lt;5] = -5In [23]: dataOut[23]: col1 col2 col3 col4a -5 -5 -5 -5b -5 5 6 7c 8 9 10 11d 12 13 14 15 为了在DataFrame的行上进行标签索引，可以通过loc进行：123456789101112131415161718In [48]: data.loc['a',['col1','col2']]Out[48]:col1 -5col2 -5Name: a, dtype: int64In [49]: data.loc[['a','d'],['col1','col3']]Out[49]: col1 col3a -5 -5d 12 14In [50]: data.loc[data.col3&gt;5,:'col3']Out[50]: col1 col2 col3b -5 5 6c 8 9 10d 12 13 14 算术运算和数据对齐pandas可以对不同索引的对象进行算数运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是对该索引对的并集，自动的数据对齐操作在不重叠的索引处引入NA值，缺失值会在算术运算过程中传播:123456789101112131415161718192021222324252627282930In [55]: s1 = Series(np.arange(3),index=['a','b','c'])In [56]: s2 = Series(np.arange(3,9),index=['a','b','c','d','e','f'])In [57]: s1Out[57]:a 0b 1c 2dtype: int64In [58]: s2Out[58]:a 3b 4c 5d 6e 7f 8dtype: int64In [59]: s1+s2Out[59]:a 3.0b 5.0c 7.0d NaNe NaNf NaNdtype: float64 对于DataFrame，对齐操作会同时发生在行和列上，它们相加后会返回一个新的DataFrame，其索引和列为原来两个DataFrame的并集：123456789101112131415161718192021222324252627282930In [65]: df1 = DataFrame(np.arange(9).reshape(3,3),columns=list('abc'), ...: index=['row1','row2','row3']) ...:In [66]: df2 = DataFrame(np.arange(16).reshape(4,4),columns=list('abcd'), ...: index=['row1','row2','row3','row4']) ...:In [67]: df1Out[67]: a b crow1 0 1 2row2 3 4 5row3 6 7 8In [68]: df2Out[68]: a b c drow1 0 1 2 3row2 4 5 6 7row3 8 9 10 11row4 12 13 14 15In [69]: df1+df2Out[69]: a b c drow1 0.0 2.0 4.0 NaNrow2 7.0 9.0 11.0 NaNrow3 14.0 16.0 18.0 NaNrow4 NaN NaN NaN NaN 在算术方法中填充值 灵活的算术方法 方法 说明 add 用于加法(+)的方法 sub 用于减法(-)的方法 div 用于除法(/)的方法 mul 用于乘法(*)的方法 对于不同索引的对戏那个进行算术运算时，当一个对象中某个轴标签在另一个对象中找不到时填充一个特殊值,在对Series或DataFrame重新索引时也可以指定一个填充值：1234567891011121314In [76]: df2.add(df1,fill_value=0)Out[76]: a b c drow1 0.0 2.0 4.0 3.0row2 7.0 9.0 11.0 7.0row3 14.0 16.0 18.0 11.0row4 12.0 13.0 14.0 15.0In [77]: df1.reindex(columns=df2.columns,fill_value=0)Out[77]: a b c drow1 0 1 2 0row2 3 4 5 0row3 6 7 8 0 DataFrame和Series之间的运算默认情况下DataFrame和Series之间的算术运算会讲Series的索引匹配到DataFrame的列，然后沿着行一直向下广播；如果某个索引值在DataFrame的列货Series的索引中找不到，则参与运算的两个对象就会被重新索引译形成并集；如果希望匹配行且在列上广播则必须使用算术运算方法：1234567891011121314151617181920212223242526272829303132333435363738394041424344In [94]: s1 = df2.loc['row1']In [95]: df2Out[95]: a b c drow1 0 1 2 3row2 4 5 6 7row3 8 9 10 11row4 12 13 14 15In [96]: s1Out[96]:a 0b 1c 2d 3Name: row1, dtype: int64In [97]: df2-s1Out[97]: a b c drow1 0 0 0 0row2 4 4 4 4row3 8 8 8 8row4 12 12 12 12In [98]: s2 = Series(range(3),index=list('abf'))In [99]: df2-s2Out[99]: a b c d frow1 0.0 0.0 NaN NaN NaNrow2 4.0 4.0 NaN NaN NaNrow3 8.0 8.0 NaN NaN NaNrow4 12.0 12.0 NaN NaN NaNIn [100]: s3 = df2['a']Out[101]: a b c drow1 0 1 2 3row2 0 1 2 3row3 0 1 2 3row4 0 1 2 3 函数应用和映射NumPy的ufuncs(元素级数组方法)也可用于操作pandas对象:12345678910111213141516171819In [102]: frame = DataFrame(np.random.randn(4,3),columns=list('abc'), ...: index=['row1','row2','row3','row4']) ...:In [103]: frameOut[103]: a b crow1 0.755289 0.886977 -0.984527row2 0.460170 -0.514393 0.180462row3 0.828386 -0.545317 -1.176786row4 0.860822 -1.659938 0.952070In [104]: np.abs(frame)Out[104]: a b crow1 0.755289 0.886977 0.984527row2 0.460170 0.514393 0.180462row3 0.828386 0.545317 1.176786row4 0.860822 1.659938 0.952070 apply方法可以将函数应用到各列或行所形成的一维数组上，许多常见的数组统计功能都被实现成DataFrame方法(如sum和mean)，因此无需使用apply方法；除标量外，传递给apply的函数还可以返回多个值组成的Series；元素级的Python函数也是可以使用的，可以使用applymap得到frame中各个浮点值的格式化字符串:123456789101112131415161718192021222324252627282930313233343536In [112]: f = lambda x:x.max() -x.min()In [113]: frame.apply(f)Out[113]:a 0.400653b 2.546915c 2.128856dtype: float64In [114]: def f(x): ...: return Series([x.min(),x.max()],index=['min','max']) ...:In [115]: frame.apply(f)Out[115]: a b cmin 0.460170 -1.659938 -1.176786max 0.860822 0.886977 0.952070In [116]: format = lambda x: '%.2f' % xIn [117]: frame.applymap(format)Out[117]: a b crow1 0.76 0.89 -0.98row2 0.46 -0.51 0.18row3 0.83 -0.55 -1.18row4 0.86 -1.66 0.95In [118]: frame['a'].map(format)Out[118]:row1 0.76row2 0.46row3 0.83row4 0.86Name: a, dtype: object 排序和排名排序使用sort_index方法对行或列索引进行排序(按字典顺序)，它将返回一个已排序的对象；对于DataFrame则可以根据任意一个轴上的索引进行排序；数据默认时按升序进行排序的，可以设置ascending=False来降序排序：12345678910111213141516171819202122232425262728293031In [134]: obj = Series(range(4), index=list('dabc'))In [135]: obj.sort_index()Out[135]:a 1b 2c 3d 0dtype: int64In [136]: frame = DataFrame(np.arange(8).reshape((2,4)),index=['col2','col1'], ...: columns=list('badc')) ...:In [137]: frame.sort_index()Out[137]: b a d ccol1 4 5 6 7col2 0 1 2 3In [138]: frame.sort_index(axis=1)Out[138]: a b c dcol2 1 0 3 2col1 5 4 7 6In [139]: frame.sort_index(axis=1, ascending=False)Out[139]: d c b acol2 2 3 0 1col1 6 7 4 5 sort_values方法用于按值进行排序，在排序时，任何的缺失值默认都会放到Series的末尾：123456789In [144]: obj.sort_values()Out[144]:4 -3.05 2.00 4.02 7.01 NaN3 NaNdtype: float64 在DataFrame中，可以将一个或多个列的名字传递给by选项来根据一个或多个列中的值进行排序，要根据多个列进行排序，可以传入名称的列表：12345678910111213141516171819202122232425In [150]: frame = DataFrame(&#123;'b':[2,5,0,1],'a':[0,1,0,1]&#125;)In [151]: frameOut[151]: a b0 0 21 1 52 0 03 1 1In [152]: frame.sort_values(by='b')Out[152]: a b2 0 03 1 10 0 21 1 5In [153]: frame.sort_values(by=['a','b'])Out[153]: a b2 0 00 0 23 1 11 1 5 排名排名会增设一个排名值(从1开始，一直到数组中有效的数据的数量)，它可以根据某种规则破坏平级关系；rank是通过“为各组分配一个平均排名”的方式破坏平级关系1。 排名用于破坏平级关系的method的选项 method 说明 ‘average’ 默认：在相等分组中，为各个值分配平均排名 ‘min’ 使用整个分组的最小排名 ‘max’ 使用整个分组的最大排名 ‘first’ 按值在原始数据中的出现顺序分配排名 按降序进行排名使用ascending=False，其他的相似:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091In [9]: obj = Series([7,6,7,5,4,4,3])In [10]: obj.rank()Out[10]:0 6.51 5.02 6.53 4.04 2.55 2.56 1.0dtype: float64In [11]: obj.rank(method='min')Out[11]:0 6.01 5.02 6.03 4.04 2.05 2.06 1.0dtype: float64In [12]: obj.rank(method='max')Out[12]:0 7.01 5.02 7.03 4.04 3.05 3.06 1.0dtype: float64In [13]: obj.rank(method='first')Out[13]:0 6.01 5.02 7.03 4.04 2.05 3.06 1.0dtype: float64In [9]: obj = Series([7,6,7,5,4,4,3])In [10]: obj.rank()Out[10]:0 6.51 5.02 6.53 4.04 2.55 2.56 1.0dtype: float64In [11]: obj.rank(method='min')Out[11]:0 6.01 5.02 6.03 4.04 2.05 2.06 1.0dtype: float64In [12]: obj.rank(method='max')Out[12]:0 7.01 5.02 7.03 4.04 3.05 3.06 1.0dtype: float64In [13]: obj.rank(method='first')Out[13]:0 6.01 5.02 7.03 4.04 2.05 3.06 1.0dtype: float64 DataFrame可以在行或列上计算排名:12345678910111213141516171819202122In [15]: frame = DataFrame(&#123;'b':[1,3,-1],'a':[2,-1,-2],'c':[1,2,3]&#125;)In [16]: frameOut[16]: a b c0 2 1 11 -1 3 22 -2 -1 3In [17]: frame.rank(axis=0)Out[17]: a b c0 3.0 2.0 1.01 2.0 3.0 2.02 1.0 1.0 3.0In [18]: frame.rank(axis=1)Out[18]: a b c0 3.0 1.5 1.51 1.0 3.0 2.02 1.0 2.0 3.0 带有重复值的轴索引带有重复索引值的Series和DataFrame可以使用is_unique属性确认它是否唯一；对于带有重复值的索引，如果某个值对应多个值，则会返回一个Series(或DataFrame)；而对应单个值则返回一个标量(Series)：123456789101112131415161718192021222324252627282930313233343536373839404142434445In [19]: obj = Series(range(5),index=list('abbvd'))In [20]: objOut[20]:a 0b 1b 2v 3d 4dtype: int32In [21]: obj.index.is_uniqueOut[21]: FalseIn [22]: obj['a']Out[22]: 0In [23]: obj['b']Out[23]:b 1b 2dtype: int32In [24]: df = DataFrame(np.random.randn(4,3),index=['a','a','b','c'])In [26]: dfOut[26]: 0 1 2a 2.139973 0.102242 0.366141a -0.999559 0.324575 -0.808672b 1.121435 1.508694 1.151597c 0.610592 1.623871 -1.331131In [27]: df.loc['c']Out[27]:0 0.6105921 1.6238712 -1.331131Name: c, dtype: float64In [28]: df.loc['a']Out[28]: 0 1 2a 2.139973 0.102242 0.366141a -0.999559 0.324575 -0.808672 1.破坏平级关系是指在两个相同的数之间确认先后顺序。使用average表示如果在数组中7排在第五位和第六位，则其排名为5.5。min则为min(5,6)为5；max则为max(5,6)为7；first则表示在原数据中先出现排序靠前，紧邻的+1，依次递增。 ↩]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas入门(一)]]></title>
    <url>%2F2018%2F03%2F19%2Fpandas%E5%85%A5%E9%97%A8-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[SeriesSeries1 是一种类似于一维数组的对象，它由一组数据(各种NumPy数据类型)以及一组与之相关的数据标签(即索引)组成。Series的字符串表现形式为：索引在左边，值在右边。如果没有为数据指定索引，会自动创建一个0到n-1的整数型索引。可以通过index参数指定索引来代替自动生成的索引:12345678910111213141516171819In [4]: ser1 = Series([1,2,2,3])In [5]: ser1Out[5]:0 11 22 23 3dtype: int64In [6]: ser2 = Series([1,2,2,3],index=['a','b','c','d'])In [7]: ser2Out[7]:a 1b 2c 2d 3dtype: int64 可以通过索引的方式选取Series中的单个或一组值；数组运算(布尔型数组进行过滤，标量乘法，应用数学函数)都会保留索引和值之间的连接；Series可以看成是一个定长的有序字典，可以用在原本需要字典参数的函数中:1234567891011121314151617181920212223242526272829In [8]: ser2['a']Out[8]: 1In [9]: ser2[['a','b']]Out[9]:a 1b 2dtype: int64In [10]: ser2*2Out[10]:a 2b 4c 4d 6dtype: int64In [11]: ser2[ser2&gt;=2]Out[11]:b 2c 2d 3dtype: int64In [12]: 'a' in ser2Out[12]: TrueIn [13]: 'g' in ser2Out[13]: False 可以直接通过字典来创建Series，则Series中的索引就是原字典的键(有序列表)，如果键对应的值找不到，将会是使用NA表示缺失数据,pandas的isnull和notnull函数可用于检测缺失数据：123456789101112131415161718192021In [14]: dic = &#123;'a':1,'b':2,'c':3&#125;In [15]: dics = Series(dic)In [16]: dicsOut[16]:a 1b 2c 3dtype: int64In [17]: states = ['a','b','c','d']In [18]: dicstates = Series(dic,index=states)In [19]: dicstatesOut[19]:a 1.0b 2.0c 3.0d NaN Series在算数运算中会自动对齐不同索引的数据：12345678910111213141516171819202122In [20]: dicsOut[20]:a 1b 2c 3dtype: int64In [21]: dicstatesOut[21]:a 1.0b 2.0c 3.0d NaNdtype: float64In [22]: dics+dicstatesOut[22]:a 2.0b 4.0c 6.0d NaNdtype: float64 Series本身及其索引有一个name属性，同时Series的索引可以通过赋值的方式就地修改:1234567891011121314151617181920In [23]: dics.name='dics'In [24]: dics.index.name='letter'In [25]: dicsOut[25]:lettera 1b 2c 3Name: dics, dtype: int64In [26]: dics.index=['z','x','y']In [27]: dicsOut[27]:z 1x 2y 3Name: dics, dtype: int64 DataFrame构造DataFrame 可以输入给DataFrame构造器的数据 类型 说明 二维ndarray 数据矩阵，还可以传入行标和列标 由数组、列标或元组组成的字典 每个序列会变成DataFrame的一列，所有序列的长度必须相同 NumPy的结构化/记录数组 类似于“由数组组成的字典” 由Series组成的字典 每个Series会成为一列。如果没有显示指定索引，则个Series的索引会被合并成结果的行索引 由字典组成的字典 各内层字典会成为一列。键会被合并成结果的行索引，跟“由Series组成的字典”情况一样 字典或Series的列表 各项将会成为DataFrame的一行。字典键或Series索引的并集将会成为DataFrame的列标 另一个DataFrame 该DataFrame的索引将会被沿用，除非显式指定了其他索引 NumPy的MaskedArray 类似于“二维ndarray”的情况，只是掩码值在结果DataFrame会编程NA/缺失值 DataFrame 是一个表格型的数据结构。它含有一组有序的列，每列可以是不同的值类型(数值、字符串、布尔值等)。DataFrame既有行索引也有列索引，它可以被看做由Series组成的字典(共同用一个索引)，DataFrame面向行和面向列的操作基本上是平衡的。构建DataFrame可以通过直接传入一个由等长列表或NumPy数组组成的字典，和Series一样DataFrame也会自动加上索引且全部列会被有序排列，如果指定了列索引，则DataFrame的列会按照指定顺序进行排列。如果传入的列在数据中找不到，会产生NA值：123456789101112131415161718192021222324In [30]: data =&#123;'state':['a','b','c','d'], ...: 'year':[2000,2001,2002,2003], ...: 'pop':[1,2,3,4]&#125;In [31]: frame = DataFrame(data)In [32]: frameOut[32]: pop state year0 1 a 20001 2 b 20012 3 c 20023 4 d 2003In [34]: DataFrame(data,columns=['year','pop','state','debt'],index=['i1','i2','i3','i4'])Out[34]: year pop state debti1 2000 1 a NaNi2 2001 2 b NaNi3 2002 3 c NaNi4 2003 4 d NaNIn [35]: frame.columnsOut[35]: Index(['pop', 'state', 'year'], dtype='object') 可以通过字典标记的方式或属性的方式将DataFrame的列获取为一个Series，返回的Series拥有原DataFrame相同的索引，且其name属性已经被相应地设置好了。行也可以通过位置或名称的方式进行获取，比如用索引字段ix:12345678910111213141516171819202122In [40]: frame.stateOut[40]:0 a1 b2 c3 dName: state, dtype: objectIn [41]: frame['year']Out[41]:0 20001 20012 20023 2003Name: year, dtype: int64In [42]: frame.ix[1]Out[42]:pop 2state byear 2001Name: 1, dtype: object 列可以通过赋值的方式进行修改，将列表或数组给某个列时，其长度必须跟DataFrame的长度相匹配。如果赋值的事一个Series就会精确匹配DataFrame的索引，所有的空位都将被填上缺失值，为不存在的列赋值会创建出一个新列，关键字del可以删除列:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061In [49]: frame2=DataFrame(data,columns=['year','pop','state','debt'],index=['i1','i2','i3','i4'])In [50]: frame2Out[50]: year pop state debti1 2000 1 a NaNi2 2001 2 b NaNi3 2002 3 c NaNi4 2003 4 d NaNIn [51]: frame2['debt']=np.arange(4.)In [52]: frame2Out[52]: year pop state debti1 2000 1 a 0.0i2 2001 2 b 1.0i3 2002 3 c 2.0i4 2003 4 d 3.0In [53]: frame2=DataFrame(data,columns=['year','pop','state','debt'],index=['i1','i2','i3','i4'])In [54]: frame2Out[54]: year pop state debti1 2000 1 a NaNi2 2001 2 b NaNi3 2002 3 c NaNi4 2003 4 d NaNIn [55]: val = Series([-1,-2,-3],index=['i1','i3','i4'])In [56]: frame2['debt']=valIn [57]: frame2Out[57]: year pop state debti1 2000 1 a -1.0i2 2001 2 b NaNi3 2002 3 c -2.0i4 2003 4 d -3.0In [58]: frame2['big']= frame2['pop']&gt;=3In [59]: frame2Out[59]: year pop state debt bigi1 2000 1 a -1.0 Falsei2 2001 2 b NaN Falsei3 2002 3 c -2.0 Truei4 2003 4 d -3.0 TrueIn [60]: del frame2['big']In [61]: frame2Out[61]: year pop state debti1 2000 1 a -1.0i2 2001 2 b NaNi3 2002 3 c -2.0i4 2003 4 d -3.0 嵌套字典被传给DataFrame后会被解释为：外层字典的键作为列，内层字典键作为行索引，可以通过T进行转置。内层字典的键会被合并，排序以形成最终的索引。如果现实指定了索引，就不会如此。同理，Series组成的字典也是一样的用法:123456789101112131415161718192021222324252627282930313233In [63]: pop = &#123;'out1':&#123;2002:1.1,2001:1.2&#125;, ...: 'out2':&#123;2001:1.3,2004:1.4&#125;&#125;In [64]: frame3 = DataFrame(pop)In [65]: frame3Out[65]: out1 out22001 1.2 1.32002 1.1 NaN2004 NaN 1.4In [66]: frame3.TOut[66]: 2001 2002 2004out1 1.2 1.1 NaNout2 1.3 NaN 1.4In [67]: DataFrame(pop,index=[2002,2001,2004])Out[67]: out1 out22002 1.1 NaN2001 1.2 1.32004 NaN 1.4In [68]: sData = &#123;'out1':frame3['out1'][:-1], ...: 'out2':frame3['out2'][:-1]&#125;In [69]: DataFrame(sData)Out[69]: out1 out22001 1.2 1.32002 1.1 NaN 设置了DataFrame的index和columns的name属性，这些信息将会被显示出来，values属性会以二维ndarray的形式返回DataFrame中的数据，如果DataFrame各列的数据类型不同，则值数组的数据类型就会选用能兼容所有列的数据类型：123456789101112131415161718192021222324In [70]: frame3.index.name='year'In [71]: frame3.columns.name='state'In [72]: frame3Out[72]:state out1 out2year2001 1.2 1.32002 1.1 NaN2004 NaN 1.4In [73]: frame3.valuesOut[73]:array([[ 1.2, 1.3], [ 1.1, nan], [ nan, 1.4]])In [74]: frame2.valuesOut[74]:array([[2000, 1, 'a', -1.0], [2001, 2, 'b', nan], [2002, 3, 'c', -2.0], [2003, 4, 'd', -3.0]], dtype=object) 索引对象pandas的索引对象负责管理轴标签和其他元数据。 pandas中主要的Index对象 类 说明 Index 最泛化的Index对象，将轴标签表示为一个由Python对象组成的NumPy数组 Int64Index 针对整数的特殊Index MultiIndex “层次化”索引对象，表示单个轴上的多层索引。可以看做由元组组成的数组 DatetimeIndex 存储纳秒级时间戳(用NumPy的datetime64类型表示) PeriodIndex 针对Period数据(时间间隔)的特殊Index Index的方法和属性 方法 说明 append 连接另一个Index对象，产生一个新的Index diff 计算差集，并得到一个Index intersection 计算交集 union 计算并集 isin 计算一个指示各值是否都包含在参数集合中的布尔型数组 delete 删除索引i处的元素，并得到新的Index drop 删除传入的值，并得到新的Index insert 将元素插入到索引i处，并得到新的Index is_monotonic 当各元素均大于等于前一个元素时，返回True is_unique 当Index没有重复值时，返回True unique 计算Index中唯一值的数组 构建Series或DataFrame时，所得到的任何数组或其他序列的标签都会被转换成一个Index，Index对象是 不可修改的，这使得Index对象在多个数据结构之间安全共享。除了长得像数组，Index的功能也类似与一个固定大小的集合，每个索引都有一些方法和属性，它们用于设置逻辑并回答有关索引所包含数据的常见问题:123456789101112131415161718192021222324252627282930In [76]: obj = Series(range(3),index=['a','b','c'])In [77]: index =obj.indexIn [78]: indexOut[78]: Index(['a', 'b', 'c'], dtype='object')In [79]: index[:-1]Out[79]: Index(['a', 'b'], dtype='object')In [80]: inde=pd.Index(np.arange(3))In [81]: obj2=Series(['a','b','c'],index=inde)In [82]: obj2.index is indeOut[82]: TrueIn [83]: frame3Out[83]:state out1 out2year2001 1.2 1.32002 1.1 NaN2004 NaN 1.4In [84]: 'out1' in frame3.columnsOut[84]: TrueIn [85]: 2005 in frame3.indexOut[85]: False 1.使用 from pandas import Series, DataFrame和 import pandas as pd引入相关的包 ↩]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy基础(二)]]></title>
    <url>%2F2018%2F03%2F17%2Fnumpy%E5%9F%BA%E7%A1%80-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[通用函数通用函数(即ufunc)是一种对ndarray中的数据执行元素级运算的函数。它是简单函数(接受一个或多个标量值，并产生一个或多个标量值)的矢量化包装器。 一元ufunc 函数 说明 abs、fabs 计算整数、浮点数或复数的绝对值。对于非复数值，可以使fabs sqrt 计算各元素的平方根。相当于arr**0.5 square 计算各元素的平方。相当于arr**2 exp 计算各元素的指数e^x log、log10、log2、log1p 分别对自然对数(底为e)、底为10的log、底为2的log、log(1+x) sign 计算各元素的正负号:1(正数)、0(零)、-1(负数) ceil 计算各元素的ceiling值，即大于等于该值的最小整数 floor 计算各元素的floor值，即小于等于该值的最大整数 rint 将各元素四舍五入到最接近的整数，保留dtype modf 将数组的小数和整数部分以独立数组的形式返回 isnan 返回一个表示“哪些值是NaN(这不是一个数字)”的布尔型数组 isfinite、isinf 分别返回一个表示“哪些元素是有穷的(非inf、非NaN)”或“哪些元素是无穷的”布尔型数组 cos、cosh、sin、sinh、tan、tanh 普通型和双曲型三角函数 arccos、arccosh、arcsin、arcsinh、arctan、arctanh 反三角函数 logical_not 计算各元素not x的真值。相当于-arr 二元ufunc 函数 说明 add 将数组中对应的元素相加 subtract 从第一个数组中减去第二个数组中的元素 multiply 数组元素相乘 divide、floor_divide 除法或向下圆整除法(丢弃余数) power 对第一个数组中的元素A，根据第二个数组中的相应元素B，计算A^B maximum、fmax 元素级的最大值计算。fmax将忽略NaN minimum、fmin 元素级的最小值计算。fmin将忽略NaN mod 元素级的求模计算(除法的余数) copysign 将第二个数组中的值的符号复制给第一个数组中的值 greater、greater_equal、less、less_equal、equal、not_equal 执行元素级的比较运算，最终产生布尔型数组。相当于中缀运算符&gt;、&gt;=、&lt;、&lt;=、==、!= logical_and、logical_or、logical_xor 执行元素级的真值逻辑运算。相当于中缀运算符&amp;、&#124;、^ 许多ufunc都是简单的元素级变体，一元的ufunc接受一个数组，二元的接受两个并返回一个结果数组：123456789101112131415161718192021222324252627282930In [2]: arr = np.arange(10)In [3]: arrOut[3]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])In [4]: np.sqrt(arr)Out[4]:array([0. , 1. , 1.41421356, 1.73205081, 2. , 2.23606798, 2.44948974, 2.64575131, 2.82842712, 3. ])In [5]: np.exp(arr)Out[5]:array([1.00000000e+00, 2.71828183e+00, 7.38905610e+00, 2.00855369e+01, 5.45981500e+01, 1.48413159e+02, 4.03428793e+02, 1.09663316e+03, 2.98095799e+03, 8.10308393e+03])In [6]: x = randn(5)In [7]: y = randn(5)In [8]: xOut[8]:array([-9.27415622e-01, -1.67964296e-03, -1.91023663e+00, -1.31307986e-01, -1.17927352e+00])In [9]: yOut[9]: array([ 0.82239493, 0.43695129, -0.00905311, 0.31991891, -0.34529735])In [10]: np.maximum(x,y)Out[10]: array([ 0.82239493, 0.43695129, -0.00905311, 0.31991891, -0.34529735]) 利用数组进行数据处理矢量化 将数据处理任务表述为简洁的数组表达式，用数组表达式代替循环。例如计算函数sqrt(x^2+y^2)。np.meshgrid接受两个一维数组，并产生两个二维矩阵(对应两个数组中所有(x,y)对):12345678910111213141516171819202122232425262728293031In [11]: points = np.arange(-5, 5, 0.01)In [12]: xs, ys = np.meshgrid(points,points)In [13]: xsOut[13]:array([[-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], ..., [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99]])In [14]: z = np.sqrt(np.square(xs)+np.square(ys))In [15]: zOut[15]:array([[7.07106781, 7.06400028, 7.05693985, ..., 7.04988652, 7.05693985, 7.06400028], [7.06400028, 7.05692568, 7.04985815, ..., 7.04279774, 7.04985815, 7.05692568], [7.05693985, 7.04985815, 7.04278354, ..., 7.03571603, 7.04278354, 7.04985815], ..., [7.04988652, 7.04279774, 7.03571603, ..., 7.0286414 , 7.03571603, 7.04279774], [7.05693985, 7.04985815, 7.04278354, ..., 7.03571603, 7.04278354, 7.04985815], [7.06400028, 7.05692568, 7.04985815, ..., 7.04279774, 7.04985815, 7.05692568]]) 将条件逻辑表述为数组运算np.where是三元表达式x if condition else y的矢量化版本。np.wehere接受三个参数cond、xarr、yarr,当判定cond为true时选择执行xarr否则执行yarr。因此np.where也可以嵌套使用。np.where的第二个和第三个参数不必时数组，可以是标量值。where通常用于根据另一个数组产生新的数组。1234567891011121314151617181920212223242526272829303132333435363738In [23]: xarr = np.array([0.1,0.2,0.3])In [24]: yarr = np.array([1.1,1.2,1.3])In [25]: cond = np.array([True,False,True])In [26]: result = np.where(cond,xarr,yarr)In [27]: resultOut[27]: array([0.1, 1.2, 0.3])In [28]: arr = randn(4,4)In [29]: arrOut[29]:array([[ 0.17276546, -1.27954884, -0.07326268, -2.40995669], [-0.15796552, -1.85102248, 0.53499154, -0.1332765 ], [ 0.81853502, 1.35768841, 1.55543773, 1.01407613], [-1.05967769, 0.39289449, 0.13509303, -0.68143339]])In [30]: np.where(arr&gt;0,1,-1)Out[30]:array([[ 1, -1, -1, -1], [-1, -1, 1, -1], [ 1, 1, 1, 1], [-1, 1, 1, -1]])In [31]: np.where(arr&gt;0,1,arr)Out[31]:array([[ 1. , -1.27954884, -0.07326268, -2.40995669], [-0.15796552, -1.85102248, 1. , -0.1332765 ], [ 1. , 1. , 1. , 1. ], [-1.05967769, 1. , 1. , -0.68143339]])In [32]: cond2 = np.array([False,False,True])In [33]: np.where(cond&amp;cond2,0,np.where(cond,1,np.where(cond,2,3)))Out[33]: array([1, 3, 0]) 数学和统计方法可以通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计。sum、mean以及标准差std等聚合计算(aggregation)既可以当做数组的实例方法调用，也可以当做顶级NumPy函数使用。 基本数组统计方法 方法 说明 sum 对数组中全部或某轴向的元素求和。零长度的数组的sum为0 mean 算数平均数。零长度的数组的mean为NaN std、var 分别为标准差和方差，自由度可调(默认为n) argmin、argmax 分别为最大和最小元素的索引 cumsum 所有元素的累计和 cumprod 所有元素的累计积 mean和sum这类的函数接受一个axis参数(用于计算该轴向上的统计值)，最终结果是一个少一维的数组:123456789101112131415161718In [36]: arr = np.random.randn(5,4)In [37]: arrOut[37]:array([[-0.00502805, 0.23545272, 0.04886622, -0.46971953], [-1.08918278, 1.19958904, -0.54808552, -1.60148873], [-0.60059372, -0.9743709 , 1.39660621, -0.97132217], [-0.11917925, 1.99922758, -1.58943388, 1.60237969], [-0.28361465, -2.57463163, -0.96786527, -0.00376026]])In [38]: arr.mean()Out[38]: -0.26580774446749256In [39]: np.mean(arr)Out[39]: -0.26580774446749256In [40]: arr.mean(axis=1)Out[40]: array([-0.04760716, -0.509792 , -0.28742014, 0.47324854, -0.95746796]) cumsum和cumprod之类的方法不聚合，而是产生一个由中间结果组成的数组：12345678910111213141516171819202122232425In [47]: arr = np.array([[0,1,2],[3,4,5],[6,7,8]])In [48]: arr.cumsum(0)Out[48]:array([[ 0, 1, 2], [ 3, 5, 7], [ 9, 12, 15]])In [49]: arr.cumsum(1)Out[49]:array([[ 0, 1, 3], [ 3, 7, 12], [ 6, 13, 21]])In [50]: arr.cumprod(0)Out[50]:array([[ 0, 1, 2], [ 0, 4, 10], [ 0, 28, 80]])In [51]: arr.cumprod(1)Out[51]:array([[ 0, 0, 0], [ 3, 12, 60], [ 6, 42, 336]]) 用于布尔型数组的方法上面罗列的方法中，布尔值会被强制转换为1(True)和0(False)。所以sum可以用来对布尔型数组中的True值计数。而any方法用来测试数组中是否存在一个或多个True，all用来检查数组中所有值是否都是True：123456789101112In [52]: arr = randn(20)In [53]: (arr &gt; 0).sum()Out[53]: 11In [54]: bools=np.array([False,True,False])In [55]: bools.any()Out[55]: TrueIn [56]: np.all(bools)Out[56]: False 排序NumPy数组通过sort方法就地排序，多维数组可以在任何一个轴向上进行排序，只需将轴编号传给sort。顶级方法np.sort返回的是数组的已排序副本，而就地排序则会修改数组本身：123456789101112131415161718192021222324252627282930313233343536373839In [57]: arr = randn(6)In [58]: arrOut[58]:array([ 0.20563118, -0.6733116 , -1.44713961, 0.49352122, 0.73564391, 1.71627219])In [59]: arr.sort()In [60]: arrOut[60]:array([-1.44713961, -0.6733116 , 0.20563118, 0.49352122, 0.73564391, 1.71627219])In [61]: arr = rand(5,3)In [62]: arrOut[62]:array([[0.18125744, 0.10766187, 0.46160903], [0.34363544, 0.28353683, 0.06096776], [0.52424935, 0.13756835, 0.78614215], [0.12944147, 0.95273729, 0.09078996], [0.85118943, 0.18928544, 0.23857278]])In [63]: np.sort(arr,1)Out[63]:array([[0.10766187, 0.18125744, 0.46160903], [0.06096776, 0.28353683, 0.34363544], [0.13756835, 0.52424935, 0.78614215], [0.09078996, 0.12944147, 0.95273729], [0.18928544, 0.23857278, 0.85118943]])In [64]: arrOut[64]:array([[0.18125744, 0.10766187, 0.46160903], [0.34363544, 0.28353683, 0.06096776], [0.52424935, 0.13756835, 0.78614215], [0.12944147, 0.95273729, 0.09078996], [0.85118943, 0.18928544, 0.23857278]]) 唯一化及其他集合逻辑NumPy提供了一些针对一维ndarray的基本集合运算。 数组的集合运算 方法 说明 unique(x) 计算x中的唯一元素，并返回有序结果 intersect1d(x,y) 计算x和y中的公共元素，并返回有序结果 union1d(x,y) 计算x和y的并集，并返回有序结果 in1d(x,y) 得到一个表示“x的元素是否包含于y”的布尔型数组 setdiff1d(x,y) 集合的差，即元素在x中且不在y中 setxor1d(x,y) 集合的对称差，即存在于一个数组中单不同时存在于两个数组中的元素(异或) 12In [66]: np.unique(names)Out[66]: array(['Jim', 'Tom', 'bob'], dtype='&lt;U3') 用于数组的文件输入输出将数组以二进制格式保存到磁盘np.save和np.load是读写磁盘数组数据的两个组药函数。默认情况下数组以未压缩的原始二进制格式保存在扩展名为 .npy 的文件中。np.savez可以将多个数组保存到一个压缩文件中，将数组以关键字参数的形式传入即可。加载 .npz 文件时，将会得到一个类似字典的对象，该对象对各个数组进行延迟加载:12345678910111213In [68]: arr = np.arange(10)In [69]: np.save('arr',arr)In [70]: np.load('arr.npy')Out[70]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])In [71]: np.savez('arr_more',a=arr,b=arr)In [72]: arr_more = np.load('arr_more.npz')In [73]: arr_more['a']Out[73]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 线性代数 numpy.linalg函数 函数 说明 diag 以一维数组的形式返回方阵的对角线(或非对角线)元素，或将一维数组转换为方阵(非对角线元素为0) dot 矩阵乘法 trace 计算对角线的和 det 计算矩阵行列式 eig 计算方阵的特征值和特征向量 inv 计算方阵的逆 pinv 计算矩阵的Moore-Penrose伪逆 qr 计算QR分解 svd 计算奇异值分解(SVD) solve 解线性方程组Ax=b，其中A为一个方阵 lstsq 计算Ax=b的最小二乘解 1234567891011121314151617181920212223242526272829303132333435363738394041In [83]: x = randn(3,3)In [84]: xOut[84]:array([[ 0.45880764, -0.90269718, -1.62963467], [-0.76727739, 2.24799683, 0.65118256], [ 0.43217346, -2.47319723, -0.48442667]])In [85]: mat = x.T.dot(x)In [86]: matOut[86]:array([[ 0.98599295, -3.20785172, -1.45668284], [-3.20785172, 11.9850565 , 4.13300564], [-1.45668284, 4.13300564, 3.31441709]])In [87]: inv(mat)Out[87]:array([[16.03043111, 3.2650856 , 2.97386734], [ 3.2650856 , 0.8114194 , 0.42317945], [ 2.97386734, 0.42317945, 1.08102824]])In [88]: matOut[88]:array([[ 0.98599295, -3.20785172, -1.45668284], [-3.20785172, 11.9850565 , 4.13300564], [-1.45668284, 4.13300564, 3.31441709]])In [89]: mat.dot(inv(mat))Out[89]:array([[ 1.00000000e+00, -1.71619808e-16, 2.22044605e-16], [ 1.06801676e-14, 1.00000000e+00, 0.00000000e+00], [ 3.55271368e-15, 8.88178420e-16, 1.00000000e+00]])In [90]: q,r = qr(mat)In [91]: rOut[91]:array([[-3.65847231, 13.01900838, 5.33621718], [ 0. , -1.23249681, 1.27109691], [ 0. , 0. , 0.31324131]]) 随机数生成 部分numpy.random函数 函数 说明 seed 确定随机数生成器的种子 permutation 返回一个序列的随机排列或返回一个随机排列的范围 shuffle 对一个序列就地随机排序 rand 产生均匀分布的样本值 randint 从给定的上下限范围内随机选取整数 randn 产生正态分布(平均值为0，标准差为1)的样本值 normal 产生正态(高斯)分布的样本值 binomial 产生二项分布的样本值 beta 产生Beta分布的样本值 chisquare 产生卡方分布的样本值 gamma 产生Gamma分布的样本值 uniform 产生在[0,1）中均匀分布的样本值 随机漫步使用np.random模块一次性产生1000个“掷硬币”结果(即两个数中任选一个),将其分别设置为1或-1，然后计算累计和,然后可以做求取最大值最小值的简单统计：12345678910111213In [96]: nsteps = 1000In [97]: draws = np.random.randint(0, 2, size=nsteps)In [98]: steps = np.where(draws&gt;0,1,-1)In [99]: walk = steps.cumsum()In [101]: walk.min()Out[101]: -24In [102]: walk.max()Out[102]: 9 然后可以计算首次穿越时间，即随机漫步过程中第一次到达某个特定值的时间。使用np.abs(walk)&gt;=10得到一个布尔型数组，它表示的距离是否达到或超过10，使用argmax(并不高效，会对数组进行完全扫描)找到布尔型数组第一个最大值索引(True就是最大值):12In [103]: (np.abs(walk)&gt;=10).argmax()Out[103]: 107 一次模拟多个随机漫步通过给numpy.random函数传入一个二元元组产生一个二维数组,然后使用累计和创建随机漫步过程(一行一个)，接着计算最大值和最小值。得到这些数据后来计算30或-30的最小穿越时间。因为不是5000个都达到了30，所以使用any进行检查，然后利用检查后的布尔数组选出哪些穿越了30(绝对值)的随机漫步(行)，并调用argmax在轴1上获取穿越时间1234567891011121314151617181920212223242526272829303132333435363738In [104]: nwalks = 5000In [105]: nsteps = 5000In [106]: draws = np.random.randint(0,2,size=(nwalks,nsteps))In [107]: steps = np.where(draws&gt;0,1,-1)In [108]: walks = steps.cumsum(1)In [109]: walksOut[109]:array([[ -1, -2, -1, ..., 20, 19, 18], [ -1, 0, 1, ..., 16, 17, 18], [ -1, 0, 1, ..., 80, 79, 78], ..., [ 1, 2, 3, ..., 6, 5, 6], [ 1, 0, -1, ..., -130, -131, -132], [ 1, 0, 1, ..., -16, -17, -16]])In [110]: walks.max()Out[110]: 255In [111]: walks.min()Out[111]: -235In [112]: hits30 = (np.abs(walks)&gt;=30).any(1)In [113]: hits30Out[113]: array([ True, True, True, ..., True, True, True])In [115]: hits30.sum()Out[115]: 4992In [117]: crossing_time =(np.abs(walks[hits30])&gt;=30).argmax(1)In [118]: crossing_time.mean()Out[118]: 883.0564903846154]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy基础(一)]]></title>
    <url>%2F2018%2F03%2F16%2Fnumpy%E5%9F%BA%E7%A1%80-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[NumPy1的部分功能如下： ndarray，一个具有矢量运算和复杂广播能力的快熟且节省空间的多维数组 用于对数组数据进行快速运算的标准数学函数 线性代数、随机数生成及傅里叶变换功能 用于集成C、C++、Fortran等语言编写的代码的工具 对于大部分数据分析应用，关注的功能集中在： 用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算 常用的数组算法，如排序、唯一化、集合运算等 高效的描述统计和数据聚合/摘要运算 用于异构数据集的合并/连接运算的数据对齐和关系型数据运算 将条件逻辑表述为数组表达式(而不是带有if-ekif-else分支的循环) 数据的分组运算(聚合、转换、函数应用等) 多维数组对象(ndarray)N维数组对象(即ndarray)是一个快速而灵活的大数据集容器。可以利用这种数组执行一些数学运算，语法和标量元素之间的运算一样：12345678910111213141516In [4]: data = np.array([[1,2,3],[3,4,5]])In [5]: dataOut[5]:array([[1, 2, 3], [3, 4, 5]])In [6]: data*10Out[6]:array([[10, 20, 30], [30, 40, 50]])In [7]: data+dataOut[7]:array([[ 2, 4, 6], [ 6, 8, 10]]) 创建ndarrayarray函数是创建数组最简单的方法，它接受一切序列型的对象(包括其他数组)，然后产生一个新的含有传入数据的NumPy数组。 数组创建函数 函数 说明 array 将输入数据(列表、元组或其他序列类型)转换为ndarray。要么推断出dtype，要么显示指定dtype。默认直接复制输入数据 asarray 将输入转换为ndarray，如果输入本身就是一个ndarray就不进行复制 arange 类似于内置的range，但返回的是一个ndarray而不是列表 ones、ones_like 根据指定的形状和dtype创建一个全1数组。ones_like以另一个数组为参数，并根据其形状和dtype创建一个全1数组 zeros、zeros_like 类似于ones、ones_like，产生全0数组 empty、empty_like 创建新数组，只分配内存空间但不填充任何值 eye、identity 创建一个正方的NXN单位矩阵(对角线为1，其余为0) 列表转换 1234In [8]: arr1 = np.array([1,2,3])In [9]: arr1Out[9]: array([1, 2, 3]) 嵌套序列将会被转换为一个多维数组: 123456In [10]: arr2 = np.array([[1,2,3],[1,2,3]])In [11]: arr2Out[11]:array([[1, 2, 3], [1, 2, 3]]) 除非显式说明，np.array会尝试为新建的数组推断一个合适的数据类型。数据类型保存在一个特殊的dtype对象中:12In [12]: arr1.dtypeOut[12]: dtype('int32') 除了np.array之外，zeros和ones可以创建指定长度或形状的全0或全1数组。empty可以创建一个没有任何具体值的数组。使用这些方法创建数组，只需传入一个表示形状的元组:12345678910111213141516171819In [15]: np.zeros(10)Out[15]: array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])In [16]: np.zeros((3,2))Out[16]:array([[ 0., 0.], [ 0., 0.], [ 0., 0.]])In [17]: np.empty((3,2,3))Out[17]:array([[[ 6.23042070e-307, 4.67296746e-307, 1.69121096e-306], [ 1.33511290e-306, 1.15711989e-306, 1.42418987e-306]], [[ 1.37961641e-306, 1.60220528e-306, 1.24611266e-306], [ 9.34598925e-307, 1.24612081e-306, 1.11260755e-306]], [[ 1.60220393e-306, 1.51320640e-306, 9.34609790e-307], [ 1.86921279e-306, 1.24610723e-306, 0.00000000e+000]]]) 使用empty方法创建的数组返回的是一些未初始化的垃圾值，而不是0arange是Python内置函数range的数组版:12In [18]: np.arange(5)Out[18]: array([0, 1, 2, 3, 4]) ndarray的数据类型 NumPy的数据类型 类型 类型代码 说明 int8、uint8 i1、u1 有符号和无符号的8位(1个字节)整型 int16、uint16 i2、u2 有符号和无符号的18位(2个字节)整型 int32、uint32 i4、u4 有符号和无符号的32位(4个字节)整型 int64、uint64 i8、u8 有符号和无符号的64位(8个字节)整型 float16 f2 半精度浮点数 float32 f4或f 标准的单精度浮点数。与C的float兼容 float64 f8或d 标准的双精度浮点数。与C的double和Python的float对象兼容 float128 f16或g 扩展精度浮点数 complex64、complex128、complex256 c32 复数 bool ? 存储True和False的布尔类型 object O Python对象类型 string_ S 固定长度的字符串类型(每个字符1个字节)。例如要创建一个长度为10的字符串，应使用S10 unicode_ U 固定长度的unicode类型(字节数由平台决定)。跟字符串的定义方式一样(如U10) 可以再创建array对象时使用dtype参数设定数据类型，也可以通过astype方法显示转换其dtype,如果将浮点数转换成整数，则小数部分将会被截断；如果字符串数组全是数字，也可以用astype将其转换为数值形式：123456789101112In [19]: arr = np.array([1.2,-3.4,5.6], dtype='f8')In [20]: arr.dtypeOut[20]: dtype('float64')In [21]: arr.astype(np.int32)Out[21]: array([ 1, -3, 5])In [22]: numeric_string = np.array(['1.5','2.5','1.1'],dtype=np.string_)In [23]: numeric_string.astype(np.float64)Out[23]: array([ 1.5, 2.5, 1.1]) 数组和标量之间的运算矢量化 是指数组不用编写任何循环即可对数据执行批量运算。大小相等的数组之间的任何算术运算都会将运算应用到元素级：1234567891011In [24]: arr = np.array([[1,1,1],[2,2,2]])In [25]: arr*arrOut[25]:array([[1, 1, 1], [4, 4, 4]])In [26]: arr+arrOut[26]:array([[2, 2, 2], [4, 4, 4]]) 数组和标量的运算会将标量值传播到各个元素:123456789In [27]: 1/arrOut[27]:array([[ 1. , 1. , 1. ], [ 0.5, 0.5, 0.5]])In [28]: arr ** 0.5Out[28]:array([[ 1. , 1. , 1. ], [ 1.41421356, 1.41421356, 1.41421356]]) 基本的索引和切片将一个标量赋值给一个切片时。改值会自动传播到整个选区。跟列表最重要的区别在于数组切片是原始数组的视图。这说明数据不会被复制，视图上的任何修改都会直接反映到原数组上:2 1234567891011121314151617In [35]: arr = np.arange(10)In [36]: arrOut[36]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])In [37]: arr_slice = arr[2:5]In [38]: arr_sliceOut[38]: array([2, 3, 4])In [39]: arr_slice[1:2] = 1000In [40]: arrOut[40]: array([ 0, 1, 2, 1000, 4, 5, 6, 7, 8, 9])In [41]: arr_sliceOut[41]: array([ 2, 1000, 4]) 对于高维数组，各索引的位置上的元素不在是标量，而是降维数组，索引对各个元素进行递归访问。对二维数组而言，一级索引对应的事一维数组，二级索引对应的是一维数组下的元素索引(这里一维数组的元素是标量),索引有两种方式:123456789101112131415In [42]: arr = np.array([[1,2,3],[4,5,6]])In [43]: arrOut[43]:array([[1, 2, 3], [4, 5, 6]])In [44]: arr[0]Out[44]: array([1, 2, 3])In [45]: arr[0][1]Out[45]: 2In [46]: arr[0,2]Out[46]: 3 对于高维数组而言，不添加索引返回整个数组，添加一级索引，返回一个降维数组(这里是2x3的数组)，添加二级索引则在一级索引的基础上添加索引返回(这里是一维数组):1234567891011121314151617In [47]: arr = np.array([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])In [48]: arrOut[48]:array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]])In [49]: arr[0]Out[49]:array([[1, 2, 3], [4, 5, 6]])In [50]: arr[0,1]Out[50]: array([4, 5, 6]) 标量和数组都可以赋值给原数组:123456789101112131415161718192021222324252627282930313233343536In [67]: arr = np.array([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])In [68]: arrOut[68]:array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]])In [69]: old_arr = arr[0].copy()In [70]: old_arrOut[70]:array([[1, 2, 3], [4, 5, 6]])In [71]: arr[0]= 1In [72]: arrOut[72]:array([[[ 1, 1, 1], [ 1, 1, 1]], [[ 7, 8, 9], [10, 11, 12]]])In [73]: arr[0] = old_arrIn [74]: arrOut[74]:array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]]) 切片索引ndarray的切片语法跟Python列表的一维对象差不多，但是高纬度对象的花样很多，可以在一个或多个轴上进行切片，也可以跟整数索引混合使用,传入多个切片和索引相同都是递归切片:312345678910111213141516In [75]: arr2d = np.array([[1,2,3],[3,4,5]])In [76]: arr2dOut[76]:array([[1, 2, 3], [3, 4, 5]])In [77]: arr2d[:2]Out[77]:array([[1, 2, 3], [3, 4, 5]])In [78]: arr2d[:2,:1]Out[78]:array([[1], [3]]) 同时传入索引和切片可以得到低纬度的切片:12In [80]: arr2d[1,:1]Out[80]: array([3]) 只有:表示选取整个轴，可以通过这个对高纬度的进行切片：1234In [81]: arr2d[:,:1]Out[81]:array([[1], [3]]) 同时对切片表达式的赋值也会扩展到整个选区：123456In [82]: arr2d[:,:1] = 0In [83]: arr2dOut[83]:array([[0, 2, 3], [0, 4, 5]]) 布尔型索引可以对数组使用比较运算，其返回一个布尔型数组；可以使用布尔型数组进行数组索引，会返回True对应的数组，布尔型数组的长度必须跟被索引的轴长度一致:12345678910111213141516171819202122232425In [84]: names = np.array(['bob','john','tom'])In [85]: data = randn(3,6)In [86]: namesOut[86]:array(['bob', 'john', 'tom'], dtype='&lt;U4')In [87]: dataOut[87]:array([[-1.38783828, 1.53823048, -0.83396793, 2.53149852, -0.55033656, 0.13621489], [-1.92912846, 1.45011928, 0.76228734, 1.37168505, 0.71817348, -0.48010419], [-0.27052654, 0.72243318, -0.53976533, -0.55488584, -0.18700473, -0.06341261]])In [88]: names == 'bob'Out[88]: array([ True, False, False], dtype=bool)In [90]: data[names == 'bob']Out[90]:array([[-1.38783828, 1.53823048, -0.83396793, 2.53149852, -0.55033656, 0.13621489]]) 布尔型数组还可以和切片、整数(或整数序列)混合使用:12345In [91]: data[names == 'bob',2:]Out[91]: array([[-0.83396793, 2.53149852, -0.55033656, 0.13621489]])In [92]: data[names == 'bob',2]Out[92]: array([-0.83396793]) 要选取除某个元素以外的值，可以使用不等号(!=)，也可以通过~对条件进行否定；同时也可以使用&amp;(和)、|(或)之类的布尔运算符：1234567891011121314151617181920212223In [93]: data[names != 'bob']Out[93]:array([[-1.92912846, 1.45011928, 0.76228734, 1.37168505, 0.71817348, -0.48010419], [-0.27052654, 0.72243318, -0.53976533, -0.55488584, -0.18700473, -0.06341261]])In [95]: data[~(names == 'bob')]Out[95]:array([[-1.92912846, 1.45011928, 0.76228734, 1.37168505, 0.71817348, -0.48010419], [-0.27052654, 0.72243318, -0.53976533, -0.55488584, -0.18700473, -0.06341261]])In [97]: data[(names == 'bob')| (names=='tom')]Out[97]:array([[-1.38783828, 1.53823048, -0.83396793, 2.53149852, -0.55033656, 0.13621489], [-0.27052654, 0.72243318, -0.53976533, -0.55488584, -0.18700473, -0.06341261]])In [98]: data[(names == 'bob')&amp; (names=='tom')]Out[98]: array([], shape=(0, 6), dtype=float64) 通过布尔索引选取数组中的数据，总是创建数据的副本，即使返回一模一样的数组。 花式索引花式索引(Fancy indexing)指的是利用整数数组进行索引。为了以特定顺序选取行子集，只需传入一个指定顺序的整数列表或ndarray即可：12345678910111213141516171819202122In [102]: arr = np.empty((7,4))In [103]: for i in range(7): ...: arr[i]=i ...:In [104]: arrOut[104]:array([[ 0., 0., 0., 0.], [ 1., 1., 1., 1.], [ 2., 2., 2., 2.], [ 3., 3., 3., 3.], [ 4., 4., 4., 4.], [ 5., 5., 5., 5.], [ 6., 6., 6., 6.]])In [105]: arr[[4,3,1,2]]Out[105]:array([[ 4., 4., 4., 4.], [ 3., 3., 3., 3.], [ 1., 1., 1., 1.], [ 2., 2., 2., 2.]]) 使用负数索引将会从末尾开始选取行:123456In [106]: arr[[-4,-3,-1,-2]]Out[106]:array([[ 3., 3., 3., 3.], [ 4., 4., 4., 4.], [ 6., 6., 6., 6.], [ 5., 5., 5., 5.]]) 一次性传入多个索引数组返回的事一个以为数组，其中的元素对应各个索引元组：1234567891011121314151617In [107]: arr = np.arange(32).reshape((8,4))In [108]: arrOut[108]:array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]])In [109]: arr[[1,2,3,4],[1,2,3,4]]In [110]: arr[[1,2,3,4],[0,1,2,3]]Out[110]: array([ 4, 9, 14, 19]) 其中选出的元素是(1,0),(2,1),(3,2),(4,3)。而选取矩阵的行列子集的方法如下：123456In [111]: arr[[1,2,3,4]][:,[0,1,2,3]]Out[111]:array([[ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]]) 选取矩阵的另一个方法是使用np.ix_函数，它可以将两个一维整数数组转换为一个用于选取方形区域的索引器：123456In [112]: arr[np.ix_([1,2,3,4],[0,1,2,3])]Out[112]:array([[ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]]) 花式索引总是将数据复制到新数组中。 数组转置和轴对换转置(transpose)是重塑的一种特殊形式，它返回的是源数据的视图。数组不仅有transpose方法，还有一个特殊的T属性，在计算内积的时候经常需要用到：12345678910111213In [114]: arr.TOut[114]:array([[ 0, 4, 8, 12, 16, 20, 24, 28], [ 1, 5, 9, 13, 17, 21, 25, 29], [ 2, 6, 10, 14, 18, 22, 26, 30], [ 3, 7, 11, 15, 19, 23, 27, 31]])In [115]: np.dot(arr.T, arr)Out[115]:array([[2240, 2352, 2464, 2576], [2352, 2472, 2592, 2712], [2464, 2592, 2720, 2848], [2576, 2712, 2848, 2984]]) transpose需要得到一个由轴编号组成的元组才能对这些轴进行转置:12345678910111213141516171819202122232425262728In [126]: arrOut[126]:array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])In [127]: arr.shapeOut[127]: (2, 2, 3)In [128]: arr.transpose((1,2,0))Out[128]:array([[[ 0, 6], [ 1, 7], [ 2, 8]], [[ 3, 9], [ 4, 10], [ 5, 11]]])In [129]: arr.transpose((1,0,2))Out[129]:array([[[ 0, 1, 2], [ 6, 7, 8]], [[ 3, 4, 5], [ 9, 10, 11]]]) 上面arr.shape返回的结果是(2,2,3) 表明这是一个三维数组，形状为2x2x3,执行arr.transpose((1,2,0))对三个轴进行了重新排列形状变成了2x3x2。在原数组中元素对应的下标为：12345[[[(0,0,0), (0,0,1), (0,0,2)], [(0,1,0), (0,1,1), (0,1,2)]], [[(1,0,0), (1,0,1), (1,0,2)], [(1,1,0), (1,1,1),(1,1,2)]]] 进行轴变换之后的原下标变为:123456789101112131415(0,0,0)-&gt;(0,0,0)(0,0,1)-&gt;(0,1,0)(0,0,2)-&gt;(0,2,0)(0,1,0)-&gt;(1,0,0)(0,1,1)-&gt;(1,1,0)(0,1,2)-&gt;(1,2,0)(1,0,0)-&gt;(0,0,1)(1,0,1)-&gt;(0,1,1)(1,0,2)-&gt;(0,2,1)(1,1,0)-&gt;(1,0,1)(1,1,1)-&gt;(1,1,1)(1,1,2)-&gt;(1,2,1) 将将上面重新编号后的索引对应轴排列并将原数组对应的数字填入其中：123456[[[(0,0,0), (0,0,1)], -&gt; (0,0,0) ,(1,0,0) -&gt; 0,6 [(0,1,0), (0,1,1)], -&gt; (0,0,1) ,(1,0,1) -&gt; 1,7 [(0,2,0), (0,2,1)]], -&gt; (0,0,2) ,(1,0,2) -&gt; 2,8 [[(1,0,0), (1,0,1)], -&gt; (0,1,0) ,(1,1,0) -&gt; 3,9 [(1,1,0), (1,1,1)], -&gt; (0,1,1) ,(1,1,1) -&gt; 4,10 [(1,2,0), (1,2,1)]] -&gt; (0,1,2) ,(1,1,2) -&gt; 5, 11 所以最后的数组变为：1234567array([[[ 0, 6], [ 1, 7], [ 2, 8]], [[ 3, 9], [ 4, 10], [ 5, 11]]]) swapaxes方法需要接受一对轴编号,其返回的事源数据的视图:12345678910111213array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]])In [138]: arr.swapaxes(0,1)Out[138]:array([[[ 0, 1, 2], [ 6, 7, 8]], [[ 3, 4, 5], [ 9, 10, 11]]]) 1.NumPy将通过语句import numpy as np导入 ↩2.使用副本需要显式地进行复制操作，arr[1:4].copy() ↩3.轴根据shape返回元组的大小确认，如果arr.shape返回(2,2,3)则表示这是一个三维数组，0就是对应第一个2的数轴，指的第一维，1对应第二个2的数轴，指的第二维，2对应3的数轴，指的第三维 ↩]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPython入门]]></title>
    <url>%2F2018%2F03%2F15%2FIPython%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[IPython基础IPython的环境需要自行安装。如果已经安装了Python，可以通过执行pip install ipython安装。然后只需要在命令行输入ipython就能启动：12345Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)]Type 'copyright', 'credits' or 'license' for more informationIPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.In [1]: 可以在IPython中执行任何Python语句，和使用Python解释器一样：1234567891011121314151617181920In [1]: import numpy as npIn [2]: from numpy.random import randnIn [3]: data = &#123;i:randn() for i in range(10)&#125;In [4]: dataOut[4]:&#123;0: -0.24193324837938815, 1: 0.22563840475528563, 2: 0.14465306885873513, 3: 0.5076262433687561, 4: 0.9067731627966235, 5: 0.23827518072962814, 6: 0.3233586627456586, 7: 0.0327013232275763, 8: -0.357340429464286, 9: -1.4105691657079547&#125;In [5]: 许多Python对象都被格式化为可读性更好的形式 Tab键自动完成在shell中输入表达式时，只要按下Tab键，当前命名空间中任何与已输入的字符串相匹配的变量(对象、函数等)就会被找出来：12345678In [5]: an_example1 = 15In [6]: an_example2 = 20In [7]: an&lt;TAB&gt; an_example1 AnalogCommonProxyStub.dll an_example2 and any() 也可以在任何对象后面输入一个句点以便自动完成方法和属性的输入：123456In [7]: a = [1, 2, 3]In [8]: a.&lt;TAB&gt; append() count() insert() reverse() clear() extend() pop() sort() copy() index() remove() 应用在模块上:123456In [8]: import datetimeIn [9]: datetime. date() MAXYEAR timedelta datetime MINYEAR timezone datetime_CAPI time() tzinfo() IPython默认会隐藏那些以下划线开头的方法和属性。如果需要应Tab键自动完成，可以先输入一个下划线。也可以直接修改IPython配置文件中的相关设置。Tab键还可以找出电脑文件系统中与之匹配的东西：1234In [6]: ca&lt;TAB&gt; callable() %%capture catchLink/ 其中 catchLibk/ 为当前目录下的一个子目录。在使用补全目录的时候需要使用正斜杠(/)，文件夹或文件名中间不能有空格。 内省在变量前面或者后面加上一个问号(?)就可以将有关该对象的一些通用信息显示:123456789In [2]: b = []In [3]: b?Type: listString form: []Length: 0Docstring:list() -&gt; new empty listlist(iterable) -&gt; new list initialized from iterable's items 如果该对象是一个函数或实例方法，则其docstring也会被显示出来：1234567891011121314151617181920In [4]: def add_number(a,b): ...: """ ...: Add two numbers together ...: Returns ...: ----------------------- ...: the sum: type of arguments ...: """ ...: return a+b ...: ...:In [5]: add_number?Signature: add_number(a, b)Docstring:Add two numbers togetherReturns-----------------------the sum: type of argumentsFile: d:\python\&lt;ipython-input-4-7144b04645ed&gt;Type: function 使用??还将显示源代码:12345678910111213In [6]: add_number??Signature: add_number(a, b)Source:def add_number(a,b): """ Add two numbers together Returns ----------------------- the sum: type of arguments """ return a+bFile: d:\python\&lt;ipython-input-4-7144b04645ed&gt;Type: function ?还可以搜索IPython的命名空间，一些字符再配以通配符(*)即可显示出所有与该通配符表达式相匹配的名称:12345678In [7]: import numpy as npIn [8]: np.*load*?np.__loader__np.loadnp.loadsnp.loadtxtnp.pkgload %run命令在IPython会话环境中，所有文件都可以通过%run命令当做Python程序来运行。现在在目录下有一个叫做ipython_script_test.py的脚本：1234567891011#!/usr/bin/python3# -*- coding:utf-8 -*-def f(x, y, z): return (x+y) /za = 1b = 2c = 3result = f(a, b, c) 然后运行，并且运行成功后该文件中所定义的全部变量(import、函数和全局变量)都可以在IPython shell中访问:1234567In [9]: %run ipython_script_test.pyIn [10]: resultOut[10]: 1.0In [11]: aOut[11]: 1 中断正在执行的代码任何代码在执行时只要按下“Ctrl-C/control-C”,就会引发一个KeyboardInterrupt，除非Python代码已经调用某个已编译的扩展模块需要等待Python解释器重新获取控制权外，绝大部分Python程序将立即停止执行。 执行剪切板中的代码使用%paste和%cpaste两个魔术函数粘贴代码在shell中以整体执行： %paste 123456789In [12]: %pastedef f(x, y, z): return (x+y) /za = 1b = 2c = 3result = f(a, b, c)## -- End pasted text -- %cpaste 相比于%paste，%cpaste多出了一个用于粘贴代码的特殊提示符,若果发现粘贴的代码有错，只需按下“Ctrl-C/control-C”即可终止%cpaste提示符：12345678910In [16]: %cpastePasting code; enter '--' alone on the line to stop or use Ctrl-D.:def f(x, y, z):: return (x+y) /z::a = 1:b = 2:c = 3:result = f(a, b, c):-- 键盘快捷键IPython提供了许多用于提示符导航和查阅历史shell命令的键盘快捷键(C指代Ctrl或control)： 命令 说明 C-P或上箭头 后向搜索命令历史中以当前输入的文本开头的命令 C-N或下箭头 前向搜索命令历史中以当前输入的文本开头的命令 C-R 按行读取的反向历史搜索(部分匹配) C-Shift-V/Command-Shift-V 从剪切板粘贴文本 C-C 终止当前正在执行的代码 C-A 将光标移动到行首 C-E 将光标移动到行尾 C-K 删除从光标开始至行尾的文本 C-U 清楚当前行的所有文本(只是和C-K相反，即删除从光标开始至行首的文本) C-F 将光标向前移动一个字符 C-b 将光标向后移动一个字符 C-L 清屏 异常和跟踪如果%run某段脚本或执行某条语句是发生异常，IPython会默认输出整个调用栈跟踪，其中还会附上调用栈各点附近的几行代码作为上下文参考:12345678910111213141516In [17]: %run ipython_bug.py---------------------------------------------------------------------------ZeroDivisionError Traceback (most recent call last)D:\Python\ipython\ipython_bug.py in &lt;module&gt;() 5 b = 2 6 c = 0----&gt; 7 result = f(a, b, c)D:\Python\ipython\ipython_bug.py in f(x, y, z) 1 def f(x, y, z):----&gt; 2 return (x+y) /z 3 4 a = 1 5 b = 2ZeroDivisionError: division by zero 魔术命令IPython有一些特殊命令，它们有的为常见任务提供便利，有的则使控制IPython系统的行为更轻松。魔术命令以百分号 % 为前缀的命令。例如通过%timeit检测任何Python语句的执行时间:1234In [41]: a = np.random.randn(100,100)In [42]: %timeit np.dot(a,a)237 µs ± 40 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 魔术命令可以看做运行于IPython系统中的命令行程序，使用?即可查看其选项:123456789101112131415161718192021222324252627282930313233343536373839In [44]: %reset?Docstring:Resets the namespace by removing all names defined by the user, ifcalled without arguments, or by removing some types of objects, suchas everything currently in IPython's In[] and Out[] containers (seethe parameters for details).Parameters-----------f : force reset without asking for confirmation.-s : 'Soft' reset: Only clears your namespace, leaving history intact. References to objects may be kept. By default (without this option), we do a 'hard' reset, giving you a new session and removing all references to objects from the current session.in : reset input historyout : reset output historydhist : reset directory historyarray : reset only variables that are NumPy arraysSee Also--------reset_selective : invoked as ``%reset_selective``Examples--------:: In [6]: a = 1 In [7]: a Out[7]: 1 In [8]: 'a' in _ip.user_ns Out[8]: True 魔术命令可以不带百分号使用，只要没有定义与其同名的变量。 常用的魔术命令 命令 说明 %quickref 显示Python的快速参考 %magic 显示所有魔术命令的详细文档 %debug 从最新的异常跟踪的底部进入交互式调试器 %hist 打印命令的输入(可选输出)历史 %pdb 在异常发生后自动进入调试器 %paste 执行剪切板中的Python代码 %cpaste 打开一个特殊提示符以便手工粘贴待执行的Python代码 %reset 删除interactive命名空间的全部变量/名称 %page OBJECT 通过分页器打印输出OBJECT %run script.py 在IPython中执行一个Python脚本文件 %prun statement 通过cProfile执行statement，并打印分析器的输出结果 %time statement 报告statement的执行时间 %timeit statement 多次执行statement以计算系统平均执行时间。对那些执行时间非常小的代码很有用 %who、%who_is、%whos 显示interactive命名空间中定义的变量，信息级别/冗余度可变 %xdel variable 删除variable，并参加过时清除其在IPython中的对象上的一切引用 matplotlib集成与pylab模式启动IPython时加上--pylab标记来集成matplotlibipython --pylab。这样IPython会默认GUI后台集成，就可以创建matplotlib绘图了。并且NumPy和matplotlib的大部分功能会被引入到最顶层的interactive命名空间以产生一个交互式的计算环境。也可以通过%gui对此进行手工设置。123456Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)]Type 'copyright', 'credits' or 'license' for more informationIPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.Using matplotlib backend: TkAggIn [1]: 使用命令历史IPython维护着一个位于硬盘上的小型数据库，其中含有执行过的每条命令的文本： 只需很少的按键次数即可搜索、自动完成并执行之前已经执行过的命令 在会话间持久化命令历史 将输入/输出历史记录到日志文件 搜索并重用命令历史如果需要输入之前执行过的相同的命令，只需要按照上面的快捷键表操作，就可以搜索出命令历史中第一个与输入的字符相匹配的命令。既可以后向搜索也可以前向搜索。 输入和输出变量IPython会将输入(输入的文本)和输出(返回的对象)的引用保存在一些特殊变量中。最近的两个输出结果分别保存在 _(一个下划线)和 __(两个下划线)变量中：1234567891011121314In [6]: 1+1Out[6]: 2In [7]: _Out[7]: 2In [8]: _+1Out[8]: 3In [9]: 3+1Out[9]: 4In [10]: __Out[10]: 3 输入的文本保存在名为_ix的变量中，其中 X 是输入行的行号。每个输入变量都有一个对应的输出变量_x:12345In [11]: _i6Out[11]: '1+1'In [12]: _6Out[12]: 2 由于输入变量是字符串，因此可以用Python的exec()方法重新执行:1234In [18]: exec(_i6)In [19]: _Out[19]: '1+1' 有几个魔术命令可以用于控制输入和输出历史。%hist用于打印全部或部分输入历史，可以选择是否带行号。%reset用于清空interactive命名空间，并可选择是否清空输入和输出缓存。%xdel用于从IPython系统中移除特定对象的一切引用。 记录输入和输出IPython能够记录整个控制台会话，包括输入和输出。执行%logstart即可开始记录日志：12345678In [20]: %logstartActivating auto-logging. Current session state plus future input saved.Filename : ipython_log.pyMode : rotateOutput logging : FalseRaw input log : FalseTimestamping : FalseState : active IPython的日志功能可以在任何时刻开启。还有与%logstart配套的%logoff、%logon、%logstate和%logstop，可以参考其文档。 与操作系统交互可以在IPython中实现标准的Windows或UNIX命令行活动，将命令的执行结果保存在Python对象中 跟系统相关的IPython魔术命令 命令 说明 !cmd 在系统shell中执行cmd output=!cmd args 执行cmd，并将stout存放在output中 %alias alias_name cmd 为系统shell命令定义别名 %bookmark 使用IPython的目录书签系统 %cd directory 将系统工作目录更改为directory %pwd 返回系统的当前工作目录 %pushd directory 将当前目录入栈，并转向目标目录 %popd 弹出栈顶目录，并转向该目录 %dirs 返回一个含有当前目录栈的列表 %dhist 打印目录访问历史 %env 以dict形式返回系统环境变量 shell命令和别名在IPython中，以感叹号(!)开头的命令行表示其后的所有内容需要在系统shell中执行:1234In [23]: !pythonPython 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)] on win32Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; 还可以将shell命令的控制台输出存放到变量中，只需将 ! 开头的表达式赋值给变量:1234In [152]: ip_info = !lsIn [153]: ip_infoOut[153]: ['experiment.py', 'ipython_bug.py', 'ipython_script_test.py'] 软件开发工具IPython集成并加强了Python内置的pdb调试器，同时提供了一些简单易用的代码运行时间及性能分析工具。 交互式调试器IPython的调试器增强了pdb，如Tab键自动完成、语法高亮、为异常跟踪的每条信息添加上下文参考。%debug命令(在发生异常之后马上输入)将会调用那个“事后”调试器，并直接跳转到引发异常的那个栈帧：123456789101112131415161718192021222324In [45]: %run ipython_bug.py---------------------------------------------------------------------------ZeroDivisionError Traceback (most recent call last)D:\Python\ipython\ipython_bug.py in &lt;module&gt;() 5 b = 2 6 c = 0----&gt; 7 result = f(a, b, c)D:\Python\ipython\ipython_bug.py in f(x, y, z) 1 def f(x, y, z):----&gt; 2 return (x+y) /z 3 4 a = 1 5 b = 2ZeroDivisionError: division by zeroIn [46]: %debug&gt; d:\python\ipython\ipython_bug.py(2)f() 1 def f(x, y, z):----&gt; 2 return (x+y) /z 3 4 a = 1 5 b = 2 在这个调试器中，可以执行任意Python代码并查看各个栈帧中的一切对象和数据。默认是从最低级开始(即错误发生的地方)。输入u(或up)和d(或down)即可在栈跟踪的各级别之间切换:123456789101112131415ipdb&gt; u&gt; d:\python\ipython\ipython_bug.py(7)&lt;module&gt;() 3 4 a = 1 5 b = 2 6 c = 0----&gt; 7 result = f(a, b, c)ipdb&gt; d&gt; d:\python\ipython\ipython_bug.py(2)f() 1 def f(x, y, z):----&gt; 2 return (x+y) /z 3 4 a = 1 5 b = 2 执行%pdp命令可以让IPython在出现异常之后自动调用调试器。如果需要设置断点或对函数/脚本进行单步调试以查看各条语句的执行情况时，可以使用带有-d选项的%run命令，这会在执行脚本文件中的代码之前打开调试器，然后输入s(或step)步进才能进入脚本:123456789101112131415161718192021222324252627282930313233In [50]: %run -d ipython_bug.pyBreakpoint 1 at d:\python\ipython\ipython_bug.py:1NOTE: Enter 'c' at the ipdb&gt; prompt to continue execution.&gt; d:\python\ipython\ipython_bug.py(1)&lt;module&gt;()1---&gt; 1 def f(x, y, z): 2 return (x+y) /z 3 4 a = 1 5 b = 2ipdb&gt; s&gt; d:\python\ipython\ipython_bug.py(4)&lt;module&gt;() 2 return (x+y) /z 3----&gt; 4 a = 1 5 b = 2 6 c = 0ipdb&gt; s&gt; d:\python\ipython\ipython_bug.py(5)&lt;module&gt;() 3 4 a = 1----&gt; 5 b = 2 6 c = 0 7 result = f(a, b, c)ipdb&gt; s&gt; d:\python\ipython\ipython_bug.py(6)&lt;module&gt;() 3 4 a = 1 5 b = 2----&gt; 6 c = 0 7 result = f(a, b, c) 通过b num在num行出设置断点，输入c(或continue)使脚本一直运行下去直到该断点时为止,然后输入n(或next)直到执行下一行(即step over):1234567891011121314151617181920212223242526272829303132333435363738In [53]: %run -d ipython_bug.pyBreakpoint 1 at d:\python\ipython\ipython_bug.py:1NOTE: Enter 'c' at the ipdb&gt; prompt to continue execution.&gt; d:\python\ipython\ipython_bug.py(1)&lt;module&gt;()1---&gt; 1 def f(x, y, z): 2 return (x+y) /z 3 4 a = 1 5 b = 2ipdb&gt; b 7Breakpoint 2 at d:\python\ipython\ipython_bug.py:7ipdb&gt; c&gt; d:\python\ipython\ipython_bug.py(7)&lt;module&gt;() 3 4 a = 1 5 b = 2 6 c = 02---&gt; 7 result = f(a, b, c)ipdb&gt; nZeroDivisionError: division by zero&gt; d:\python\ipython\ipython_bug.py(7)&lt;module&gt;() 3 4 a = 1 5 b = 2 6 c = 02---&gt; 7 result = f(a, b, c)ipdb&gt; n--Return--None&gt; d:\python\ipython\ipython_bug.py(7)&lt;module&gt;() 3 4 a = 1 5 b = 2 6 c = 02---&gt; 7 result = f(a, b, c) IPython调试器命令 命令 功能 h(elp) 显示命令列表 help command 显示command的文档 c(ontinue) 恢复程序的执行 q(uit) 退出调试器，不再执行任何代码 b(readk) number 在当前文件的第number行设置一个断点 b path/to/file.py:number 在指定文件的第number行设置一个断点 s(tep) 单步进入函数调用 n(ext) 执行当前行，并前进到当前级别的下一行 u(p)/d(own) 在函数调用栈中向上或向下移动 a(rgs) 显示当前函数的参数 debug statement 在新的(递归)调试器中调用语句statement l(ist) statement 显示当前行，以及当前栈级别的上下文参考代码 w(here) 打印当前位置的完整栈跟踪(包括上下文参考代码) 测试代码的执行时间:%time和%timeit%time一次执行一条语句，然后报告总体执行时间1234567In [56]: strings = ['foo','bar','abc','foobar','python','Guide Peple']*100000In [57]: %time method1 = [x for x in strings if x.startswith('foo')]Wall time: 102 msIn [58]: %time method2 = [x for x in strings if x[:3] == 'foo']Wall time: 59.2 ms %timeit对于任意语句，它会自动多次执行以产生一个非常精确的平均执行时间12345In [59]: %timeit method1 = [x for x in strings if x.startswith('foo')]100 ms ± 5.73 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)In [60]: %timeit method2 = [x for x in strings if x[:3] == 'foo']57 ms ± 7.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) 基本性能分析：%prun和%run -p代码的性能分析跟代码执行时间密切相关，只不过它关注的事耗费时间的位置，主要的Python性能分析工具是cProfile模块。CProfile在执行一个程序或代码块时，会记录各函数所耗费的时间。CProfile一般在命令行上使用，它将执行整个程序然后输出各函数的执行时间。%prun分析的是Python语句而不是整个.py文件：123456789101112131415161718192021222324252627In [141]: %cpastePasting code; enter '--' alone on the line to stop or use Ctrl-D.:def run_experiment(niter=100): k = 100 results = [] for _ in range(niter): mat = np.random.randn(k, k) max_eigenvalue = np.abs(eigvals(mat)).max() results.append(max_eigenvalue) return results:::::::::--In [142]: %prun -l 7 -s cumulative run_experiment() 3804 function calls in 0.901 seconds Ordered by: cumulative time List reduced from 31 to 7 due to restriction &lt;7&gt; ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.901 0.901 &#123;built-in method builtins.exec&#125; 1 0.000 0.000 0.901 0.901 &lt;string&gt;:1(&lt;module&gt;) 1 0.002 0.002 0.901 0.901 &lt;ipython-input-141-78ef833ef08b&gt;:1(run_experiment) 100 0.814 0.008 0.838 0.008 linalg.py:834(eigvals) 100 0.060 0.001 0.060 0.001 &#123;method 'randn' of 'mtrand.RandomState' objects&#125; 100 0.012 0.000 0.018 0.000 linalg.py:213(_assertFinite) 300 0.008 0.000 0.008 0.000 &#123;method 'reduce' of 'numpy.ufunc' objects&#125; 执行%run -p -s cumulative experiment.py也能达到以上的效果，无需退出IPython:123456789101112131415In [75]: %run -p -l 7 -s cumulative experiment.pyLargest one we saw:11.9165340849 3888 function calls (3887 primitive calls) in 0.467 seconds Ordered by: cumulative time List reduced from 77 to 7 due to restriction &lt;7&gt; ncalls tottime percall cumtime percall filename:lineno(function) 2/1 0.000 0.000 0.467 0.467 &#123;built-in method builtins.exec&#125; 1 0.000 0.000 0.467 0.467 &lt;string&gt;:1(&lt;module&gt;) 1 0.000 0.000 0.467 0.467 interactiveshell.py:2445(safe_execfile) 1 0.000 0.000 0.467 0.467 py3compat.py:182(execfile) 1 0.000 0.000 0.467 0.467 experiment.py:1(&lt;module&gt;) 1 0.001 0.001 0.466 0.466 experiment.py:5(run_experiment) 100 0.431 0.004 0.436 0.004 linalg.py:819(eigvals) ipython html notebook需要安装 jupyter 来使用该功能:1pip3 install jupyter 这是一个基于Web的交互式计算文档格式。它有一种基于JSON的文档格式.upynb，可以轻松分享代码、输出结果以及图片等内容。执行如下命令启动：1jupyter notebook 这是运行于命令行上的轻量级服务器进程，Web浏览器会自动打开Notebook的仪表盘。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>IPython</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python文本处理]]></title>
    <url>%2F2018%2F03%2F13%2FPython%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[逗号分割值(CSV)CSV简介逗号分割值(Comma-Spearated Value, CSV) 通常用于在电子表格软件和纯文本之间交互数据。CSV文件内容仅仅是一些用逗号分隔的原始字符串值。CSV格式的文件需要专门用于解析和生成CSV的库，不能使用str.splt(&#39;,&#39;)来解析，因为会处理单个字段中含有逗号的情形。123456789101112131415161718192021222324252627282930#!/usr/bin/python3# -*- coding:utf-8 -*-import csv# 创建需要导入的数据源DATA = ( (1, 'Web Clients and Servers', 'base64,urllib'), (2, 'Web program：CGI &amp; WSGI', 'cgi, time, wsgiref'), (3, 'Web Services', 'urllib,twython'))print('*** WRITTING CSV DATA')# 打开一个csv文件，使用utf-8编码，同时为了防止写入时附加多的空白行设置newline为空with open('bookdata.csv', 'w', encoding='utf-8', newline='') as w: # csv.writer笑一个打开的文件(或类文件)对象，返回一个writer对象 # 可以用来在打开的文件中逐行写入逗号分隔的数据。 writer = csv.writer(w) for record in DATA: writer.writerow(record)# writer对象提供一个writerow()方法print('****REVIEW OF SAVED DATA')with open('bookdata.csv', 'r', encoding='utf-8') as r: # csv.reader()用于返回一个可迭代对象，可以读取该对象并解析为CSV数据的每一行 # csv.reader()使用一个已打开文件的句柄，返回一个reader对象 # 当逐行迭代数据时，CSV数据会自动解析并返回给用户 reader = csv.reader(r) for chap, title, modpkgs in reader: print('Chapter %s: %r (featureing %s)' % (chap, title, modpkgs)) 输出结果 12345*** WRITTING CSV DATA****REVIEW OF SAVED DATAChapter 1: &apos;Web Clients and Servers&apos; (featureing base64,urllib)Chapter 2: &apos;Web program：CGI &amp; WSGI&apos; (featureing cgi, time, wsgiref)Chapter 3: &apos;Web Services&apos; (featureing urllib,twython) csv模块还提供csv.DictReader类和csv.DictWriter类，用于将CSV数据读进字典中(首先查找是否使用给定字段名，如果没有，就是用第一行作为键)，接着将字典字段写入CSV文件中。 JSONJSON是JavaScript的子集，专门用于指定结构化的数据。JSON是以人类更易读的方式传输结构化数据。 JSON和Python类型之间的区别 JSON Python3 object dict array list tuple string str number(int) int number(real) float true True false False null None json提供了dump()/load()和dumps()/loads()。除了基本参数外，这些函数还包含许多仅用于JSON的选项。模块还包括encoder类和decoder类，用户既可以继承也可以直接使用。Python字典可以转化为JSON对象，Python列表和元组也可以转成对应的JSON数组。12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/python3# -*- coding:UTF-8 -*-# 返回一个表示Python对象的字符串# 用来美观地输出Python对象from json import dumpsfrom pprint import pprint# Python字典，使用字典是因为其可以构建具有结构化层次的属性。# 在等价的JSON表示方法中，会移除所有额外的逗号Books = &#123; '0000001': &#123; 'title': 'Core', 'edition': 2, 'year': 2007, &#125;, '0000002': &#123; 'title': 'Python Programming', 'edition': 3, 'authors': ['Jack', 'Bob', 'Jerry'], 'year': 2009, &#125;, '0000003': &#123; 'title': 'Programming', 'year': 2009, &#125;&#125;# 显示转储的Python字典print('***RAW DICT***')print(Books)# 使用更美观的方法输出print('***PRETTY_PRINTED DICT***')pprint(Books)# 使用json.dumps()内置的美观的输出方式，传递缩进级别print('***PRETTY_PRINTED JSON***')print(dumps(Books, indent=4)) 输出结果 12345678910111213141516171819202122232425262728293031***RAW DICT***&#123;&apos;0000001&apos;: &#123;&apos;title&apos;: &apos;Core&apos;, &apos;edition&apos;: 2, &apos;year&apos;: 2007&#125;, &apos;0000002&apos;: &#123;&apos;title&apos;: &apos;Python Programming&apos;, &apos;edition&apos;: 3, &apos;authors&apos;: [&apos;Jack&apos;, &apos;Bob&apos;, &apos;Jerry&apos;], &apos;year&apos;: 2009&#125;, &apos;0000003&apos;: &#123;&apos;title&apos;: &apos;Programming&apos;, &apos;year&apos;: 2009&#125;&#125;***PRETTY_PRINTED DICT***&#123;&apos;0000001&apos;: &#123;&apos;edition&apos;: 2, &apos;title&apos;: &apos;Core&apos;, &apos;year&apos;: 2007&#125;, &apos;0000002&apos;: &#123;&apos;authors&apos;: [&apos;Jack&apos;, &apos;Bob&apos;, &apos;Jerry&apos;], &apos;edition&apos;: 3, &apos;title&apos;: &apos;Python Programming&apos;, &apos;year&apos;: 2009&#125;, &apos;0000003&apos;: &#123;&apos;title&apos;: &apos;Programming&apos;, &apos;year&apos;: 2009&#125;&#125;***PRETTY_PRINTED JSON***&#123; &quot;0000001&quot;: &#123; &quot;title&quot;: &quot;Core&quot;, &quot;edition&quot;: 2, &quot;year&quot;: 2007 &#125;, &quot;0000002&quot;: &#123; &quot;title&quot;: &quot;Python Programming&quot;, &quot;edition&quot;: 3, &quot;authors&quot;: [ &quot;Jack&quot;, &quot;Bob&quot;, &quot;Jerry&quot; ], &quot;year&quot;: 2009 &#125;, &quot;0000003&quot;: &#123; &quot;title&quot;: &quot;Programming&quot;, &quot;year&quot;: 2009 &#125;&#125; XMLXML数据是纯文本数据，但是其可读性不高，所以需要使用解析器进行解析。 将字典转化为XML 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/python3# -*- coding:UTF-8 -*-#from xml.etree.ElementTree import Element, SubElement, tostringfrom xml.dom.minidom import parseString# Python字典，使用字典是因为其可以构建具有结构化层次的属性。# 在等价的JSON表示方法中，会移除所有额外的逗号Books = &#123; '0000001': &#123; 'title': 'Core', 'edition': 2, 'year': 2007, &#125;, '0000002': &#123; 'title': 'Python Programming', 'edition': 3, 'authors': 'Jack:Bob:Jerry', 'year': 2009, &#125;, '0000003': &#123; 'title': 'Programming', 'year': 2009, &#125;&#125;# 创建顶层对象# 将所有其他内容添加到该节点下books = Element('books')for isbn, info in Books.items(): # 对于每一本书添加一个book子节点 # 如果原字典没有提供作者和版本，则使用提供的默认值。 book = SubElement(books, 'book') info.setdefault('authors', 'Bob') info.setdefault('edition', 1) for key, val in info.items(): # 遍历所有键值对，将这些内容作为其他子节点添加到每个book中 SubElement(book, key).text = ', '.join(str(val).split(':'))xml = tostring(books)print('*** RAW XML***')print(xml)print('***PRETTY-PRINTED XML***')dom = parseString(xml)print(dom.toprettyxml(' '))print('***FLAT STRUCTURE***')for elmt in books.iter(): print(elmt.tag, '-', elmt.text)print('\n***TITLE ONLY***')for book in books.findall('.//title'): print(book.text) 输出结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647*** RAW XML***b&apos;&lt;books&gt;&lt;book&gt;&lt;title&gt;Core&lt;/title&gt;&lt;edition&gt;2&lt;/edition&gt;&lt;year&gt;2007&lt;/year&gt;&lt;authors&gt;Bob&lt;/authors&gt;&lt;/book&gt;&lt;book&gt;&lt;title&gt;Python Programming&lt;/title&gt;&lt;edition&gt;3&lt;/edition&gt;&lt;authors&gt;Jack, Bob, Jerry&lt;/authors&gt;&lt;year&gt;2009&lt;/year&gt;&lt;/book&gt;&lt;book&gt;&lt;title&gt;Programming&lt;/title&gt;&lt;year&gt;2009&lt;/year&gt;&lt;authors&gt;Bob&lt;/authors&gt;&lt;edition&gt;1&lt;/edition&gt;&lt;/book&gt;&lt;/books&gt;&apos;***PRETTY-PRINTED XML***&lt;?xml version=&quot;1.0&quot; ?&gt;&lt;books&gt; &lt;book&gt; &lt;title&gt;Core&lt;/title&gt; &lt;edition&gt;2&lt;/edition&gt; &lt;year&gt;2007&lt;/year&gt; &lt;authors&gt;Bob&lt;/authors&gt; &lt;/book&gt; &lt;book&gt; &lt;title&gt;Python Programming&lt;/title&gt; &lt;edition&gt;3&lt;/edition&gt; &lt;authors&gt;Jack, Bob, Jerry&lt;/authors&gt; &lt;year&gt;2009&lt;/year&gt; &lt;/book&gt; &lt;book&gt; &lt;title&gt;Programming&lt;/title&gt; &lt;year&gt;2009&lt;/year&gt; &lt;authors&gt;Bob&lt;/authors&gt; &lt;edition&gt;1&lt;/edition&gt; &lt;/book&gt;&lt;/books&gt;***FLAT STRUCTURE***books - Nonebook - Nonetitle - Coreedition - 2year - 2007authors - Bobbook - Nonetitle - Python Programmingedition - 3authors - Jack, Bob, Jerryyear - 2009book - Nonetitle - Programmingyear - 2009authors - Bobedition - 1***TITLE ONLY***CorePython ProgrammingProgramming]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web框架:Django]]></title>
    <url>%2F2018%2F03%2F12%2FWeb%E6%A1%86%E6%9E%B6-Django%2F</url>
    <content type="text"><![CDATA[Django简介 安装在使用Django开发之前，必须安装必需的组件，包括依赖组件和Django本身 1pip3 install django 项目和应用项目 是指的一系列文件，用来创建并运行一个完整的Web站点。在项目文件夹下，有一个或多个子文件夹，每个文件夹有特定的功能，称为 应用。应用不一定要位于项目文件夹中。应用可以专注于项目某一方面的功能，或可以作为通用组件，用于不同的项目。应用是一个具有特定功能的子模块，这些子模块组合起来就能完成Web站点的功能。 在Django中创建项目Django自带有一个名为django-admin.py/django-admin.exe的工具，它可以简.化任务。在POSIX平台上，一般在/usr/local/bin、/usr/bin这样的目录中。使用Windows系统会安装在Python包下的Scripts目录下，如E:\Python\Python36\Scripts。两种系统都应该确保文件位于PATH环境变量中。在项目文件加下执行命令创建项目: 1django-admin.py startproject mysite Django项目文件 文件名 描述/用途 init.py 告诉Python这是一个软件包 urls.py 全局URL配置(“URLconf”) setting.py 项目相关的配置 manage.py 应用的命令行接口 运行开发服务器Django内置Web服务器，该服务器运行在本地，专门用于开发阶段，仅用于开发用途。使用开发服务器有以下几个优点： 可以直接运行与测试项目和应用，无需完整的生产环境 当改动Python源码文件并重新载入模块时，开发服务器会自动检测，无须每次编辑代码后手动重启 开发服务器知道如何为Django管理应用程序寻找和显示静态媒体文件，所以无须立即了解管理方面的内容 启动服务器 1python manage.py runserver 应用创建应用在项目目录下使用如下命令创建一个应用：1python3 ./manage.py startapp blog 这样就建立了一个blog目录，其中有如下内容： 文件名 描述/目的 __init.py 告诉Python这是一个包 urls.py 应用的URL配置文件(“URLconf”)，这个文件并不像项目的URLconf那样自动创建 models.py 数据模型 views.py 视图函数(即MVC中的控制器) tests.py 单元测试 与项目类似，应用也是一个Python包。本地应用的URLconf需要手动创建，接着使用URLconf里的include()指令将请求分配给应用的URLconf。为了让Django知道这个新应用是项目的一部分，需要编辑 settings.py，将应用名称(blog)添加到元组的末尾。Django使用 INSTALLED_APPS 来配置系统的不同部分，包括自动管理应用程序和测试框架。123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog'] 创建模型添加数据库服务创建模型models.py 将定义博客的数据结构，首先创建一个基本类型。数据模型表示将会存储在数据库每条记录的数据类型。Django提供了许多字段类型，用来将数据映射到应用中。1234567891011121314from django.db import models# Create your models here.class BlogPost(models.Model): """ django.db.models.Model的子类Model是Django中用于数据模型的标准基类。 BlogPost中的字段像普通类属性那样定义， 每个都是特定字段类的实例，每个实例对应数据库中的一条记录。 """ title = models.CharField(max_length=150) body = models.TextField() timestamp = models.DateTimeField() 创建数据库在项目的setting.py文件中设置数据库。关于数据库，有6个相关设置(有时只需要两个):ENGINE、NAME、HOST、PORT、USER、PASSWORD。只需要在相关设置选项后面添上需要让Django使用的数据库服务器中合适的值即可。 使用MySQL 1234567891011DATABASES = &#123; # 使用mysql 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'django_test', 'USER': 'root', 'PASSWORD': '', 'HOST': 'localhost', 'PORT': '3306', &#125;&#125; 使用SQLiteSQLite一般用于测试，它没有主机、端口、用户、密码信息。因为其使用本地文件存储信息，本地文件系统的访问权限就是数据库的访问控制。SQLite不仅可以使用本地文件，还可以使用纯内存数据库。使用实际的Web服务器(如Apache)来使用SQLite时，需要确保拥有Web服务器进程的账户同时拥有数据库文件本身和含有数据库文件目录的写入权限。 1234567DATABASES = &#123; # 使用sqlite 'default': &#123; 'ENGINE': 'django.db.backends.sqlite3', 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), &#125;&#125; 创建表使用 makemigrations 参数创建映射文件，当执行命令时Django会查找INSTALLED_APPS中列出的应用的models.py文件。对于每个找到的模型，都会创建一个映射表。1python3 ./manage.py makemigrations 使用 migrate 映射到数据库1python3 ./manage.py migrate Python应用Shell在Django中使用Python shell即使没有模版(view)或视图(controller)，也可以通过添加一些BlogPost项来测试数据模型。如果应用由RDBMS支持，则可以为每个blog项的表添加一个数据记录。如果使用的是NoSQL数据库，则需要向数据库中添加其他对象、文档或实体。通过以下命令启动shell(使用对应版本)：123456python3 ./manage.py shellPython 3.6.4 (default, Jan 6 2018, 11:51:59)Type &apos;copyright&apos;, &apos;credits&apos; or &apos;license&apos; for more informationIPython 6.2.1 -- An enhanced Interactive Python. Type &apos;?&apos; for help.In [1]: Django shell和标准的shell相比更专注于Django项目的环境，可以与视图函数和数据模型交互，这个shell会自动设置环境变量，包括sys.path，它可以访问Django与自己项目中的模块和包，否则需要手动配置。除了标准shell之外，还有其他的交互式解释器可供选择。Django更倾向于使用功能丰富的shell，如IPython和bpython，这些shell在普通的解释器基础上提供及其强大的功能。运行shell命令时，Django首先查找含有扩展功能的shell，如果没有回返回标准解释器。这里使用的是IPython。也可以使用 -i 来强制使用普通解释器。1234567python3 ./manage.py shell -i pythonPython 3.6.4 (default, Jan 6 2018, 11:51:59)[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.(InteractiveConsole)&gt;&gt;&gt; 测试数据模型在启动Python shell之后输入一些Python或IPython命令来测试应用及其数据模型。1234567891011121314151617181920212223242526272829303132333435In [1]: from datetime import datetimeIn [2]: from blog.models import BlogPostIn [3]: BlogPost.objects.all()Out[3]: &lt;QuerySet [&lt;BlogPost: BlogPost object (1)&gt;, &lt;BlogPost: BlogPost object (2)&gt;, &lt;BlogPost: BlogPost object (3)&gt;]&gt;In [4]: bp = BlogPost(title=&apos;my blog&apos;, body=&apos;&apos;&apos; ...: my 1st blog... ...: yoooo!&apos;&apos;&apos;, ...: timestamp=datetime.now())In [5]: bpOut[5]: &lt;BlogPost: BlogPost object (None)&gt;In [6]: bp.save()In [7]: BlogPost.objects.count()Out[7]: 4In [9]: bp = BlogPost.objects.all()[0]In [11]: print(bp.title)test shellIn [13]: print(bp.body)my 1st blog post...yo!In [14]: bp.timestamp.ctime()Out[14]: &apos;Sun Mar 11 08:13:31 2018&apos; 前两行命令导入相应的对象，第3步查询数据库中BlogPost对象，第4步是实例化一个BlogPost对象来向数据库中添加BlogPost对象，向其中传入对应属性的值(title、body和timestamp)。创建完对象后，需要通过BlogPost.save()方法将其写入到数据库中。完成创建和写入后，使用BlogPost.objects.count()方法确认数据库中对象的个数。然后获取BlogPost对象列表的第一个元素并获取对应属性的值。设置时区:123456789LANGUAGE_CODE = 'zh-hans'TIME_ZONE = 'Asia/Shanghai'USE_I18N = TrueUSE_L10N = TrueUSE_TZ = False Django管理应用admin应用让开发者在完成完整的UI之前验证处理数据的代码。 设置admin在 setting.py 的INSTALLED_APP中添加&#39;django.contrib.admin&#39;,，然后运行python3 ./manage.py makemigrations和python3 ./manage.py migrate两条命令来创建其对应的表。在admin设置完之后于 urls.py 中设置url路径：123456from django.contrib import adminfrom django.urls import pathurlpatterns = [ path('admin/', admin.site.urls),] 最后应用程序需要告诉Django哪个模型需要在admin页面中显示并编辑，这时候就需要在应用的 admin.py 中注册BlogPost：1234from django.contrib import adminfrom blog import models# Register your models here.admin.site.register(models.BlogPost) 使用admin使用命令python3 ./manage.py runserver启动服务，然后在浏览器中输入 http://localhost:8000/admin 访问admin页面。在访问之前使用python3 manage.py createsuperuser创建的超级用户的用户名和密码用于登录管理页面。（账号：root，密码：Aa123456）为了更好地显示博文列表，更新blog/admin.py文件，使用新的BlogPostAdmin类：12345678910from django.contrib import adminfrom blog import models# Register your models here.class BlogPostAdmin(admin.ModelAdmin): list_display = ('title', 'timestamp')admin.site.register(models.BlogPost, BlogPostAdmin) 创建博客的用户界面Django shell和admin是针对于开发者的工具，而现在需要构建用户的界面。Web页面应该有以下几个经典组建： 模板，用于显示通过Python类字典对象传入的信息 视图函数，用于执行针对请求的核心逻辑。视图会从数据库中获取信息，并格式化显示结果 模式，将传入的请求映射到对应的视图中，同时也可以将参数传递给视图 Django是自底向上处理请求，它首先查找匹配的URL模式，接着调用对应的视图函数，最后将渲染好的数据通过模板展现给用户。构建应用可以按照如下顺序： 因为需要一些可观察对象，所以先创建基本的模板 设计一个简单的URL模式，让Django可以立刻访问应用 开发出一个视图函数原型，然后在此基础上迭代开发在构建应用过程中模板和URL模式不会发生太大的变化，而应用的核心是视图。这非常符合 测试驱动模型(TDD) 的开发模式。 创建模板 变量标签变量标签 是由 花括号() 括起来的内容，花括号内用于显示对象的内容。在变量标签中，可以使用Python风格的 点分割标识 访问这些变量的属性。这些值可以是纯数据，也可以是可调用对象，如果是后者，会自动调用这些对象而无需添加圆括号”()”来表示这个函数或方法可调用。 过滤器过滤器 是在变量标签中使用的特殊函数，它能在标签中立即对变量进行处理。方法是在变量右边插入一个 管道符号(“|”)，接着跟上过滤器名称。&lt;h2&gt; { { post.title | title } } &lt;/h2&gt; 上下文上下文 是一种特殊的Python字典，是传递给模板的变量。假设通过上下文传入的BlogPost对象称为”post”。通过上下文传入所有的博文，这样可以通过循环显示所有文章。 块标签块标签 通过花括号和百分号来表示：&#123;%…%&#125;，它们用于向HTML模版中插入如循环或判断这样的逻辑。 将HTML模版代码保存到一个简单的模版文件中，命名为archive.html，放置在应用文件夹下的 templates 目录下，模版名称任取，但模版目录一定是 templates12345&#123;%for post in posts%&#125; &lt;h2&gt;&#123;&#123;post.title&#125;&#125;&lt;/h2&gt; &lt;h2&gt;&#123;&#123;post.timestamp&#125;&#125;&lt;/h2&gt; &lt;h2&gt;&#123;&#123;post.body&#125;&#125;&lt;/h2&gt;&#123;% endfor%&#125; 创建URL模式 项目的URLconf服务器通过WSGI的功能，最终会将请求传递给Django。接受请求的类型(GET、POST等)和路径(URL中除了协议、主机、端口之外的内容)并传递到项目的URLconf文件(mysite/urls.py)。为了符合代码重用、DRY、在一处调试相同的代码等准则，需要应用能负责自己的URL。在项目的urls.py(这里时mysite/urls.py)中添加url配置项，让其指向应用的URLconf。123456789from django.contrib import adminfrom django.urls import pathfrom django.urls import includeurlpatterns = [ path('admin/', admin.site.urls), # include函数将动作推迟到其他URLconf # 这里将以blog/开通的请求缓存起来，并传递给mysite/blog/urls.py path('blog/', include('blog.urls'))] include() 会移除当前的URL路径头，路径中剩下的部分传递给下游URLconf中的path()函数。（当输入’http://localhost:8080/blog/foo/bar‘ 这个URL时，项目的URLconf接收到的是blog/foo/bar，匹配blog找到一个include()函数，然后将foo/bar传递给mysite/blog/urls.py）。上述代码中使用include()和未使用include()的区别在于使用include()传递的是 字符串，未使用include传递的是 对象。 应用的URLconf在项目的URLconf中通过include()包含blog.urls，让匹配blog应用的URL将剩余的部分传递到blog应用中处理。在mysite/blog/urls.py(没有就创建),添加以下代码：123456from django.urls import *import blog.viewsurlpatterns = [ # 第一个参数是路径，第二个参数是视图函数，在调用到这个URL时用于处理信息 path('', blog.views.archive)] 请求URL的头部分(blog/)匹配到的是根URLconf已经被去除。添加新的视图在列表中添加一行代码即可。 创建视图函数一个简单的视图函数会从数据库获取所有博文，并使用模板显示给用户： 向数据库查询所有博客条目 载入模板文件 为模板创建上下文字典 将模板渲染到HTML中 通过HTTP响应返回HTML在应用的views.py中添加如下代码:12345678910from django.shortcuts import renderfrom blog.models import BlogPostfrom django.template import loader, Contextfrom django.shortcuts import render_to_response# Create your views here.def archive(request): posts = BlogPost.objects.all() return render_to_response('archive.html', &#123;'posts': posts&#125;) 改进输出现在得到了一个可以工作的应用，有了可以工作的简单博客，可以响应客户端的请求，从数据库提取信息，向用户显示博文。现在更改查询方式，让博文按时间逆序显示，并且限制每页显示的数目。 BlogPOST是数据模型类。Objects属性是模型的Manager类，其中含有all()方法来获取QuerySet。QuerySet执行“惰性迭代”，在求值时才会真正查询数据库。 实现排序只需调用order_by()方法时提供一个排序参数即可(views.py)：1234def archive(request): # 在timestamp前面加上减号(-)指定按时间逆序排列。正常的升序只需要移除减号 posts = BlogPost.objects.all().order_by('-timestamp') return render_to_response('archive.html', &#123;'posts': posts&#125;) 为了测试限制显示数目，先启动Django shell添加数据：12345678910python ./manage.py shellPython 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.(InteractiveConsole)&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; from blog.models import BlogPost&gt;&gt;&gt; for i in range(10):... bp = BlogPost(title=&apos;post $%d&apos; % i ,body=&apos;body of post $%d&apos; %d, timestamp=datetime.now())... bp.save()... 然后使用切片的方式获取最新的10篇(views.py)：1234def archive(request): # 在timestamp前面加上减号(-)指定按时间逆序排列。正常的升序只需要移除减号 posts = BlogPost.objects.all().order_by('-timestamp')[:10] return render_to_response('archive.html', &#123;'posts': posts&#125;) 设置模型的默认排序方式 如果在模型中设置首选的排序方式，其他基于Django的应用或访问这个数据的项目也会使用这个顺序。为了给模型设置默认顺序，需要创建一个名为 Meta 的内部类，在其中设置一个名为 ordering 的属性(models.py):123456789101112class BlogPost(models.Model): """ django.db.models.Model的子类Model是Django中用于数据模型的标准基类。 BlogPost中的字段像普通类属性那样定义， 每个都是特定字段类的实例，每个实例对应数据库中的一条记录。 """ title = models.CharField(max_length=150) body = models.TextField() timestamp = models.DateTimeField() class Meta: ordering = ('-timestamp',) 取消视图函数中的排序(views.py):1234def archive(request): # 在timestamp前面加上减号(-)指定按时间逆序排列。正常的升序只需要移除减号 posts = BlogPost.objects.all()[:10] return render_to_response('archive.html', &#123;'posts': posts&#125;) 处理用户输入 添加一个HTML表单，让用户可以输入数据(archive.html),为了防止 1234567891011121314&lt;form action="/blog/create/" method="post"&gt; Title: &lt;input type="text" name="title"&gt;&lt;br&gt; Body: &lt;textarea name="body" rows="3" cols="60"&gt;&lt;/textarea&gt;&lt;br&gt; &lt;input type="submit"&gt;&lt;/form&gt;&lt;hr&gt;&#123;%for post in posts%&#125; &lt;h2&gt;&#123;&#123;post.title&#125;&#125;&lt;/h2&gt; &lt;p&gt;&#123;&#123;post.timestamp&#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123;post.body&#125;&#125;&lt;/p&gt;&lt;hr&gt;&#123;% endfor %&#125; 插入(URL，视图)这样的URLConf项使用前面的HTML，需要用到/blog/create/的路径，所以需要将其关联到一个视图函数中，该函数用于把内容保存到数据库中，这个函数命名为create_blogpost()，在应用的urls.py中添加： 1234567from django.urls import *import blog.viewsurlpatterns = [ # 第一个参数是路径，第二个参数是视图函数，在调用到这个URL时用于处理信息 path('', blog.views.archive), path(r'create/', blog.views.create_blogpost)] 创建视图来处理用户输入在应用的views.py中添加上面定义的处理方法 1234567891011def create_blogpost(request): if request.method == 'POST': # 检查POST请求 # 创建新的BlogPost项，获取表单数据，并用当前时间建立时间戳。 BlogPost( title=request.POST.get('title'), body=request.POST.get('body'), timestamp=datetime.now() ).save() # 重定向会/blog return HttpResponseRedirect('/blog') 在完成上面的步骤之后，会发现创建表单的调用会被拦截报403的错误。这是因为Django有数据保留特性，不允许不安全的POST通过 跨站点请求伪造（Cross-site Request Forgery,CSRF） 来进行攻击。需要在HTML表单添加CSRF标记(&#123;% csrf_token %&#125;):123456789101112131415&lt;form action="/blog/create/" method="post"&gt;&#123;%csrf_token%&#125; Title: &lt;input type="text" name="title"&gt;&lt;br&gt; Body: &lt;textarea name="body" rows="3" cols="60"&gt;&lt;/textarea&gt;&lt;br&gt; &lt;input type="submit"&gt;&lt;/form&gt;&lt;hr&gt; &#123;%for post in posts%&#125; &lt;h2&gt;&#123;&#123;post.title&#125;&#125;&lt;/h2&gt; &lt;p&gt;&#123;&#123;post.timestamp&#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123;post.body&#125;&#125;&lt;/p&gt;&lt;hr&gt;&#123;% endfor %&#125; 通过模板发送向这些标记请求的上下文实例，这里将archive()方法调用的render_to_response()改为render:1234def archive(request): # 在timestamp前面加上减号(-)指定按时间逆序排列。正常的升序只需要移除减号 posts = BlogPost.objects.all()[:10] return render(request, 'archive.html', &#123;'posts': posts&#125;) 表单和模型表单 如果表单字段完全匹配一个数据模型，则通过Django ModelForm能更好的完成任务(models.py): 123456class BlogPostForm(forms.ModelForm): class Meta: # 定义一个Meta类，他表示表单基于哪个数据模型。当生成HTML表单时，会含有对应数据模型中的所有属性字段。 # 不信赖用户输入正确的时间戳可以通过添加exclude属性来设置。 model = BlogPost exclude = ('timestamp',) 使用ModelForm来生成HTML表单(archive.html): 123456789101112&lt;form action="/blog/create/" method="post"&gt;&#123;%csrf_token%&#125; &lt;table&gt;&#123;&#123;form&#125;&#125;&lt;/table&gt; &lt;input type="submit"&gt;&lt;/form&gt;&lt;hr&gt; &#123;%for post in posts%&#125; &lt;h2&gt;&#123;&#123;post.title&#125;&#125;&lt;/h2&gt; &lt;p&gt;&#123;&#123;post.timestamp&#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123;post.body&#125;&#125;&lt;/p&gt;&lt;hr&gt;&#123;% endfor %&#125; 因为数据已经存在于数据模型中，便不用去通过请求获取单个字段，而由于timestamp不能从表单获取，所以修改后的views.py中create_blogpost()方法如下: 12345678910111213141516def create_blogpost(request): if request.method == 'POST': # 检查POST请求 # 创建新的BlogPost项，获取表单数据，并用当前时间建立时间戳。 # BlogPost( # title=request.POST.get('title'), # body=request.POST.get('body'), # timestamp=datetime.now() # ).save() form = BlogPostForm(request.POST) if form.is_valid(): post = form.save(commit=False) post.timestamp = datetime.now() post.save() # 重定向会/blog return HttpResponseRedirect('/blog') 添加测试Django通过扩展Python自带的单元测试模块来提供测试功能。Django还可以测试文档字符串(即docstring)，这称为 文档测试(doctest) 应用的tests.py 12345678910111213141516171819202122232425262728293031323334353637383940414243from django.test import TestCasefrom datetime import datetimefrom django.test.client import Clientfrom blog.models import BlogPost# Create your tests here.class BlogPostTest(TestCase): # 测试方法必须以“test_”开头，方法名后面的部分随意。 def test_obj_create(self): # 这里仅仅通过测试确保对象成功创建，并验证标题内容 BlogPost.objects.create( title='raw title', body='raw body', timestamp=datetime.now()) # 如果两个参数相等则测试成功，否则该测试失败 # 这里验证对象的数目和标题 self.assertEqual(1, BlogPost.objects.count()) self.assertEqual('raw title', BlogPost.objects.get(id=1).title) def test_home(self): # 在'/blog/'中调用应用的主页面，确保收到200这个HTTP返回码 response = self.client.get('/blog/') self.assertIn(response.status_code, (200, )) def test_slash(self): # 测试确认重定向 response = self.client.get('/') self.assertIn(response.status_code, (301, 302)) def test_empty_create(self): # 测试'/blog/create/'生成的视图，测试在没有任何数据就错误地生成GET请求， # 代码应该忽略掉这个请求，然后重定向到'/blog' response = self.client.get('/blog/create/') self.assertIn(response.status_code, (301, 302)) def test_post_create(self): # 模拟真实用户请求通过POST发送真实数据，创建博客项，让后将用户重定向到"/blog" response = self.client.post('/blog/create/', &#123; 'title': 'post title', 'body': 'post body' &#125;) self.assertIn(response.status_code, (301, 302)) self.assertEqual(1, BlogPost.objects.count()) self.assertEqual('post title', BlogPost.objects.get(id=1).title) 源代码]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Web框架</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CGI和WSGI]]></title>
    <url>%2F2018%2F03%2F08%2FCGI%E5%92%8CWSGI%2F</url>
    <content type="text"><![CDATA[CGI这里将会主要介绍CGI的含义、与Web服务器的工作方式，使用Python创建CGI应用 CGI简介 通用网关接口(Common Gateway Interface CGI) 在Web服务器和应用之间充当了交互作用 Web服务器从客户端接收到请求(GET或POST)，并调用相应的应用程序 Web服务器和客户端等待HTML页面 应用程序处理完成后将会生成动态的HTML页面返回服务器，服务器将这个结果返回给用户 表单处理过程，服务器与外部应用程序交互，收到并生成的HTML页面通过CGI返回客户端含有需要用户输入项(文本框、单选按钮等)、Submit按钮、图片的Web页面，都会涉及某种CGI活动。创建HTML的CGI应用程序通常是高级语言来实现的，可以接受、处理用户数据，向服务器端返回HTML页面。CGI有明显的局限性，以及限制Web服务器同时处理客户端的数量。(CGI被抛弃的原因) CGI应用程序和和相关模块 CGI应用程序CGI 应用程序和典型的应用程序主要区别在于输入、输出以及用户和程序的交互方面。当一个CGI脚本启动后，需要获得用户提供的表单数据，但这些数据必须从Web客户端才可以获得，这就是 请求(request)。与标准输出不同，这些输出将会发送回连接的Web客户端，而不是发送到屏幕、GUI窗口或者硬盘上。这些返回的数据必须是具有一系列有效头文件的HTML标签数据。用户和脚本之间没有任何交互，所有交互都发生在Web客户端(基于用户的行为)、Web服务器端和CGI应用程序间。 cgi模块cgi模块有一个主要类 FieldStorage 完成了所有的工作。Python CGI脚本启动会实例化这个类，通过Web服务器从Web客户端读出相关的用户信息。在实例化完成后，其中会包含一个类似字典的对象，它具有一系列键值对。键就是通过表单传入的表单条目的名字，而值则包含响应的数据。这些值有三个对象：FieldStorage 对象；MiniFieldStorage 对象用在没有文件上传或mulitple-part格式数据的情况下，MiniFieldStorage 实例只包含名称和数据的键值对；当表单中的某个字段有多个输入值时，还可以是这些对象的列表。 cgitb模块cgitb模块用于在浏览器中看到Web应用程序的回溯信息，而不是“内部服务器错误”。 CGI应用程序 再启动服务器的目录下创建一个cgi-bin目录，放入Python CGI脚本。将一些HTML文件放到启动服务器的目录中。确保启动服务器目录中有个cgi-bin目录，同时确保其中有相应的.py文件。否则服务器将会把Python文件作为静态文本返回而不是执行它们 CGI服务器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232#!/usr/bin/python3# -*- coding:UTF-8 -*-from cgi import FieldStoragefrom os import environfrom io import StringIOfrom urllib.parse import quote, unquoteclass AdvCGI(object): # 创建header和url静态类变量，在显示不同页面的方法中会用到这些变量 header = 'Content-Type:text/html\n\n' url = '/cgi-bin/advcgi.py' # HTML静态文本表单，其中含有程序语言设置和每种语言的HTML元素 formhtml = ''' &lt;HTML&gt; &lt;HEAD&gt; &lt;TITLE&gt;Advanced CGI Demo&lt;/TITLE&gt; &lt;/HEAD&gt; &lt;BODY&gt; &lt;H2&gt;Advanced CGI Demo&lt;/H2&gt; &lt;FORM METHOD=post ACTION='%s' ENCTYPE='multipart/form-data'&gt; &lt;H3&gt;My Cookie Setting&lt;/H3&gt; &lt;LI&gt; &lt;CODE&gt;&lt;B&gt;CPPuser = %s&lt;/B&gt;&lt;/CODE&gt; &lt;H3&gt;Enter cookie value&lt;BR&gt; &lt;INPUT NAME=cookie value='%s'/&gt;(&lt;I&gt;optional&lt;/I&gt;) &lt;/H3&gt; &lt;H3&gt;Enter your name&lt;BR&gt; &lt;INPUT NAME=person VALUE='%s'/&gt;(&lt;I&gt;required&lt;/I&gt;) &lt;/H3&gt; &lt;H3&gt;What languages can you program in ? (&lt;I&gt;at least one required&lt;/I&gt;) &lt;/H3&gt; %s &lt;H3&gt;Enter file to upload&lt;SMALL&gt;(max size 4k)&lt;/SMALL&gt;&lt;/H3&gt; &lt;INPUT TYPE=file NAME=upfile VALUE='%s' SIZE=45&gt; &lt;P&gt;&lt;INPUT TYPE=submit /&gt; &lt;/LI&gt; &lt;/FORM&gt; &lt;/BODY&gt; &lt;/HTML&gt; ''' langset = ('Python', 'Java', 'C++', 'C', 'JavaScript') langItem = '&lt;INPUT TYPE=checkbox NAME=lang VALUE="%s"%s&gt; %s\n' def get_cpp_cookies(self): """ 当浏览器对应用进行连续调用时，将相同的cookie通过HTTP头发送回服务器 :return: """ # 通过HTTP_COOKIE访问这些值 if 'HTTP_COOKIE' in environ: cookies = [x.strip() for x in environ['HTTP_COOKIE'].split(';')] for eachCookie in cookies: # 寻找以CPP开头的字符串 # 只查找，名为“CPPuser”和“CPPinfo”的cookie值 if len(eachCookie) &gt; 6 and eachCookie[:3] == 'CPP': # 去除索引8处的值进行计算，计算结果保存到Python对象中 tag = eachCookie[3:7] try: # 查看cookie负载，对于非法的Python对象，仅仅保存相应的字符串值。 self.cookies[tag] = eval(unquote(eachCookie[8:])) except (NameError, SyntaxError): self.cookies[tag] = unquote(eachCookie[8:]) # 如果这个cookie丢失，就给他指定一个空字符串 if 'info' not in self.cookies: self.cookies['info'] = '' if 'user' not in self.cookies: self.cookies['user'] = '' else: self.cookies['info'] = self.cookies['user'] = '' if self.cookies['info'] != '': self.who, langstr, self.fn = self.cookies['info'].split(';') self.langs = langstr.split(',') else: self.who = self.fn = '' self.langs = ['Python'] def show_form(self): """ 将表单显示给用户 :return: """ # 从之前的请求中(如果有)获取cookie，并适当地调整表单的格式 self.get_cpp_cookies() langstr = [] for eachLang in AdvCGI.langset: langstr.append(AdvCGI.langItem % ( eachLang, ' CHECKED' if eachLang in self.langs else '', eachLang)) if not ('user' in self.cookies and self.cookies['user']): cookstatus = '&lt;I&gt;(cookie has not been set yet)&lt;/I&gt;' usercook = '' else: usercook = cookstatus = self.cookies['user'] print('%s%s' % (AdvCGI.header, AdvCGI.formhtml % ( AdvCGI.url, cookstatus, usercook, self.who, ''.join(langstr), self.fn))) errhtml = ''' &lt;HTML&gt; &lt;HEAD&gt; &lt;TITLE&gt;Advanced CGI Demo&lt;/TITLE&gt; &lt;/HEAD&gt; &lt;BODY&gt; &lt;H3&gt;ERROR&lt;/H3&gt; &lt;B&gt;%s&lt;/B&gt; &lt;P&gt; &lt;FORM&gt; &lt;INPUT TYPE= button VALUE=Back ONCLICK="window.history.back()"&gt;&lt;/INPUT&gt; &lt;/FORM&gt; &lt;/BODY&gt; &lt;/HTML&gt; ''' def show_error(self): """ 生成错误页面 :return: """ print('%s%s' % (AdvCGI.header, AdvCGI.errhtml % (self.error))) reshtml = ''' &lt;HTML&gt; &lt;HEAD&gt; &lt;TITLE&gt;Advanced CGI Demo&lt;/TITLE&gt; &lt;/HEAD&gt; &lt;BODY&gt; &lt;H2&gt;Your Uploaded Data&lt;/H2&gt; &lt;H3&gt;Your cookie value is: &lt;B&gt;%s&lt;/B&gt;&lt;/H3&gt; &lt;H3&gt;Your name is: &lt;B&gt;%s&lt;/B&gt;&lt;/H3&gt; &lt;H3&gt;You can program in the following languages:&lt;/H3&gt; &lt;UL&gt;%s&lt;/UL&gt; &lt;H3&gt;Your uploaded file...&lt;BR&gt; Name: &lt;I&gt;%s&lt;/I&gt;&lt;BR&gt; Contents: &lt;/H3&gt; &lt;PRE&gt;%s&lt;/PRE&gt; Click &lt;A HREF="%s"&gt;&lt;B&gt;here&lt;/B&gt;&lt;/A&gt; to return to form. &lt;/BODY&gt; &lt;/HTML&gt;''' def set_cpp_cookies(self): """ 应用程序调用这个方法来发送cookie（从Web服务器）到浏览器，并存储在浏览器中 :return: """ for eachCookie in self.cookies: print('Set-Cookie: CPP%s=%s; path=/' % ( eachCookie, quote(self.cookies[eachCookie]))) def doResult(self): """ 生成结果页面 :return: """ MAXBYTES = 4096 langlist = ''.join('&lt;LI&gt;%s&lt;BR&gt;' % eachLang for eachLang in self.langs) filedata = self.fp.read(MAXBYTES) if len(filedata) == MAXBYTES and f.read(): filedata = '%s%s' % (filedata, '...&lt;B&gt;&lt;I&gt;(file truncated due to size)&lt;/I&gt;&lt;/B&gt;') self.fp.close() if filedata == '': filedata = '&lt;B&gt;&lt;I&gt;(file not give or upload error)&lt;/I&gt;&lt;/B&gt;' filename = self.fn if not ('user' in self.cookies and self.cookies['user']): cookstatus = '&lt;I&gt;(cookie has not been set yet)&lt;/I&gt;' usercook = '' else: usercook = cookstatus = self.cookies['user'] self.cookies['info'] = ':'.join((self.who, ','.join(self.langs), filename)) self.set_cpp_cookies() print('%s%s' % ( AdvCGI.header, AdvCGI.reshtml % (cookstatus, self.who, langlist, filename, filedata, AdvCGI.url))) def go(self): self.cookies = &#123;&#125; self.error = '' form = FieldStorage() if not list(form.keys()): self.show_form() return if 'person' in form: print(form.keys()) self.who = form['person'].value.strip().title() if self.who == '': self.error = 'Your name is required.(blank)' else: self.error = 'Your name is required.(missing)' self.cookies['user'] = unquote(form['cookie'].value.strip()) if 'cookie' in form else '' if 'lang' in form: lang_data = form['lang'] if isinstance(lang_data, list): self.langs = [eachLang.value for eachLang in lang_data] else: self.langs = [lang_data.value] else: self.error = 'At least one language required' if 'upfile' in form: upfile = form['upfile'] self.fn = upfile.filename or '' if upfile.file: self.fp = upfile.file else: self.fp = StringIO('(no data)') else: self.fp = StringIO('(no file)') self.fn = '' if not self.error: self.doResult() else: self.show_error()if __name__ == '__main__': page = AdvCGI() page.go() 启动程序 将启动程序放在启动目录中，然后执行。 1234567#!/usr/bin/python# -*- coding:UTF-8 -*-from http.server import CGIHTTPRequestHandler, testif __name__ == '__main__': test(CGIHTTPRequestHandler) 源代码 WSGIWSGI1 是为了替代CGI而出现的。 服务器集成和外部进程 服务器集成服务器集成也叫 服务器API，其针对CGI性能的解决方案是将网关集成进服务器，不是讲服务器切分成多个语言解释器来分别处理请求，而是生成函数调用，运行应用程序代码，在运行过程中进行响应。服务器根据对应的API通过一组预先创建的进程或线程处理工作。服务器API的会使含有bug的代码影响服务器执行效率，不同语言的实现无法兼容，应用程序必须线程安全。 外部进程外部进程让CGI应用在服务器外部运行。当有请求进入时，服务器将这个请求传递到外部进程中。外部进程存在时间长，不是处理完单个请求后就终止，所以其扩展性比纯CGI好。因为使用了不同的调用机制，所以造成开发者的负担，不仅要开发应用本省，还要决定于服务器的集成。 WSGI简介WSGI只是定义的一个接口，其目标是在Web服务器和Web框架层之间提供一个通用的API标准，减少之间的会操作性并形成统一的调用方式。根据WSGI定义，其应用是可调用对象，其参数固定为：含有服务器环境变量的字典；可调用对象，该对象使用HTTP状态码和返回给客户端的HTTP头来初始化响应。 WSGI服务器在服务器端，必须调用应用，传入环境变量和start_response()这个可调用对象，接着等待应用执行完毕。在执行完成后，必须获得返回的可迭代对象，将这些数据返回给客户端。 1.WSGI只是做一个简单的了解，可以结合框架一起看。 ↩]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Web编程</tag>
        <tag>CGI</tag>
        <tag>WSGI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Web客户端和服务器]]></title>
    <url>%2F2018%2F03%2F06%2FPython-Web%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Python Web客户端工具浏览器只是Web客户端的一种。任何一个向Web服务器端发送请求来获取数据的应用程序都是“客户端”。使用urllib模块下载或者访问Web上信息的应用程序就是简单的Web客户端。 统一资源定位符 URL(统一资源定位符)适用于网页浏览的一个地址，这个地址用来在Web上定位一个文档，或者调用一个CGI程序来为客户端生成一个文档。URL是多种统一资源标识符(Uniform Resource Identifier, URI)的一部分。一个URL是一个简单的URI，它使用已有的协议或方案(http/ftp等)。非URL的URI有时称为统一资源名称(Uniform Resource Name, URN)，现在唯一使用的URI只有URL。 URL使用以下格式：post_sch://net_loc/path;parans?query#frag Web地址的各个组件 URL组件 描述 post_sch 网络协议或下载方案 net_loc 服务器所在地(也许含有用户信息) path 使用斜杠(/)分割的文件或CGI应用的路径 params 可选参数 query 连接符(&amp;)分割的一系列键值对 frag 指定文档内特定锚的部分 net_loc可以拆分为多个组件，一些可选一些必备：user:passwd@host:port 网络地址的各个组件 组件 描述 user 用户名或登录(FTP) passwd 用户密码(FTP) host 运行Web服务器的计算机名称或地址(必需的) port 端口号(如果不是默认的80) Python3 使用urllib.parse和urllib.request两种不同的模块分别以不同的功能和兼容性来处理URL urllib.parse模块 urllib.parse核心函数 urllib.parse函数 描述 urllib.parse.urlparse(urlstring, scheme=’’,allow_fragments=True) 将urlstring解析成各个组件，如果在urlstring中没有给定协议或者方法，使用scheme；allow_fragments决定是否允许URL片段 urllib.parse.urlunparse(parts) 将URL数据的一个元组拼成URL字符串 urllib.parse.urljoin(base,url,allow_fragments=True) 将URL的根域名和url拼合成一个完整的URL；allow_fragments的决定是否允许URL片段 urllib.parse.quote(string,safe=’/‘,encoding=None,errors=None) 对string在URL里无法使用的字符进行编码，safe中的字符无需编码 urllib.parse.quote_plus(string,safe=’’,encoding,errors) 除了将空格编译成加(+)号(而非20%)之外，其他功能与quote()相似 urllib.parse.unquote(string,encoding=’utf-8’,errors=’replace’) 将string编译过的字符解码 urllib.parse.unquote_plus(string,encoding=’utf-8’,errors=’replace’) 除了将加好转换为空格，其他功能与unquote()相同 urllib.parse.urlencode(query,doseq=False,safe=’’,encoding=None,errors=None,quote_via=quote_plus) 将query通过quote_plus()编译成有效的CGI查询自妇产，用quote_plus()对这个字符串进行编码 下面将对每个方法进行演示,首先导入urllib.parse下面的所有方法from urllib.parse import * urllib.parse.urlparse(urlstring, scheme=’’,allow_fragments=True) 123urlparse('http://coldjune.com/categories/')# 输出结果ParseResult(scheme='http', netloc='coldjune.com', path='/categories/', params='', query='', fragment='') urllib.parse.urlunparse(parts) 123urlunparse(('http', 'coldjune.com', '/categories/', '', '', ''))# 输出结果'http://coldjune.com/categories/' urllib.parse.urljoin(base,url,allow_fragments=True) 1234567891011121314151617# 如果是绝对路径将整个替换除根域名以外的所有内容urljoin('http://coldjune.com/categories/1.html','/tags/2.html')# 输出结果'http://coldjune.com/tags/2.html'# 如果是相对路径将会将末端文件去掉与心得url连接urljoin('http://coldjune.com/categories/1.html','tags/2.html')# 输出结果'http://coldjune.com/categories/tags/2.html'``* *urllib.parse.quote(string,safe='/',encoding=None,errors=None)*&gt; 逗号、下划线、句号、斜线和字母数字这类符号不需要转换，其他均需转换。URL不能使用的字符前面会被加上百分号(%)同时转换为十六进制(%xx,xx表示这个字母的十六进制) ```Python quote('http://www.~coldjune.com/tag categoriese?name=coold&amp;search=6') # 输出结果 'http%3A//www.%7Ecoldjune.com/tag%20categoriese%3Fname%3Dcoold%26search%3D6' urllib.parse.unquote(string,encoding=’utf-8’,errors=’replace’) 123unquote('http%3A//www.%7Ecoldjune.com/tag%20categoriese%3Fname%3Dcoold%26search%3D6')# 输出结果'http://www.~coldjune.com/tag categoriese?name=coold&amp;search=6' urllib.parse.quote_plus(string,safe=’’,encoding,errors) 123quote_plus('http://www.~coldjune.com/tag categoriese?name=coold&amp;search=6')# 输出结果'http%3A%2F%2Fwww.%7Ecoldjune.com%2Ftag+categoriese%3Fname%3Dcoold%26search%3D6' urllib.parse.unquote_plus(string,encoding=’utf-8’,errors=’replace’) 123unquote_plus('http%3A%2F%2Fwww.%7Ecoldjune.com%2Ftag+categoriese%3Fname%3Dcoold%26search%3D6')# 输出结果'http://www.~coldjune.com/tag categoriese?name=coold&amp;search=6' urllib.parse.urlencode(query,doseq=False,safe=’’,encoding=None,errors=None,quote_via=quote_plus) 1234query=&#123;'name':'coldjune','search':'6'&#125;urlencode(query)# 输出结果'name=coldjune&amp;search=6' urllib.request模块/包 urllib.request模块核心函数 urllib.request函数 描述 urllib.request.urlopen(url, data=None, [timeout,]*,cafile=None, capath=None,cadefault=False,context=None) 打开url(string或者Request对象)，data为发送给服务器的数据，timeout为超时属性， cafile,capath,cadefault为调用HTTPS请求时证书认证 urllib.request.urlretrieve(url,filename=None,reporthook=None,data=None) 将url中的文件下载到filename或临时文件中(如果没有指定filename)；如果函数正在执行，reporthook将会获得下载的统计信息 urllib.request.urlopen(url, data=None, [timeout,],cafile=None, capath=None,cadefault=False,context=None) urlopen()打开url所指向的URL；如果没有给定协议或者下载方案，或者传入”file”方案，urlopen()会打开一个本地文件。对于所有的HTTP请求，使用”GET”请求，向Web服务器发送的请求字符串应该是url的一部分；使用”POST”请求，请求的字符串应该放到data变量中。连接成功后返回的是一个文件类型对象 urlopen()文件类型对象的方法 方法 描述 f.read([bytes]) 从f中读出所有或bytes个字节 f.readline() 从f中读取一行 f.readlines() 从f中读取所有行，作为列表返回 f.close() 关闭f的URL连接 f.fileno() 返回f的文件句柄 f.info() 获取f的MIME头文件 f.geturl() 返回f的真正URL urllib.request.urlretrieve(url,filename=None,reporthook=None,data=None) urlretrieve（）用于下载完整的HTML 如果提供了reporthook函数，则在每块数据下载或传输完成后调用这个函数。调用使用目前读入的块数、块的字节数和文件的总字节数三个参数。urlretrieve()返回一个二元组(local_filename, headers)，local_filename是含有下载数据的本地文件名，headers是Web服务器响应后返回的一系列MIME文件头。 HTTP验证示例 需要先启动本地的tomcat并访问tomcat地址 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/python3# -*- coding:UTF-8 -*-import urllib.requestimport urllib.errorimport urllib.parse# 初始化过程# 后续脚本使用的常量LOGIN = 'wesly'PASSWD = "you'llNeverGuess"URL = 'http://localhost:8080/docs/setup.html'REALM = 'Secure Archive'def handler_version(url): # 分配了一个基本处理程序类，添加了验证信息。 # 用该处理程序建立一个URL开启器 # 安装该开启器以便所有已打开的URL都能用到这些验证信息 hdlr = urllib.request.HTTPBasicAuthHandler() hdlr.add_password(REALM, urllib.parse.urlparse(url)[1], LOGIN, PASSWD) opener = urllib.request.build_opener(hdlr) urllib.request.install_opener(opener=opener) return urldef request_version(url): # 创建了一个Request对象，在HTTP请求中添加了简单的base64编码的验证头 # 该请求用来替换其中的URL字符串 from base64 import encodebytes req = urllib.request.Request(url) b64str = encodebytes(bytes('%s %s' % (LOGIN, PASSWD), 'utf-8'))[:-1] req.add_header("Authorization", 'Basic %s' % b64str) return reqfor funcType in ('handler', 'request'): # 用两种技术分别打开给定的URL，并显示服务器返回的HTML页面的第一行 print('***Using %s:' % funcType.upper()) url = eval('%s_version' % funcType)(URL) f = urllib.request.urlopen(url) print(str(f.readline(), 'utf-8')) f.close() 输出结果 12345***Using HANDLER:&lt;!DOCTYPE html SYSTEM &quot;about:legacy-compat&quot;&gt;***Using REQUEST:&lt;!DOCTYPE html SYSTEM &quot;about:legacy-compat&quot;&gt; Web客户端一个稍微复杂的Web客户端例子就是 网络爬虫。这些程序可以为了不同目的在因特网上探索和下载页面。 通过起始地址(URL)，下载该页面和其他后续连接页面，但是仅限于那些与开始页面有相同域名的页面。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181#!/usr/bin/python3# -*- coding:UTF-8 -*-# 导入相关的包，其中bs4中的BeautifulSoup负责解析html文档import osimport sysimport urllib.requestimport urllib.parsefrom bs4 import BeautifulSoupclass Retriever(object): """ 从Web下载页面，解析每个文档中的连接并在必要的时候把它们加入"to-do"队列。 __slots__变量表示实例只能拥有self.url和self.file属性 """ __slots__ = ('url', 'file') def __init__(self, url): """ 创建Retriever对象时调用，将get_file()返回的URL字符串和对 应的文件名作为实例属性存储起来 :param url: 需要抓取的连接 """ self.url, self.file = self.get_file(url) def get_file(self, url, default='index.html'): """ 把指定的URL转换成本地存储的更加安全的文件，即从Web上下载这个文件 :param url: 指定URL获取页面 :param default: 默认的文件名 :return: 返回url和对应的文件名 """ # 将URL的http://前缀移除，丢掉任何为获取主机名 # 而附加的额外信息，如用户名、密码和端口号 parsed = urllib.parse.urlparse(url) host = parsed.netloc.split('@')[-1].split(':')[0] # 将字符进行解码，连接域名创建文件名 filepath = '%s%s' % (host, urllib.parse.unquote(parsed.path)) if not os.path.splitext(parsed.path)[1]: # 如果URL没有文件扩展名后这将default文件加上 filepath = os.path.join(filepath, default) # 获取文件路径 linkdir = os.path.dirname(filepath) if not os.path.isdir(linkdir): # 如果linkdir不是一个目录 if os.path.exists(linkdir): # 如果linkdir存在则删除 os.unlink(linkdir) # 创建同名目录 os.makedirs(linkdir) return url, filepath def download(self): """ 通过给定的连接下载对应的页面，并将url作为参数调用urllib.urlretrieve() 将其另存为文件名。如果出错返回一个以'*'开头的错误提示串 :return: 文件名 """ try: retval = urllib.request.urlretrieve(self.url, filename=self.file) except IOError as e: retval = (('***ERROR: bad URL "%s": %s' % (self.url, e)),) return retval def parse_links(self): """ 通过BeautifulSoup解析文件，查看文件包含的额外连接。 :return: 文件中包含连接的集合 """ with open(self.file, 'r', encoding='utf-8') as f: data = f.read() soup = BeautifulSoup(data, 'html.parser') parse_links = [] for x in soup.find_all('a'): if 'href' in x.attrs: parse_links.append(x['href']) return parse_linksclass Crawler(object): """ 管理Web站点的完整抓取过程。添加线程则可以为每个待抓取的站点分别创建实例 """ # 用于保持追踪从因特网上下载下来的对象数目。没成功一个递增1 count = 0 def __init__(self, url): """ self.q 是待下载的连接队列，这个队列在页面处理完毕时缩短，每个页面中发现新的连接则增长 self.seen 是已下载连接的集合 self.dom 用于存储主链接的域名，并用这个值判定后续连接的域名与主域名是否一致 :param url: 抓取的url """ self.q = [url] self.seen = set() parsed = urllib.parse.urlparse(url) host = parsed.netloc.split('@')[-1].split(':')[0] self.dom = '.'.join(host.split('.')[-2:]) def get_page(self, url, media=False): """ 用于下载页面并记录连接信息 :param url: :param media: :return: """ # 实例化Retriever类并传入需要抓取的连接 # 下在对应连接并取到文件名 r = Retriever(url) fname = r.download()[0] if fname[0] == '*': print(fname, '....skipping parse') return Crawler.count += 1 print('\n(', Crawler.count, ')') print('URL:', url) print('FILE:', fname) self.seen.add(url) # 跳过所有非Web页面 ftype = os.path.splitext(fname)[1] if ftype not in ('.htm', '.html'): return for link in r.parse_links(): if link.startswith('mailto:'): print('...discarded , mailto link') continue if not media: ftype = os.path.splitext(link)[1] if ftype in ('.mp3', '.mp4', '.m4av', '.wav'): print('... discarded, media file') continue if not link.startswith('http://') and ':' not in link: link = urllib.parse.quote(link, safe='#') link = urllib.parse.urljoin(url, link) print('*', link) if link not in self.seen: if self.dom not in link: print('... discarded, not in domain') else: # 如果没有下载过并且是属于该网站就加入待下载列表 if link not in self.q: self.q.append(link) print('...New, added to Q') else: print('...discarded, already in Q') else: print('...discarded, already processed') def go(self, media=False): """ 处理所有待下载连接 :param media: :return: """ while self.q: url = self.q.pop() self.get_page(url, media)def main(): if len(sys.argv) &gt; 1: url = sys.argv[1] else: try: url = input('Enter starting URL:') except (KeyboardInterrupt, EOFError): url = '' if not url: return if not url.startswith('http://') and not url.startswith('ftp://') and not url.startswith('https://'): url = 'http://%s' % url robot = Crawler(url) robot.go()if __name__ == '__main__': main() 解析Web页面BeautifulSoup是解析页面的常用库，这个库不是标准库，需要单独下载。其使用可以参照上例中的代码。 可编程的Web浏览可以使用MechanicalSoup用来模拟浏览器。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Web客户端和服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OFFICE转换工具]]></title>
    <url>%2F2018%2F03%2F06%2FOFFICE%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[全双工聊天室]]></title>
    <url>%2F2018%2F03%2F04%2F%E5%85%A8%E5%8F%8C%E5%B7%A5%E8%81%8A%E5%A4%A9%E5%AE%A4%2F</url>
    <content type="text"><![CDATA[在前面的学习中，学习了正则表达式、多线程、网络编程、数据库等相关知识点。这里结合多线程、网络编程、GUI等相关内容实现了一个全双工的聊天室。 设计思路 GUI部分框架的搭建，并编写通用部分代码，完成显示部分的基类 客户端和服务器对GUI基类进行扩展，用于显示各自特有的内容 编程线程的通用类，使所有线程的实现都通过该类，便于统一管理 完成客户端和服务器端的代码并进行整合调试 实现代码GUI的基类 chat_base.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#!/usr/bin/python3# -*- coding:UTF-8 -*-import tkinter as tkclass ChatWindowBase(object): # 窗口的基类，创建通用的窗口布局 def __init__(self): # 初始化方法 # 创建tkinter.TK()顶层窗口 # 所有主要控件都是构建在顶层窗口对象之上 # 通过tkinter.TK()创建 self.top = tk.Tk() # 在顶层窗口上添加Label控件 self.label = tk.Label(self.top, text='聊天室') # 通过Packer来管理和显示控件 # 调用pack()方法显示布局 self.label.pack() # 通过Frame控件创建子容器，用于存放其他控件 # 该对象将作为单个子对象代替父对象 self.chatfm = tk.Frame(self.top) # Scrollbar可以让显示的数据在超过Listbox的大小时能够移动列表 self.chatsb = tk.Scrollbar(self.chatfm) # 将Scrollbar放置在子容器的右侧，并且是针对y轴 self.chatsb.pack(side='right', fill='y') # 在子容器中创建高为15宽为50的Listbox # 将Listbox和Scrollbar关联起来 # 显示列表 # 显示子容器 # 控件的显示应该内部控件先显示，再显示外部控件 self.chats = tk.Listbox(self.chatfm, height=15, width=50, yscrollcommand=self.chatsb.set) self.chatsb.config(command=self.chats.yview()) self.chats.pack(side='left', fill='both') self.chatfm.pack() # 创建发送消息的子容器 self.sendfm = tk.Frame(self.top, width=50) # 创建输入框 # 绑定回车键，并且绑定send方法 # 绑定一个方法是指在触发一个事件时会去调用的方法 self.chatn = tk.Entry(self.sendfm, width=40) self.chatn.bind('&lt;Return&gt;', self.send) self.chatn.pack(side='left') # 添加按钮控件、绑定方法 self.sendchat = tk.Button(self.sendfm, text='发送', command=self.send) self.sendchat.pack(side='right', fill='both') self.sendfm.pack() def send(self, ev=None): # 创建发送消息的方法 # 空实现是为了继承时扩展 pass def receive(self): # 创建接受消息的方法 # 空实现是为了继承时扩展 pass 线程的通用类 chat_thread.py 123456789101112131415161718#!/usr/bin/python3# -*- coding:UTF-8 -*-import threadingclass ChatThread(threading.Thread): # 继承自threading.Thread，用于创建聊天室的通用线程 def __init__(self, func, args): # func: 方法 # args：方法所需要的参数 threading.Thread.__init__(self) self.func = func self.args = args def run(self): # 实现run方法，将参数传给相应的方法 self.func(*self.args) 服务端 chat_s.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#!/usr/bin/python3# -*- coding:UTF-8 -*-from chat_base import ChatWindowBasefrom chat_thread import ChatThreadfrom socket import *from time import ctimeimport tkinterHOST = ''PORT = 12345ADDR = (HOST, PORT)BUFSIZ = 1024class ChatS(ChatWindowBase): # 服务器的实现类，继承自ChatWindowBase def __init__(self): # 调用父类的__init__()方法 super(ChatS, self).__init__() self.label.configure(text='服务器') # 设置属性 # 用于保存客户端链接对象 # 用于保存客户端链接地址 self.send_sock = None self.addr = '' # 在服务器窗口创建时调用 self.receive() def send(self, ev=None): # 获取输入框信息 message = self.chatn.get() # 启动线程 ChatThread(self.send_s, (message,)).start() # 将输入框信息按照格式显示在Listbox self.chats.insert('end', '[%s]:to %s\n' % (ctime(), self.addr)) self.chats.insert('end', '%s' % message) # 删除输入框内容 self.chatn.delete(first=0, last=len(message)+1) def receive(self): # 创建socket链接 # 绑定地址 # 设置监听 # 阻塞直到有链接调用，然后保存链接的客户端对象和地址 sock = socket(AF_INET, SOCK_STREAM) sock.bind(ADDR) sock.listen(5) cli_sock, addr = sock.accept() self.addr = addr self.send_sock = cli_sock print('addr', addr) # 有链接接入时在Listbox中显示消息 self.chats.insert('end', '%s 上线' % str(addr)) # 更新顶层窗口 self.top.update() # 启动接受消息的线程 ChatThread(self.receive_s, (cli_sock, addr)).start() def send_s(self, message): # 向客户端发送消息 self.send_sock.send(bytes(message, 'utf-8')) def receive_s(self, cli_sock, addr): # 接受消息 # cli_sock: 客户端sock # addr: 客户端地址 while True: # 进入无限循环接受消息，并在Listbox显示消息 receiveData = cli_sock.recv(BUFSIZ) print('接受到消息', receiveData.decode('utf-8')) self.chats.insert('end', '[%s]:from %s' % (ctime(), addr)) self.chats.insert('end', '%s' % receiveData.decode('utf-8')) self.top.update()def main(): # 创建服务器窗口 s = ChatS() # 调用mainloop()运行整个GUI tkinter.mainloop()if __name__ == '__main__': main() 客户端 chat_c.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#!/usr/bin/python3# -*- coding:UTF-8 -*-from chat_base import ChatWindowBasefrom chat_thread import ChatThreadfrom socket import *from time import ctimeimport tkinterHOST = '127.0.0.1'PORT = 12345ADDR = (HOST, PORT)BUFSIZ = 1024class ChatC(ChatWindowBase): # 客户端的实现类，继承子ChatWindowBase方法 def __init__(self): # 初始化方法 # 在子类中必须调用父类的__init__()方法 super(ChatC, self).__init__() # 设置label的标题 self.label.configure(text='客户端') # 设置属性，用于保存sock对象用于发送和接受消息 self.sock = None # 在创建窗口时链接服务器， # 客户端需要比服务器后创建 # 否则链接会创建失败 self.receive() def send(self, ev=None): # 继承自父类，为控件调用的方法 # 获取输入框的值 message = self.chatn.get() # 创建发送消息的线程 # 将方法和方法需要的参数用作线程初始化，并启动线程 ChatThread(self.send_c, (message,)).start() # 在Listbox中按格式显示消息 self.chats.insert('end', '[%s]:to %s' % (ctime(), ADDR)) self.chats.insert('end', '%s' % message) # 删除输入框中的消息 self.chatn.delete(first=0, last=len(message)+1) # 通过更新顶层窗口显示消息 self.top.update() def receive(self): # 继承自父类 # 创建socket链接 self.sock = socket(AF_INET, SOCK_STREAM) self.sock.connect(ADDR) # 启动线程 # 将方法和方法需要的参数用作线程初始化，并启动线程 ChatThread(self.receive_c, (self.sock,)).start() def send_c(self, message): # 调用sock的send方法，向服务器发送消息 self.sock.send(bytes(message, 'utf-8')) def receive_c(self, sock): # 接受服务器数据的方法 while True: # 进入循环，等待服务器发送的消息 data = sock.recv(BUFSIZ) # 将消息按照格式显示到Listbox中 self.chats.insert('end', '[%s]:from %s' % (ctime(), ADDR)) self.chats.insert('end', '%s' % data.decode('utf-8')) # 更新控件 self.top.update()def main(): # 实例化客户端窗口 c = ChatC() # 调用mainloop方法运行整个GUI tkinter.mainloop()if __name__ == '__main__': main() 源代码]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>多线程</tag>
        <tag>网络编程</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python数据库编程(二)]]></title>
    <url>%2F2018%2F02%2F28%2FPython%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%96%E7%A8%8B-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[上一篇中主要对直接操作数据库做了一个比较详细的总结，这里将会对使用ORM框架进行简要的描述。 ORMORM系统的作者将纯SQL语句进行了抽象化处理，将其实现为Python中的对象，这样只操作这些对象就能完成与生成SQL语句相同的任务。 python与ORMSQLAlchemy和SQLObject是两种不同的Python ORM。这两种ORM并不在Python标准库中，所以需要安装。 安装SQLAlchemypip3 install sqlalchemy 安装SQLObjectpip3 install -U SQLObject 在这里将会通过两种ORM移植上一篇的数据库适配器示例应用 SQLAlchemy SQLAlchemy相比于SQLObject的接口更加接近于SQL语句。SQLAlchemy中对象的抽象化十分完成，还可以以更好的灵活性提交原生的SQL语句 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159#!/usr/bin/python3# -*- coding:UTF-8 -*-# 首先导入标准库中的模块(os.path、random)# 然后是第三方或外部模块(sqlalchemy)# 最后是应用的本地模块(ushuffleDB)from os.path import dirnamefrom random import randrange as randfrom sqlalchemy import Column, Integer, \ String, create_engine, exc, ormfrom sqlalchemy.ext.declarative \ import declarative_basefrom ushuffleDB import DBNAME, NAMELEN, \ randName, FIELDS, tformat, cformat, setup# 数据库类型+数据库驱动名称://用户名:密码@地址:端口号/数据库名称DSNs = &#123; 'mysql': 'mysql+pymysql://root:root@localhost:3306/%s' % DBNAME, 'sqlite': 'sqlite:///:memory:',&#125;# 使用SQLAlchemy的声明层# 使用导入的sqlalchemy.ext.declarative.declarative_base# 创建一个Base类Base = declarative_base()class Users(Base): # 数据子类 # __tablename__定义了映射的数据库表名 __tablename__ = 'users' # 列的属性，可以查阅文档来获取所有支持的数据类型 login = Column(String(NAMELEN)) userid = Column(Integer, primary_key=True) projid = Column(Integer) def __str__(self): # 用于返回易于阅读的数据行的字符串格式 return ''.join(map(tformat, (self.login, self.userid, self.projid)))class SQLAlchemyTest(object): def __init__(self, dsn): # 类的初始化执行了所有可能的操作以便得到一个可用的数据库，然后保存其连接 # 通过设置echo参数查看ORM生成的SQL语句 # create_engine('sqlite:///:memory:', echo=True) try: eng = create_engine(dsn) except ImportError: raise RuntimeError() try: eng.connect() except exc.OperationalError: # 此处连接失败是因为数据库不存在造成的 # 使用dirname()来截取掉数据库名，并保留DSN中的剩余部分 # 使数据库的连接可以正常运行 # 这是一个典型的操作任务而不是面向应用的任务，所以使用原生SQL eng = create_engine(dirname(dsn)) eng.execute('CREATE DATABASE %s' % DBNAME).close() eng = create_engine(dsn) # 创建一个会话对象，用于管理单独的事务对象 # 当涉及一个或多个数据库操作时，可以保证所有要写入的数据都必须提交 # 然后将这个会话对象保存，并将用户的表和引擎作为实例属性一同保存下来 # 引擎和表的元数据进行了额外的绑定，使这张表的所有操作都会绑定到这个指定的引擎中 Session = orm.sessionmaker(bind=eng) self.ses = Session() self.users = Users.__table__ self.eng = self.users.metadata.bind = eng def insert(self): # session.add_all()使用迭代的方式产生一系列的插入操作 self.ses.add_all( Users(login=who, userid=userid, projid=rand(1, 5)) for who, userid in randName() ) # 决定是提交还是回滚 self.ses.commit() def update(self): fr = rand(1, 5) to = rand(1, 5) i = -1 # 会话查询的功能，使用query.filter_by()方法进行查找 users = self.ses.query(Users).filter_by(projid=fr).all() for i, user in enumerate(users): user.projid = to self.ses.commit() return fr, to, i+1 def delete(self): rm = rand(1, 5) i = -1 users = self.ses.query(Users).filter_by(projid=rm).all() for i, user in enumerate(users): self.ses.delete(user) self.ses.commit() return rm, i+1 def dbDump(self): # 在屏幕上显示正确的输出 print('\n%s' % ''.join(map(cformat, FIELDS))) users = self.ses.query(Users).all() for user in users: print(user) self.ses.commit() def __getattr__(self, attr): # __getattr__()可以避开创建drop()和create()方法 # __getattr__()只有在属性查找失败时才会被调用 # 当调用orm.drop()并发现没有这个方法时，就会调用getattr(orm, 'drop') # 此时调用__getattr__()，并且将属性名委托给self.users。结束期会发现 # slef.users存在一个drop属性，然后传递这个方法调用到self.users.drop()中 return getattr(self.users, attr) def finish(self): # 关闭连接 self.ses.connection().close()def main(): # 入口函数 print('\n***Connnect to %r database' % DBNAME) db = setup() if db not in DSNs: print('ERROR: %r not supported, exit' % db) return try: orm = SQLAlchemyTest(DSNs[db]) except RuntimeError: print('ERROR: %r not supported, exit' % db) return print('\n*** Create users table(drop old one if appl.') orm.drop(checkfirst=True) orm.create() print('\n***Insert namse into table') orm.insert() orm.dbDump() print('\n***Move users to a random group') fr, to, num = orm.update() print('\t(%d users moved) from (%d) to (%d))' % (num, fr, to)) orm.dbDump() print('\n***Randomly delete group') rm, num = orm.delete() print('\t(group #%d; %d users removed)' % (rm, num)) orm.dbDump() print('\n***Drop users table') orm.drop() print('***Close cxns') orm.finish()if __name__ == '__main__': main() mysql输出结果 123456789101112131415161718192021222324252627282930313233343536***Connnect to &apos;test&apos; databaseChoose a database system: (M)ySQL (S)QLiteEnter choice:M*** Create users table(drop old one if appl.***Insert namse into tableLOGIN USERID PROJID Bob 1234 1 Dave 4523 1 Angela 4567 3 ***Move users to a random group (2 users moved) from (1) to (4))LOGIN USERID PROJID Bob 1234 4 Dave 4523 4 Angela 4567 3 ***Randomly delete group (group #2; 0 users removed)LOGIN USERID PROJID Bob 1234 4 Dave 4523 4 Angela 4567 3 ***Drop users table***Close cxns SQLite输出结果 1234567891011121314151617181920212223242526272829303132333435***Connnect to &apos;test&apos; databaseChoose a database system: (M)ySQL (S)QLiteEnter choice:S*** Create users table(drop old one if appl.***Insert namse into tableLOGIN USERID PROJID Bob 1234 2 Dave 4523 1 Angela 4567 2 ***Move users to a random group (2 users moved) from (2) to (2))LOGIN USERID PROJID Bob 1234 2 Dave 4523 1 Angela 4567 2 ***Randomly delete group (group #1; 1 users removed)LOGIN USERID PROJID Bob 1234 2 Angela 4567 2 ***Drop users table***Close cxns SQLObjectSQLObject需要mysqldb支持，但是由于mysqldb不再支持python3，所以根据提示安装替代方案Mysqlclient，选择对应的版本进行下载后执行相应的命令：pip3 install mysqlclient-1.3.12-cp36-cp36m-win_amd64.whl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#!/usr/bin/python3# -*- coding:UTF-8 -*-# 使用SQLObject代替SQLAlchemy# 其余和使用SQLAlchemy的相同from os.path import dirnamefrom random import randrange as randfrom sqlobject import *from ushuffleDB import DBNAME, NAMELEN, \ randName, FIELDS, tformat, cformat, setupDSNs = &#123; 'mysql': 'mysql://root:root@127.0.0.1:3306/%s' % DBNAME, 'sqlite': 'sqlite:///:memory:',&#125;class Users(SQLObject): # 扩展了SQLObject.SQLObject类 # 定义列 login = StringCol(length=NAMELEN) userid = IntCol() projid = IntCol() def __str__(self): # 提供用于显示输出的方法 return ''.join(map(tformat, ( self.login, self.userid, self.projid)))class SQLObjectTest(object): def __init__(self, dsn): # 确保得到一个可用的数据库，然后返回连接 try: cxn = connectionForURI(dsn) except ImportError: raise RuntimeError() try: # 尝试对已存在的表建立连接 # 规避RMBMS适配器不可用，服务器不在线及数据库不存在等异常 cxn.releaseConnection(cxn.getConnection()) except dberrors.OperationalError: # 出现异常则创建表 cxn = connectionForURI(dirname(dsn)) cxn.query('CREATE DATABASE %s' % DBNAME) cxn = connectionForURI(dsn) # 成功后在self.cxn中保存连接对象 self.cxn = sqlhub.processConnection = cxn def insert(self): # 插入 for who, userid in randName(): Users(login=who, userid=userid, projid=rand(1, 5)) def update(self): # 更新 fr = rand(1, 5) to = rand(1, 5) i = -1 users = Users.selectBy(projid=fr) for i, user in enumerate(users): user.projid = to return fr, to, i+1 def delete(self): # 删除 rm = rand(1, 5) users = Users.selectBy(projid=rm) i = -1 for i, user in enumerate(users): user.destroySelf() return rm, i+1 def dbDump(self): print('\n%s' % ''.join(map(cformat, FIELDS))) for user in Users.select(): print(user) def finish(self): # 关闭连接 self.cxn.close()def main(): print('***Connect to %r database' % DBNAME) db = setup() if db not in DSNs: print('\nError: %r not support' % db) return try: orm = SQLObjectTest(DSNs[db]) except RuntimeError: print('\nError: %r not support' % db) return print('\n***Create users table(drop old one if appl.)') Users.dropTable(True) Users.createTable() print('\n*** Insert names into table') orm.insert() orm.dbDump() print('\n*** Move users to a random group') fr, to, num = orm.update() print('\t(%d users moved) from (%d) to (%d)' % (num, fr, to)) orm.dbDump() print('\n*** Randomly delete group') rm, num = orm.delete() print('\t(group #%d;%d users removed)' % (rm, num)) orm.dbDump() print('\n*** Drop users table') # 使用dropTable()方法 Users.dropTable() print('\n***Close cxns') orm.finish()if __name__ == '__main__': main() MySQL输出结果 123456789101112131415161718192021222324252627282930313233Choose a database system:(M)ySQL(S)QLiteEnter choice:M***Create users table(drop old one if appl.)*** Insert names into tableLOGIN USERID PROJID Bob 1234 4 Dave 4523 3 Angela 4567 1 *** Move users to a random group(0 users moved) from (2) to (4)LOGIN USERID PROJID Bob 1234 4 Dave 4523 3 Angela 4567 1 *** Randomly delete group(group #3;1 users removed)LOGIN USERID PROJID Bob 1234 4 Angela 4567 1 *** Drop users table***Close cxns SQLite输出结果 123456789101112131415161718192021222324252627282930313233Choose a database system:(M)ySQL(S)QLiteEnter choice:S***Create users table(drop old one if appl.)*** Insert names into tableLOGIN USERID PROJID Bob 1234 2 Angela 4567 4 Dave 4523 3 *** Move users to a random group(1 users moved) from (3) to (1)LOGIN USERID PROJID Bob 1234 2 Angela 4567 4 Dave 4523 1 *** Randomly delete group(group #2;1 users removed)LOGIN USERID PROJID Angela 4567 4 Dave 4523 1 *** Drop users table***Close cxns 非关系型数据库Web和社交服务会产生大量的数据，并且数据的产生速率可能要比关系型数据库能够处理得更快。非关系数据库有对象数据库、键-值对存储、文档存储（或数据存储）、图形数据库、表格数据库、列/可扩展记录/宽列数据库、多值数据库等很多种类。 MongoDBMongoDB是非常流行的文档存储非关系数据库。 文档存储(MongoDB、CouchDB/Amazon SimpleDB)与其他非关系数据库的区别在于它介于简单的键-值对存储(Redis、Voldemort)与列存储(HBase、Google Bigtable)之间。比基于列的存储更简单、约束更少。比普通的键-值对存储更加灵活。一般情况下其数据会另存为JSON对象、并且允许诸如字符串、数值、列表甚至嵌套等数据类型 MongoDB(以及NoSQL)要讨论的事文档、集合而不是关系数据库中的行和列。MongoDB将数据存储于特殊的JSON串(文档)中，由于它是一个二进制编码的序列化，通常也称其为BSON格式。它和JSON或者Python字典都很相似。 PyMongo:MongoDB和PythonPyMongo是Python MongoDB驱动程序中最正式的一个。使用之前需要安装MongoDB数据库和PyMongo：pip3 install pymongo在windows下需要运行mongo.exe启动MongoDB，进入cmd到MongoDB的bin目录下，执行如下命令.mongod --dbpath E:\MongoDB\data 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#!/usr/bin/python3# -*- coding:UTF-8 -*-# 主要导入的是MongoClient对象和及其包异常errorsfrom random import randrange as randfrom pymongo import MongoClient, errorsfrom ushuffleDB import DBNAME, randName, FIELDS, tformat, cformat# 设置了集合(“表”)名COLLECTION = 'users'class MongoTest(object): def __init__(self): # 创建一个连接，如果服务器不可达，则抛出异常 try: cxn = MongoClient() except errors.AutoReconnect: raise RuntimeError # 创建并复用数据库及“users”集合 # 关系数据库中的表会对列的格式进行定义， # 然后使遵循这个列定义的每条记录成为一行 # 非关系数据库中集合没有任何模式的需求， # 每条记录都有其特定的文档 # 每条记录都定义了自己的模式，所以保存的任何记录都会写入集合中 self.db = cxn[DBNAME] self.users = self.db[COLLECTION] def insert(self): # 向MongoDB的集合中添加值 # 使用dict()工厂函数为每条记录创建一个文档 # 然后将所有文档通过生成器表达式的方式传递给集合的insert()方法 self.users.insert( dict(login=who, userid=uid, projid=rand(1, 5) )for who, uid in randName() ) def update(self): # 集合的update()方法可以给开发者相比于典型的数据库系统更多的选项 fr = rand(1, 5) to = rand(1, 5) i = -1 # 在更新前，首先查询系统中的项目ID(projid)与要更新的项目组相匹配的所有用户 # 使用find()方法，并将查询条件传进去(类似SQL的SELECT语句) for i, user in enumerate(self.users.find(&#123;'projid': fr&#125;)): # 使用$set指令可以显式地修改已存在的值 # 每条MongoDB指令都代表一个修改操作，使得修改操作更加高效、有用和便捷 # 除了$set还有一些操作可以用于递增字段值、删除字段(键-值对)、对数组添加/删除值 # update()方法可以用来修改多个文档(将multi标志设为True) self.users.update(user, &#123; '$set': &#123;'projid': to&#125; &#125;) return fr, to, i+1 def delete(self): # 当得到所有匹配查询的用户后，一次性对其执行remove()操作进行删除 # 然后返回结果 rm = rand(1, 5) i = -1 for i, user in enumerate(self.users.find(&#123;'projid': rm&#125;)): self.users.remove(user) return rm, i+1 def dbDump(self): # 没有天剑会返回集合中所有用户并对数据进行字符串格式化向用户显示 print('%s' % ''.join(map(cformat, FIELDS))) for user in self.users.find(): print(''.join(map(tformat, ( user[k] for k in FIELDS))))def main(): print('***Connect to %r database' % DBNAME) try: mongo = MongoTest() except RuntimeError: print('\nERROR: MongoDB server unreadable, exit') return print('\n***Insert names into table') mongo.insert() mongo.dbDump() print('\n***Move users to a random group') fr, to, num = mongo.update() print('\t(%d users moved) from (%d) to (%d)' % (num, fr, to)) mongo.dbDump() print('\n*** Randomly delete group') rm, num = mongo.delete() print('\tgroup #%d; %d users removed' % (rm, num)) mongo.dbDump() print('\n***Drop users table') mongo.db.drop_collection(COLLECTION)if __name__ == '__main__': main() 执行结果 12345678910111213141516171819202122***Connect to &apos;test&apos; database***Insert names into tableLOGIN USERID PROJID Dave 4523 4 Bob 1234 4 Angela 4567 2 ***Move users to a random group (0 users moved) from (1) to (2)LOGIN USERID PROJID Dave 4523 4 Bob 1234 4 Angela 4567 2 *** Randomly delete group group #2; 1 users removedLOGIN USERID PROJID Dave 4523 4 Bob 1234 4 ***Drop users table]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据库编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python数据库编程(一)]]></title>
    <url>%2F2018%2F02%2F28%2FPython%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%96%E7%A8%8B-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Python和大多数语言一样，访问数据库包括直接通过数据库接口访问和使用ORM访问两种方式。其中ORM访问的方式不需要显式地给出SQL命令。在Python中数据库是通过适配器的方式进行访问的。适配器是一个Python模块，使用它可以与关系型数据库的客户端库接口相连。 Python的DB-API DB-API是阐明一系列所需对象和数据库访问机制的标准，它可以为不同的数据库适配器和底层数据库系统提供一致性访问 模块属性DB-API模块属性 属性 描述 apilevel 需要适配器兼容的DB-API版本 threadsafety 本模块的线程安全级别 paramstyle 本模块的SQL语句参数风格 connect() Connect()函数 (多种异常) 数据属性 apilevel 该字符串指明了模块需要兼容的DB-API最高版本，默认值为1.0 threadsafety 0: 不支持线程安全。线程间不能共享模块1: 最小化线程安全支持：线程间可以共享模块，但是不能共享连接2: 适度的线程安全支持：线程间可以共享模块和连接，但是不能共享游标3: 完整的线程安全支持：线程间可以共享模块、连接和游标 如果有资源需要共享，那么就需要诸如自旋锁、信号量等同步原语达到原子锁定的目的 参数风格 paramstyle 参数风格 描述 示例 numeric 数值位置风格 WHERE name=:1 named 命名风格 WHERE name=:name pyformat Python字典printf()格式转换 WHERE name=%(name)s qmark 问号风格 WHERE name=? format ANSIC的printf()格式转换 WHERE name=%s 函数属性 connect()函数通过Connection对象访问数据库。兼容模块必须实现connect()函数。该函数创建并放回一个Connection对象 connect()函数使用例子：connect(dsn=&#39;myhost:MYDB&#39;, user=&#39;root&#39;, password=&#39;root&#39;) connect()函数属性 参数 描述 user 用户名 password 面 host 主机名 database 数据库名 dsn 数据源名 使用ODBC或JDBC的API需要使用DSN；直接使用数据库，更倾向于使用独立的登录参数。 异常 异常 描述 Warning 警告异常基类 Error 错误异常基类 InterfaceError 数据库接口(非数据库)错误 DatabaseError 数据库错误 DataError 处理数据时出现错误 OperationError 数据库操作执行期间出现的错误 IntegrityError 数据库关系完整性错误 InternalError 数据库内部错误 ProgrammingError SQL命令执行失败 NotSupportedError 出现不支持的操作 Connection对象 只有通过数据连接才能把命令传递到服务器，并得到返回的结果。当一个连接(或一个连接池)建立后，可以创建一个游标，向数据库发送请求，然后从数据库接收回应 Connection对象方法 方法名 描述 close() 关闭数据库连接 commit() 提交当前事务 rollback() 取消当前事务 cursor() 使用该连接创建(并返回)一个游标或类游标的对象 errorhandler(cxn,cur,errcls,errval) 作为给定连接的游标的处理程序 当使用close()时，这个连接将不能再使用，否则会进入到异常处理中 如果数据库不支持事务处理或启用了自动提交功能，commit()方法都无法使用 rollback()只能在支持事务处理的数据库中使用。发生异常时，rollback()会将数据库的状态恢复到事务处理开始时。 如果RDBMS(关系数据库管理系统)不支持游标，cursor()会返回一个尽可能模仿真实游标的对象 Cursor对象 游标可以让用户提交数据库命令，并获得查询的结果行。 对象属性 描述 arraysize 使用fetchmany()方法时，一次取出的结果行数，默认为1 connection 创建此游标的连接(可选) description 返回游标活动状态(7项元组):(name,type_code,display_size,internal_size,precision,scale,null-ok)，只有name和type_code是必需的 lastrowid 上次修改行的行ID(可选，如果不支持行ID，则返回None) rowcount 上次execute*()方法处理或影响的行数 callproc(func[,args]) 调用存储过程 close() 关闭游标 execute(op[,args]) 执行数据库查询或命令 executemany(op,args) 类似execute()和map()的结合，为给定的所有参数准备并执行数据库查询或命令 fetchone() 获取查询结果的下一行 fetchmany([size=cursor,arraysize]) 获取查询结果的下面size行 fetchall() 获取查询结果的所有(剩余)行 iter() 为游标创建迭代器对象(可选，参考nexi()) messages 游标执行后从数据库中获得的消息列表(元组集合，可选) next() 被迭代器用于获取查询结果的下一行(可选，类似fetchone(),参考iter()) nextset() 移动到下一个结果集合(如果支持) rownumber 当前结果集中游标的索引(以行为单位，从0开始，可选) setinputsizes(sizes) 设置允许的最大输入大小(必须有，但是实现是可选的) setoutputsize(size[,col]) 设置大列获取的最大缓冲区大小(必须有，但是实现是可选的) 游标对象最重要的属性是execute()和fetch()方法，所有针对数据库的服务请求都通过它们执行。当不需要是关闭游标 类型对象和构造函数 创建构造函数，从而构建可以简单地转换成适当数据库对象的特殊对象 类型对象 描述 Date(yr,mo,dy) 日期值对象 Time(hr,min,sec) 时间值对象 Timestamp(yr,mo,dy,hr,min,sec) 时间戳值对象 DateFromTicks(ticks) 日期对象，给出从新纪元时间（1970 年1 月1 日00:00:00 UTC）以来的秒数 TimeFromTicks(ticks) 时间对象，给出从新纪元时间（1970 年1 月1 日00:00:00 UTC）以来的秒数 TimestampFromTicks(ticks) 时间戳对象，给出从新纪元时间（1970 年1 月1 日00:00:00 UTC）以来的秒数 Binary(string) 对应二进制(长)字符串对象 STRING 表示基于字符串列的对象，比如VARCHAR BINARY 表示(长)二进制列的对象，比如RAW、BLOB NUMBER 表示数值列的对象 DATETIME 表示日期/时间列的对象 ROWID 表示“行ID”列的对象 SQL的NULL值对应于Python的NULL对象None 数据库适配器示例应用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201#!/usr/bin/python3# -*- coding:UTF-8 -*-# 导入必需的模块import osfrom random import randrange as rand# 创建了全局变量# 用于显示列的大小，以及支持的数据库种类COLSIZ = 10FIELDS = ('login', 'userid', 'projid')RDBMSs = &#123; 's': 'sqlite', 'm': 'mysql',&#125;DBNAME = 'test'DBUSER = 'root'# 数据库异常变量，根据用户选择运行的数据库系统的不同来制定数据库异常模块DB_EXC = NoneNAMELEN = 16# 格式化字符串以显示标题# 全大写格式化函数，接收每个列名并使用str.upper()方法把它转换为头部的全大写形式# 两个函数都将其输出左对齐，并限制为10个字符的宽度ljust(COLSIZ)tformat = lambda s: str(s).title().ljust(COLSIZ)cformat = lambda s: s.upper().ljust(COLSIZ)def setup(): return RDBMSs[input(''' Choose a database system: (M)ySQL (S)QLite Enter choice: ''').strip().lower()[0]]def connect(db): # 数据库一致性访问的核心 # 在每部分的开始出尝试加载对应的数据库模块，如果没有找到合适的模块 # 就返回None，表示无法支持数据库系统 global DB_EXC dbDir = '%s_%s' % (db, DBNAME) if db == 'sqlite': try: # 尝试加载sqlite3模块 import sqlite3 except ImportError: return None DB_EXC = sqlite3 # 当对SQLite调用connect()时，会使用已存在的目录 # 如果没有，则创建一个新目录 if not os.path.isdir(dbDir): os.mkdir(dbDir) cxn = sqlite3.connect(os.path.join(dbDir, DBNAME)) elif db == 'mysql': try: # 由于MySQLdb不支持python3.6，所以导入pymysql import pymysql import pymysql.err as DB_EXC try: cxn = pymysql.connect(host="localhost", user="root", password="root", port=3306, db=DBNAME) except DB_EXC.InternalError: try: cxn = pymysql.connect(host="localhost", user="root", password="root", port=3306) cxn.query('CREATE DATABASE %s' % DBNAME) cxn.commit() cxn.close() cxn = pymysql.connect(host="localhost", user="root", password="root", port=3306, db=DBNAME) except DB_EXC.InternalError: return None except ImportError: return None else: return None return cxndef create(cur): # 创建一个新表users try: cur.execute(''' CREATE TABLE users( login VARCHAR(%d), userid INTEGER, projid INTEGER ) ''' % NAMELEN) except DB_EXC.InternalError as e: # 如果发生错误，几乎总是这个表已经存在了 # 删除该表，重新创建 drop(cur) create(cur)# 删除数据库表的函数drop = lambda cur: cur.execute('DROP TABLE users')# 由用户名和用户ID组成的常量NAMES = ( ('bob', 1234), ('angela', 4567), ('dave', 4523))def randName(): # 生成器 pick = set(NAMES) while pick: yield pick.pop()def insert(cur, db): # 插入函数 # SQLite风格是qmark参数风格，而MySQL使用的是format参数风格 # 对于每个用户名-用户ID对，都会被分配到一个项目卒中。 # 项目ID从四个不同的组中随机选出的 if db == 'sqlite': cur.executemany("INSERT INTO users VALUES(?,?,?)", [(who, uid, rand(1, 5)) for who, uid in randName()]) elif db == 'mysql': cur.executemany("INSERT INTO users VALUES(%s, %s, %s)", [(who, uid, rand(1, 5)) for who, uid in randName()])# 返回最后一次操作后影响的行数，如果游标对象不支持该属性，则返回-1getRC = lambda cur: cur.rowcount if hasattr(cur, 'rowcount') else -1# update()和delete()函数会随机选择项目组中的成员# 更新操作会将其从当前组移动到另一个随机选择的组中# 删除操作会将该组的成员全部删除def update(cur): fr = rand(1, 5) to = rand(1, 5) cur.execute('UPDATE users SET projid=%d WHERE projid=%d' % (to, fr)) return fr, to, getRC(cur)def delete(cur): rm = rand(1, 5) cur.execute('DELETE FROM users WHERE projid=%d' % rm) return rm, getRC(cur)def dbDump(cur): # 来去所有行，将其按照打印格式进行格式化，然后显示 cur.execute('SELECT * FROM users') # 格式化标题 print('%s' % ''.join(map(cformat, FIELDS))) for data in cur.fetchall(): # 将数据(login,userid,projid)通过map()传递给tformat()， # 是数据转化为字符串，将其格式化为标题风格 # 字符串按照COLSIZ的列宽度进行左对齐 print(''.join(map(tformat, data)))def main(): # 主函数 db = setup() print('*** Connect to %r database' % db) cxn = connect(db) if not cxn: print('ERROR: %r not supported or unreadable, exit' % db) return cur = cxn.cursor() print('***Creating users table') create(cur=cur) print('***Inserting names into table') insert(cur, db) dbDump(cur) print('\n***Randomly moving folks') fr, to, num = update(cur) print('(%d users moved) from (%d) to (%d)' % (num, fr, to)) dbDump(cur) print('***Randomly choosing group') rm, num = delete(cur) print('\t(group #%d; %d users removed)' % (rm, num)) dbDump(cur) print('\n***Droping users table') drop(cur) print('\n*** Close cxns') cur.close() cxn.commit() cxn.close()if __name__ == '__main__': main() MySQL数据库访问结果 123456789101112131415161718192021222324252627Choose a database system: (M)ySQL (S)QLiteEnter choice:M*** Connect to &apos;mysql&apos; database***Creating users table***Inserting names into tableLOGIN USERID PROJID Dave 4523 2 Bob 1234 3 Angela 4567 3 ***Randomly moving folks(2 users moved) from (3) to (1)LOGIN USERID PROJID Dave 4523 2 Bob 1234 1 Angela 4567 1 ***Randomly choosing group (group #1; 2 users removed)LOGIN USERID PROJID Dave 4523 2 ***Droping users table*** Close cxns SQLite数据库访问结果 12345678910111213141516171819202122232425262728Choose a database system:(M)ySQL(S)QLiteEnter choice:S*** Connect to &apos;sqlite&apos; database***Creating users table***Inserting names into tableLOGIN USERID PROJID Dave 4523 1 Bob 1234 2 Angela 4567 3 ***Randomly moving folks(1 users moved) from (1) to (1)LOGIN USERID PROJID Dave 4523 1 Bob 1234 2 Angela 4567 3 ***Randomly choosing group(group #3; 1 users removed)LOGIN USERID PROJID Dave 4523 1 Bob 1234 2 ***Droping users table*** Close cxns]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据库编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python多线程(二)]]></title>
    <url>%2F2018%2F02%2F26%2FPython%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[在上篇主要对线程的概念做了一个简要的介绍，同时介绍了_thread模块和threading模块的使用方法，通过几个简短的程序实现了线程的调用。这篇将会记录一些多线程简单的应用以及相关生产者和消费者的问题。 多线程实践Python虚拟机是单线程（GIL）的原因，只有线程在执行I/O密集型的应用时才会更好地发挥Python的并发性。下面的例子是通过多线程下载图书排名信息的调用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#!/usr/bin/python3# -*- coding:UTF-8 -*-from atexit import registerimport reimport threadingimport timeimport urllib.request# 匹配排名的正则表达式# 亚马逊的网站REGEX = re.compile(b'#([\d,]+) in Books')AMZN = 'https://www.amazon.com/dp/'# ISBN编号和书名ISBNs = &#123; '0132269937': 'Core Python Programming', '0132356139': 'Python Web Development with Django', '0137143419': 'Python Fundamentals'&#125;# 请求头# 因为亚马逊会检测爬虫,所以需要加上请求头伪装成浏览器访问headers = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 ' '(KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36 TheWorld 7'&#125;def get_ranking(isbn): # 爬取网页,获取数据 # 使用str.format()格式化数据 url = '&#123;0&#125;&#123;1&#125;'.format(AMZN, isbn) # 爬取网页并解析 req = urllib.request.Request(url, headers=headers) page = urllib.request.urlopen(req) data = page.read() page.close() return str(REGEX.findall(data)[0], 'utf-8')def _show_ranking(isbn): # 显示结果 print('- %r ranked %s' % (ISBNs[isbn], get_ranking(isbn)))def _main(): print('At', time.ctime(), 'on Amazon...') for isbn in ISBNs: (threading.Thread(target=_show_ranking, args=(isbn,))).start() #_show_ranking(isbn)@registerdef _atexit(): # 注册一个退出函数，在脚本退出先请求调用这个函数 print('all DONE at:', time.ctime())if __name__ == '__main__': _main() 输出结果 12345At Tue Feb 27 10:40:51 2018 on Amazon...- &apos;Python Fundamentals&apos; ranked 4,358,513- &apos;Python Web Development with Django&apos; ranked 1,354,091- &apos;Core Python Programming&apos; ranked 458,510all DONE at: Tue Feb 27 10:42:39 2018 锁示例锁有两种状态:锁定 和 未锁定。同时它也支持两个函数：获得锁 和 释放锁。当多线程争夺锁时，允许第一个获得锁的线程进入临界区，并执行。之后到达的线程被阻塞，直到第一个线程执行结束，退出临界区，并释放锁。其他等待的线程随机获得锁并进入临界区。 锁和更多的随机性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#!/usr/bin/python3# -*- coding:UTF-8 -*-from __future__ import with_statementfrom atexit import registerfrom random import randrangefrom threading import Thread, Lock, current_threadfrom time import sleep, ctimeclass CleanOutputSet(set): # 集合的子类，将默认输出改变为将其所有元素 # 按照逗号分隔的字符串 def __str__(self): return ', '.join(x for x in self)# 锁# 随机数量的线程(3~6)，每个线程暂停或睡眠2~4秒lock = Lock()loops = (randrange(2, 5) for x in range(randrange(3, 7)))remaining = CleanOutputSet()def loop(sec): # 获取当前执行的线程名，然后获取锁并保存线程名 myname = current_thread().name lock.acquire() remaining.add(myname) print('[%s] Started %s' % (ctime(), myname)) # 释放锁并睡眠随机秒 lock.release() sleep(sec) # 重新获取锁，输出后再释放锁 lock.acquire() remaining.remove(myname) print('[%s] Completed %s (%d sec)' % (ctime(), myname, sec)) print(' (remaining: %s)' % (remaining or 'NONE')) lock.release()def loop_with(sec): myname = current_thread().name with lock: remaining.add(myname) print('[%s] Started %s' % (ctime(), myname)) sleep(sec) with lock: remaining.remove(myname) print('[%s] Completed %s (%d sec)' % (ctime(), myname, sec)) print(' (remaining: %s)' % (remaining or 'NONE'))def _main(): for pause in loops: # Thread(target=loop, args=(pause,)).start() Thread(target=loop_with, args=(pause,)).start()@registerdef _atexit(): print('all DONE at:', ctime())if __name__ == '__main__': _main() 输出结果 loop方法12345678910111213141516171819[Tue Feb 27 11:26:13 2018] Started Thread-1[Tue Feb 27 11:26:13 2018] Started Thread-2[Tue Feb 27 11:26:13 2018] Started Thread-3[Tue Feb 27 11:26:13 2018] Started Thread-4[Tue Feb 27 11:26:13 2018] Started Thread-5[Tue Feb 27 11:26:13 2018] Started Thread-6[Tue Feb 27 11:26:15 2018] Completed Thread-2 (2 sec) (remaining: Thread-3, Thread-4, Thread-1, Thread-5, Thread-6)[Tue Feb 27 11:26:15 2018] Completed Thread-6 (2 sec) (remaining: Thread-3, Thread-4, Thread-1, Thread-5)[Tue Feb 27 11:26:16 2018] Completed Thread-3 (3 sec) (remaining: Thread-4, Thread-1, Thread-5)[Tue Feb 27 11:26:16 2018] Completed Thread-4 (3 sec) (remaining: Thread-1, Thread-5)[Tue Feb 27 11:26:16 2018] Completed Thread-5 (3 sec) (remaining: Thread-1)[Tue Feb 27 11:26:17 2018] Completed Thread-1 (4 sec) (remaining: NONE)all DONE at: Tue Feb 27 11:26:17 2018 loop_with方法12345678910111213141516171819[Tue Feb 27 11:43:15 2018] Started Thread-1[Tue Feb 27 11:43:15 2018] Started Thread-2[Tue Feb 27 11:43:15 2018] Started Thread-3[Tue Feb 27 11:43:15 2018] Started Thread-4[Tue Feb 27 11:43:15 2018] Started Thread-5[Tue Feb 27 11:43:15 2018] Started Thread-6[Tue Feb 27 11:43:17 2018] Completed Thread-3 (2 sec) (remaining: Thread-1, Thread-5, Thread-4, Thread-6, Thread-2)[Tue Feb 27 11:43:17 2018] Completed Thread-6 (2 sec) (remaining: Thread-1, Thread-5, Thread-4, Thread-2)[Tue Feb 27 11:43:17 2018] Completed Thread-5 (2 sec) (remaining: Thread-1, Thread-4, Thread-2)[Tue Feb 27 11:43:18 2018] Completed Thread-1 (3 sec) (remaining: Thread-4, Thread-2)[Tue Feb 27 11:43:18 2018] Completed Thread-4 (3 sec) (remaining: Thread-2)[Tue Feb 27 11:43:18 2018] Completed Thread-2 (3 sec) (remaining: NONE)all DONE at: Tue Feb 27 11:43:18 2018 信号量示例对于拥有有限资源的应用来说，可以使用信号量的方式来代替锁。信号量 是一个计数器，当资源消耗时递减，当资源释放时递增。信号量比锁更加灵活，因为可以有多个线程，每个线程拥有有限资源的一个实例。消耗资源使计数器递减的操作成为P()，当一个线程对一个资源完成操作时，该资源返回资源池的操作称为V()。 糖果机和信号量 这个特制的机器只有5个可用的槽来保持库存。如果所有槽都满了，糖果不能再加入这个机器中；如果每个槽都空了，想要购买的消费者无法买到糖果。使用信号量来跟踪这些有限的资源 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#!/usr/bin/python3# -*- coding:UTF-8 -*-# 导入相应的模块和信号量类# BoundedSemaphore的额外功能是这个计数器的值永远不会超过它的初始值# 它可以防范其中信号量释放次数多余获得次数的异常用例from atexit import registerfrom random import randrangefrom threading import BoundedSemaphore, Lock, Threadfrom time import sleep, ctime# 全局变量# 锁# 库存商品最大值的常量# 糖果托盘lock = Lock()MAX = 5candytray = BoundedSemaphore(MAX)def refill(): # 当虚构的糖果机所有者向库存中添加糖果时执行 # 代码会输出用户的行动，并在某人添加的糖果超过最大库存是给予警告 lock.acquire() print('Refilling candy...') try: candytray.release() except ValueError: print('full, skipping') else: print('OK') lock.release()def buy(): # 允许消费者获取一个单位的库存 lock.acquire() print('Buying candy....') # 检测是否所有资源都已经消费完了 # 通过传入非阻塞的标志False，让调用不再阻塞，而在应当阻塞的时候返回一个False # 指明没有更多资源 if candytray.acquire(False): print('OK') else: print('Empty, skipping') lock.release()def producer(loops): for i in range(loops): refill() sleep(randrange(3))def consumer(loops): for i in range(loops): buy() sleep(randrange(3))def _main(): print('starting at:', ctime()) nloops = randrange(2, 6) print('THE CANDY MACHINE (full with %d bars)' % MAX) Thread(target=consumer, args=(randrange(nloops, nloops+MAX+2),)).start() Thread(target=producer, args=(nloops,)).start()@registerdef _atexit(): print('all DONE at:', ctime())if __name__ == '__main__': _main() 输出结果 12345678910111213141516171819202122232425262728293031starting at: Tue Feb 27 14:48:31 2018THE CANDY MACHINE (full with 5 bars)Buying candy....OKRefilling candy...OKRefilling candy...full, skippingBuying candy....OKRefilling candy...OKBuying candy....OKRefilling candy...OKRefilling candy...full, skippingBuying candy....OKBuying candy....OKBuying candy....OKBuying candy....OKBuying candy....OKBuying candy....Empty, skippingall DONE at: Tue Feb 27 14:48:42 2018 生产者-消费者问题和queue模块生产商品的时间是不确定的，消费生产者生产的商品的时间也是不确定的。在这个场景下将其放在类似队列的数据结构中。queue模块来提供线程间通信的机制，从而让线程之间可以互相分享数据。具体而言就是创建一个队列，让生产者在其中放入新的商品，而消费者消费这些商品 queue模块常用属性 属性 描述 Queue(maxsize=0) 创建一个先入先出队列。如果给定最大值，则在队列没有空间时阻塞，否则(没有指定最大值),为无限队列 LifoQueue(maxsize=0) 创建一个后入先出队列。如果给定最大值，则在队列没有空间时阻塞，否则(没有指定最大值),为无限队列 PriorityQueue(maxsize) 创建一个优先级队列。如果给定最大值，则在队列没有空间时阻塞，否则(没有指定最大值),为无限队列 queue异常 Empty 当对空队列调用get*()方法时抛出异常 Full 当对已满的队列调用put*()方法时抛出异常 queue对象方法 qsize() 返回队列大小(由于返回时队列大小可能被其他线程修改，所以改值为近似值) empty() 如果队列为空，则返回True；否则，返回False full() 如果队列已满，则返回True；否则，返回False put(item,block=True,timeout=None) 将item放入队列。如果block为True(默认)且timeout为None，则在有可用空间之前阻塞；如果timeout为正值，则最多阻塞timeout秒；如果block为False，则抛出Empty异常 put_nowait() 和put(item,False)相同 get(block=True,timeout=None) 从队列中取得元素，如果给定了block(非0)，则一直阻塞到有可用的元素为止 get_nowait() 和get(False)相同 task_done() 用于标识队列中的某个元素已执行完成，该方法会被下面的join()使用 join() 在队列中所有元素执行完毕并调用上面的task_done()信号之前，保持阻塞 生产者消费者问题使用了Queue对象，以及随机生产(消费)的商品的数量。生产者和消费者独立且并发地执行线程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#!/usr/bin/python3# -*- coding:UTF-8 -*-# 使用queue.Queue对象和之前的myThread.MyThread线程类from random import randintfrom time import sleepfrom queue import Queuefrom myThread import MyThreaddef writeQ(queue): # 将一个对象放入队列中 print('producing object for Q...') queue.put('xxx', 1) print('size now', queue.qsize())def readQ(queue): # 消费队列中的一个对象 val = queue.get(1) print('consumed object from Q... size now', queue.qsize())def writer(queue, loops): # 作为单个线程运行 # 向队列中放入一个对象，等待片刻，然后重复上述步骤 # 直至达到脚本执行时随机生成的次数没值 for i in range(loops): writeQ(queue) # 睡眠的随机秒数比reader短是为了阻碍reader从空队列中获取对象 sleep(randint(1, 3))def reader(queue, loops): # 作为单个线程运行 # 消耗队列中一个对象，等待片刻，然后重复上述步骤 # 直至达到脚本执行时随机生成的次数没值 for i in range(loops): readQ(queue) sleep(randint(2, 5))# 设置派生和执行的线程总数funcs = [writer, reader]nfuncs = range(len(funcs))def main(): nloops = randint(2, 5) q = Queue(32) threads = [] for i in nfuncs: t = MyThread(funcs[i], (q, nloops), funcs[i].__name__) threads.append(t) for i in nfuncs: threads[i].start() for i in nfuncs: threads[i].join() print('all DONE')if __name__ == '__main__': main() 输出结果 1234567891011121314starting at: Tue Feb 27 15:17:16 2018producing object for Q...size now 1starting at: Tue Feb 27 15:17:16 2018consumed object from Q... size now 0producing object for Q...size now 1producing object for Q...size now 2done at: Tue Feb 27 15:17:20 2018consumed object from Q... size now 1consumed object from Q... size now 0done at: Tue Feb 27 15:17:26 2018all DONE 线程的替代方案subprocess模块multiprocessing模块concurrent.futures模块]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python多线程(一)]]></title>
    <url>%2F2018%2F02%2F24%2FPython%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[多线程编程对于以下编程任务是非常理想的： 本质上是异步的 需要多个并发活动 每个活动的处理顺序可能是不确定的(随机、不可预测的) 使用多线程或者类似Queue的共享数据结构可以将一个串行程序规划成几个执行特定任务的线程 UserRequestThread: 负责读取客户端输入。程序将创建多个线程，每个客户端一个，客户端的请求将会被放入队列中 RequestProcessor: 该线程负责从队列中获取请求并进行处理，为第三个线程提供输出 ReplyThread: 负责向用户输出，将结果传回给用户，或者把数据写到本地文件系统或者数据库中 线程和进程 进程 计算机程序是储存在磁盘上的可执行二进制(或其他类型)的文件。进程 （有时称为 重量级进程）则是一个执行中的程序。每一个进程都拥有自己的地址空间、内存、数据栈以及其他用于跟踪执行的辅助数据。操作系统管理其上的所有进程的执行，并为它们合理地分配时间。进程可以通过 派生(fork或spawn)新的进程来执行任务,而进程之间的通信只能通过 进程间通信(IPC) 的方式共享信息 线程 线程（有时称为 轻量级进程）共享相同的上下文。相当于在主进程中并行运行的一些“迷你进程”。当其他线程运行是，它可以被抢占（中断）和临时挂起（睡眠），这种做法叫 让步(yielding)。早单核CPU系统中，线程的实际规划是：每个线程运行一小会儿，然后让步给其他线程（再次排队等待更多的CPU时间）。在整个进程的执行当中，每个线程执行它自己特定的任务，在必要时和其他线程进行结果通信。 线程与Python全局解释锁 对Python虚拟机的访问是由全局解释锁(GIL) 控制的。这个锁用来保证同时只能有一个线程运行。在多线程环境中，Python虚拟机将按照下面的方式执行。 设置GIL 切换进一个线程去运行 执行下面操作之一 a. 指定数量的字节码指令 b. 线程主动让出控制权(可以调用time.sleep(0)来完成) 把线程设置回睡眠状态(切换出线程) 解锁GIL 重复上述步骤 当调用外部代码(即，任意C/C++扩展的内置函数)时，GIL会保持锁定，直至函数执行结束。 退出线程 当一个线程完成函数的执行时，就会退出。还可以通过调用thread.exit()或者sys.exit()退出进程，或者抛出SystemExit异常，是线程退出。 _thread模块 _thread模块提供了派生线程、基本的同步数据结构(锁对象(lock object),也叫 原语锁、简单锁、互斥锁、互斥 和 二进制信号量) _thread模和锁对象 函数/方法 描述 _thread模块的函数 start_new_thread(function, args, kwargs = None) 派生一个新的线程，使用给定的args和可选的kwargs来执行function allocate_lock() 分配LockType锁对象 exit() 给线程退出命令 LockType锁对象的方法 acquire(wait = None) 尝试获取锁对象 locked() 如果获取了锁对象则返回True，否则，返回False release() 释放锁 使用线程一般方式 程序 123456789101112131415161718192021222324252627282930313233#!usr/bin/python3# -*- coding:UTF-8 -*-import _threadfrom time import ctime, sleepdef loop_0(): print('start loop_0 at:', ctime()) sleep(4) print('loop_0 done at:', ctime())def loop_1(): print('start loop_1 at:', ctime()) sleep(2) print('loop_1 done at:', ctime())def main(): print('starting at:', ctime()) # start_new_thread 方法即使要执行的 # 函数不需要参数，也需要传递一个空元组 _thread.start_new_thread(loop_0, ()) _thread.start_new_thread(loop_1, ()) # 阻止主线程的执行，保证其最后执行， # 后续去掉这种方式，引入锁的方式 sleep(6) print('all done at', ctime())if __name__ == '__main__': main() 执行结果 在主线程中同时开启了两个线程，loop_1()由于只睡眠了2s，所以先执行完，其实执行完loo_0()，线程执行的总时间是最慢的那个线程(loop_0() )的运行时间 123456starting at: Mon Feb 26 08:52:10 2018start loop_0 at: Mon Feb 26 08:52:10 2018start loop_1 at: Mon Feb 26 08:52:10 2018loop_1 done at: Mon Feb 26 08:52:12 2018loop_0 done at: Mon Feb 26 08:52:14 2018all done at Mon Feb 26 08:52:16 2018 使用锁对象 程序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!usr/bin/python3# -*- coding:UTF-8 -*-import _threadfrom time import ctime, sleeploops = [4, 2]def loop(nloop, sec, lock): # nloop: 第几个线程 # sec: 时间 # lock: 分配的锁 print('start loop', nloop, 'at:', ctime()) sleep(sec) print('loop', nloop, 'done at:', ctime()) # 当时间到了的时候释放锁 lock.release()def main(): print('starting at:', ctime()) locks = [] nloops = range(len(loops)) for i in nloops: # 生成锁对象 # 通过allocate_lock()函数得到锁对象 # 通过acquire()取到每个锁 # 添加进locks列表 lock = _thread.allocate_lock() lock.acquire() locks.append(lock) for i in nloops: # 派生线程 # 传递循环号，时间、锁对象 _thread.start_new_thread(loop, (i, loops[i], locks[i])) for i in nloops: # 等待所有线程的锁都释放完了才执行主线程 while locks[i].locked(): pass print('all DONE at:', ctime())if __name__ == '__main__': main() 执行结果 未再设置时间等待所有线程执行结束，而是在线程全部结束后马上运行主线程代码 123456starting at: Mon Feb 26 09:37:39 2018start loop 1 at: Mon Feb 26 09:37:39 2018start loop 0 at: Mon Feb 26 09:37:39 2018loop 1 done at: Mon Feb 26 09:37:41 2018loop 0 done at: Mon Feb 26 09:37:43 2018all DONE at: Mon Feb 26 09:37:43 2018 threading模块threading模块提供了更高级别、功能更全面的线程管理,还包括许多非常好用的同步机制 threading模块的对象 对象 描述 Thread 表示一个执行线程的对象 Lock 锁原语对象(和thread模块中的锁一样) RLock 可重入锁对象，使单一线程可以（再次）获得已持有的锁（锁递归） Condition 条件变量对象，使得一个线程等待另一个线程满足特定的“条件”，比如改变状态或某个数据值 Event 条件变量的通用版本，任何数量的线程等待某个事件的发生，在改事件发生后所有线程将被激活 Semaphone 为线程间共享的有限资源提供一个“计数器”，如果没有可用资源时会被阻塞 BoundSemaphone 与Semaphone相似，不过它不允许超过初始值 Timer 与Thread相似，不过它要在运行前等待一段时间 Barrier 创建一个“障碍”,必须达到指定数量的线程后才可以继续 Thread类 Thread对象的属性和方法 属性 描述 name 线程名 ident 线程的标识符 daemon 布尔标志，表示这个线程是否是守护线程 Thread对象方法 init(group=None, target=None, name=None, args=(), kwargs={}, verbose=None, daemon=就返回None) 实例化一个线程对象，需要一个可调用的target，以及参数args或kargs。还可以传递name或group参数。daemon的值将会设定thread.daemon属性/标志 start() 开始执行该线程 run() 定义线程功能的方法(通常在子类中被应用开发者重写) join(timeout=None) 直至启动的线程终止之前一直挂起；除非给出了timeout(秒)，否则会一直阻塞 使用Thread类，可以有很多方法创建线程。其中比较相似的三种方法是： 创建Thread的实例，传给它一个函数 创建Thread的实例，传给它一个可调用的类实例 派生Thread的子类，并创建子类的实例 创建Thread的实例，传给它一个函数join() 方法可以让主线程等待所有线程执行完毕，或者在提供了超时时间的情况下达到超时时间。join()方法只有在需要等待线程完成的时候才是有用的。 代码 1234567891011121314151617181920212223242526272829303132333435#!/usr/bin/python# -*- coding:UTF-8 -*-import threadingfrom time import ctime, sleeploops = [4, 2]def loop(nloop, sec): print('start loop', nloop, 'at:', ctime()) sleep(sec) print('loop', nloop, 'done at:', ctime())def main(): print('starting at:', ctime()) threads = [] nloops = range(len(loops)) for i in nloops: t = threading.Thread(target=loop, args=(i, loops[i])) threads.append(t) for i in nloops: # 启动线程 threads[i].start() for i in nloops: # 等待所有线程结束 threads[i].join() print('all DONE at:', ctime())if __name__ == '__main__': main() 结果 123456starting at: Mon Feb 26 14:29:36 2018start loop 0 at: Mon Feb 26 14:29:36 2018start loop 1 at: Mon Feb 26 14:29:36 2018loop 1 done at: Mon Feb 26 14:29:38 2018loop 0 done at: Mon Feb 26 14:29:40 2018all DONE at: Mon Feb 26 14:29:40 2018 创建Thread的实例，传给它一个可调用的类实例将传递进去一个可调用类(实例)而不仅仅是一个函数 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/python3# -*- coding:UTF-8 -*-import threadingfrom time import ctime, sleeploops = [4, 2]class ThreadFunc(object): def __init__(self, func, args, name=''): self.name = name self.func = func self.args = args def __call__(self): # Thread类的代码将调用ThreadFunc对象，此时会调用这个方法 # 因为init方法已经设定相关值，所以不需要再将其传递给Thread()的构造函数 self.func(*self.args)def loop(nloop, sec): print('start loop', nloop, 'at:', ctime()) sleep(sec) print('loop ', nloop, 'done at:', ctime())def main(): print('starting at:', ctime()) threads = [] nloops = range(len(loops)) for i in nloops: # 创建所有线程 t = threading.Thread(target=ThreadFunc(loop, (i, loops[i]))) threads.append(t) for i in nloops: threads[i].start() for i in nloops: # 等待所有线程 threads[i].join() print('all DONE at:', ctime())if __name__ == '__main__': main() 结果 123456starting at: Mon Feb 26 14:47:28 2018start loop 0 at: Mon Feb 26 14:47:28 2018start loop 1 at: Mon Feb 26 14:47:28 2018loop 1 done at: Mon Feb 26 14:47:30 2018loop 0 done at: Mon Feb 26 14:47:32 2018all DONE at: Mon Feb 26 14:47:32 2018 派生Thread的子类，并创建子类的实例(推荐)将Thread子类化，而不是直接对其实例化。这将在定制线程对象的时候拥有更多的灵活性，也能简化线程创建的调用过程 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#!/usr/bin/python3# -*- coding:UTF-8 -*-import threadingfrom time import ctime, sleeploops = [4, 2]class MyThread(threading.Thread): def __init__(self, func, args, name=''): # 必须先调用基类的构造函数 threading.Thread.__init__(self) self.name = name self.func = func self.args = args def run(self): # 必须重写run()方法 self.func(*self.args)def loop(nloop, sec): print('start loop', nloop, 'at:', ctime()) sleep(sec) print('loop ', nloop, 'done at:', ctime())def main(): print('starting at:', ctime()) threads = [] nloops = range(len(loops)) for i in nloops: # 创建所有线程 t = MyThread(loop, (i, loops[i]), loop.__name__) threads.append(t) for i in nloops: threads[i].start() for i in nloops: # 等待所有线程 threads[i].join() print('all DONE at:', ctime())if __name__ == '__main__': main() 结果 123456starting at: Mon Feb 26 15:08:33 2018start loop 0 at: Mon Feb 26 15:08:33 2018start loop 1 at: Mon Feb 26 15:08:33 2018loop 1 done at: Mon Feb 26 15:08:35 2018loop 0 done at: Mon Feb 26 15:08:37 2018all DONE at: Mon Feb 26 15:08:37 2018 单线程和多线程执行的对比先后使用单线程和多线程执行三个独立的递归函数，代码中加入sleep()是为了减慢执行速度，能够更好的看到效果。 myThread.py 1234567891011121314151617181920212223#!/usr/bin/python3# -*- coding:UTF-8 -*-import threadingfrom time import ctime, sleepclass MyThread(threading.Thread): def __init__(self, func, args, name=''): threading.Thread.__init__(self) self.name = name self.func = func self.args = args def get_result(self): # 返回每一次的执行结果 return self.res def run(self): print('starting at:', ctime()) self.res = self.func(*self.args) print('done at:', ctime()) compare.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/usr/bin/python3# -*- coding:UTF-8 -*-from myThread import MyThreadfrom time import ctime, sleepdef fib(x): # 斐波拉契 sleep(0.005) if x &lt; 2: return 1 return fib(x-2)+fib(x-1)def fac(x): # 阶乘 sleep(0.1) if x &lt; 2: return 1 return x*fac(x-1)def sum(x): # 累加 sleep(0.1) if x &lt; 2: return 1 return x + sum(x-1)funcs = [fib, fac, sum]n = 12def main(): nfuncs = range(len(funcs)) print('***SINGLE THREAD***') for i in nfuncs: # 单线程顺序执行 print('starting', funcs[i].__name__, 'at:', ctime()) print(funcs[i](n)) print(funcs[i].__name__, 'finished at:', ctime(), '\n') print('\n ***MULTIPLE THREADS***') threads = [] for i in nfuncs: # 多线程执行 t = MyThread(funcs[i], (n,),funcs[i].__name__) threads.append(t) for i in nfuncs: threads[i].start() for i in nfuncs: threads[i].join() print(threads[i].get_result()) print('all DONE')if __name__ == '__main__': main() 结果 12345678910111213141516171819202122232425***SINGLE THREAD***starting fib at: Mon Feb 26 15:36:22 2018233fib finished at: Mon Feb 26 15:36:24 2018starting fac at: Mon Feb 26 15:36:24 2018479001600fac finished at: Mon Feb 26 15:36:25 2018starting sum at: Mon Feb 26 15:36:25 201878sum finished at: Mon Feb 26 15:36:26 2018 ***MULTIPLE THREADS***starting at: Mon Feb 26 15:36:26 2018starting at: Mon Feb 26 15:36:26 2018starting at: Mon Feb 26 15:36:26 2018done at: Mon Feb 26 15:36:28 2018done at: Mon Feb 26 15:36:28 2018done at: Mon Feb 26 15:36:29 201823347900160078all DONE]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python网络编程(二)]]></title>
    <url>%2F2018%2F02%2F24%2FPython%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[上篇对Python中的socket模块的简单应用做了描述和记录，下面便是对SocketServer模块和Twisted框架做一个简要的记录 socketserver模块socketserver是标准库的一个高级模块，它的目标是简化很多样板代码，它们是创建网络客户端和服务器所必需的代码。 socketserver模块类 类 描述 BaseServer 包含核心服务器功能和mix-in类的钩子；仅用于推导，这样不会创建这个类的实例；可以用TCPServer或UDPServer创建类的实例 TCPServer/UDPServer 基础的网络同步TCP/UDP服务器 UnixStreamServer/UnixDatagramServer 基于文件的基础同步TCP/UDP服务器 ForkingMixIn/ThreadingMixIn 核心派出或线程功能；只用作mix-in类与一个服务器类配合实现一些异步性；不能直接实例化这个类 ForkingTCPServer/ForkingUDPServer ForkingMaxIn和TCPServer/UDPServer的组合 ThreadingTCPServer/ThreadingUDPServer ThreadingMixIn和TCPServer/UDPServer的组合 BaseRequestHandler 包含处理服务请求的核心功能；仅用于推导，无法创建这个类的实例；可以使用StreamRequestHandler或DatagramRequestHandler创建类的实例 StreamRequestHandler/DatagramRequestHandler 实现TCP/UDP服务器的服务处理器 socketserver TCP服务器/客户端在原始服务器循环中，我们阻塞等待请求，当接收到请求时就对其提供服务，然后继续等待。在此处的服务器循环中，并非在服务器中创建代码，而是定义一个处理程序，当服务器接收到一个传入的请求时，服务器就可以调用 TCP服务器 1234567891011121314151617181920212223242526272829#!usr/bin/python3# -*- coding:UTF-8 -*-# 导入socketserver相关的类和time.ctime()的全部属性from socketserver import (TCPServer as TCP, StreamRequestHandler as SRH)from time import ctimeHOST = ''PORT = 12345ADDR = (HOST, PORT)class MyRequestHandler(SRH): # MyRequestHandler继承自StreamRequestHandler def handle(self): # 重写handle方法，当接收到一个客户端消息是，会调用handle()方法 print('...connected from:', self.client_address) # StreamRequestHandler将输入和输出套接字看做类似文件的对象 # 所以使用write()将字符串返回客户端，用readline()来获取客户端信息 self.wfile.write(bytes('[%s] %s' % ( ctime(), self.rfile.readline().decode('utf-8')), 'utf-8'))# 利用给定的主机信息和请求处理类创建了TCP服务器# 然后无限循环地等待并服务于客户端请求tcpServ = TCP(ADDR, MyRequestHandler)print('waiting for connection...')tcpServ.serve_forever() TCP客户端 12345678910111213141516171819202122232425#!usr/bin/python3# -*- coding:UTF-8 -*-from socket import *HOST = '127.0.0.1'PORT = 12345BUFSIZE = 1024ADDR = (HOST, PORT)while True: tcpSocket = socket(AF_INET, SOCK_STREAM) tcpSocket.connect(ADDR) data = input('&gt; ') if not data: break # 因为处理程序类对待套接字通信像文件一样，所以必须发送行终止符。 # 而服务器只是保留并重用这里发送的终止符 tcpSocket.send(bytes('%s\r\n' % data, 'utf-8')) data = tcpSocket.recv(BUFSIZE) if not data: break # 得到服务器返回的消息时，用strip()函数对其进行处理并使用print()自动提供的换行符 print(data.decode('utf-8').strip()) tcpSocket.close() socketserver TCP服务器和客户端运行结果 在客户端启动的时候连接了一次服务器，而每一次发送一个请求连接一次，所以发送了三个请求连接了四次服务器 TCP服务器运行结果 12345waiting for connection......connected from: (&apos;127.0.0.1&apos;, 51835)...connected from: (&apos;127.0.0.1&apos;, 51877)...connected from: (&apos;127.0.0.1&apos;, 51893)...connected from: (&apos;127.0.0.1&apos;, 51901) TCP客户端运行结果 1234567&gt; hello[Sat Feb 24 10:29:28 2018] hello&gt; hello[Sat Feb 24 10:29:44 2018] hello&gt; hi[Sat Feb 24 10:29:50 2018] hi&gt; Twisted框架的简单使用 Twisted是一个完整的事件驱动的网络框架，利用它既能使用也能开发完整的异步网络应用程序和协议。它不是Python标准库的一部分，所以需要单独下载和安装它1。 1pip3 install Twisted-17.9.0-cp36-cp36m-win_amd64.whl 安装成功显示 1234567891011Processing e:\迅雷下载\twisted-17.9.0-cp36-cp36m-win_amd64.whlRequirement already satisfied: Automat&gt;=0.3.0 in e:\python\python36\lib\site-packages (from Twisted==17.9.0)Requirement already satisfied: zope.interface&gt;=4.0.2 in e:\python\python36\lib\site-packages (from Twisted==17.9.0)Requirement already satisfied: incremental&gt;=16.10.1 in e:\python\python36\lib\site-packages (from Twisted==17.9.0)Requirement already satisfied: hyperlink&gt;=17.1.1 in e:\python\python36\lib\site-packages (from Twisted==17.9.0)Requirement already satisfied: constantly&gt;=15.1 in e:\python\python36\lib\site-packages (from Twisted==17.9.0)Requirement already satisfied: attrs in e:\python\python36\lib\site-packages (from Automat&gt;=0.3.0-&gt;Twisted==17.9.0)Requirement already satisfied: six in e:\python\python36\lib\site-packages (from Automat&gt;=0.3.0-&gt;Twisted==17.9.0)Requirement already satisfied: setuptools in e:\python\python36\lib\site-packages (from zope.interface&gt;=4.0.2-&gt;Twisted==17.9.0)Installing collected packages: TwistedSuccessfully installed Twisted-17.9.0 Twisted Reactor TCP 服务器/客户端TCP服务器 123456789101112131415161718192021222324252627282930313233#!usr/bin/python3# -*- coding:UTF-8 -*-# 常用模块导入，特别是twisted.internet的protocol和reactorfrom twisted.internet import protocol, reactorfrom time import ctime# 设置端口号PORT = 12345class TWServProtocol(protocol.Protocol): # 继承Protocol类 def connectionMade(self): # 重写connectionMade()方法 # 当一个客户端连接到服务器是会执行这个方法 client = self.client = self.transport.getPeer().host print('...connected from:', client) def dataReceived(self, data): # 重写dataReceived()方法 # 当服务器接收到客户端通过网络发送的一些数据的时候会调用此方法 self.transport.write(bytes('[%s] %s' % ( ctime(), data.decode('utf-8')), 'utf-8'))# 创建一个协议工厂，每次得到一个接入连接是，制造协议的一个实例# 在reactor中安装一个TCP监听器，以此检查服务请求# 当接收到一个请求时，就是创建一个就是创建一个TWServProtocol实例来处理客户端事务factory = protocol.Factory()factory.protocol = TWServProtocolprint('waiting for connection...')reactor.listenTCP(PORT, factory)reactor.run() TCP客户端 12345678910111213141516171819202122232425262728293031323334353637383940#!usr/bin/python# -*- coding:UTF-8 -*-from twisted.internet import protocol, reactorHOST = '127.0.0.1'PORT = 12345class TWClientProtocol(protocol.Protocol): def sendData(self): # 需要发送数据时调用 # 会在一个循环中继续，直到不输入任何内容来关闭连接 data = input('&gt; ') if data: print('...send %s...' % data) self.transport.write(bytes(data, 'utf-8')) else: self.transport.loseConnection() def connectionMade(self): # self.sendData() def dataReceived(self, data): print(data.decode('utf-8')) self.sendData()class TWClientFactory(protocol.ClientFactory): # 创建了一个客户端工厂 protocol = TWClientProtocol clientConnectionLost = clientConnectionFailed = \ lambda self, connector, reason: reactor.stop()# 创建了一个到服务器的连接并运行reactor，实例化了客户端工厂# 因为这里不是服务器，需要等待客户端与我们通信# 并且这个工厂为每一次连接都创建一个新的协议对象。# 客户端创建单个连接到服务器的协议对象，而服务器的工厂则创建一个来与客户端通信reactor.connectTCP(HOST, PORT, TWClientFactory())reactor.run() TCP服务器和客户端运行结果 服务器结果 12waiting for connection......connected from: 127.0.0.1 客户端结果 1234567&gt; hello...send hello...[Sat Feb 24 11:19:49 2018] hello&gt; hi...send hi...[Sat Feb 24 11:20:02 2018] hi&gt; 1.需要安装python对应的版本和位数 ↩]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python网络编程(一)]]></title>
    <url>%2F2018%2F02%2F22%2FPython%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[使用Python的一些模块来创建网络应用程序 socket()函数模块要创建套接字，必须使用socket.socket()函数socket(socket_family, socket_type, protocol = 0),其中socket_family是 AF_UNIX或 AF_INET,socket_type是 SOCK_STREAM 或 SOCK_DGRAM。1protocol通常省略，默认为0。 创建TCP/IP套接字 1tcpSock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) 创建UDP/IP套接字 1udpSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) 套接字对象内接方法 名称 描述 服务器套接字方法 s.bind() 将地址(主机名、端口号对)绑定到套接字上 s.listen() 设置并启动TCP监听器 s.accept() 被动接受TCP客户端连接，一直等待知道连接到达(阻塞) 客户端套接字方法 s.connect() 主动发起TCP服务器连接 s.connect_ex() connect()的扩展版本，此时会以错误码的形式返回问题，而不是抛出一个异常 普通的套接字方法 s.recv() 接受TCP消息 s.recv_into() 接受TCP消息到指定的缓冲区 s.send() 发送TCP消息 s.sendall() 完整地发送TCP消息 s.recvfrom() 接受UDP消息 s.recvfrom_into() 接受UDP消息到指定的缓冲区 s.sendto() 发送UDP消息 s.getpeername() 连接到套接字(TCP)的远程地址 s.getsockname() 当前套接字的地址 s.getsockopt() 返回给定套接字选项的值 s.setsockopt() 设置给定套接字选项的值 s.shutdown() 关闭连接 s.close() 关闭套接字 s.detach() 在未关闭文件描述符的情况下关闭套接字，返回文件描述符 s.ioctl() 控制套接字的模式(仅支持Windows) 面向阻塞的套接字方法 s.setblocking() 设置套接字的阻塞或非阻塞模式 s.settimeout() 设置阻塞套接字操作的超时时间 s.gettimeout() 获取阻塞套接字操作的超时时间 面向文件的套接字方法 s.fileno() 套接字的文件描述符 s.makefile() 创建与套接字关联的文件对象 数据属性 s.family 套接字家族 s.type 套接字类型 s.proto 套接字协议 socket模块属性 属性名称 描述 数据属性 AF_UNIX、AF_INET、AF_INET6、AF_NETLINK、AF_TIPC Python中支持的套接字地址家族 SO_STREAM、SO_DGRAM 套接字类型(TCP=流，UDP=数据报) has_ipv6 指示是否支持IPv6的布尔标记 异常 error 套接字相关错误 herror 主机和地址相关错误 gaierror 地址相关错误 timeout 超时时间 函数 socket() 以给定的地址家族、套接字类型和协议类型(可选) 创建一个套接字对象 socketpair() 以给定的地址家族、套接字类型和协议类型(可选) 创建一个套接字对象 create_connection() 常规函数，它接收一个地址(主机号，端口号)对，返回套接字对象 fromfd() 以一个打开的文件描述符创建一个套接字对象 ssl() 通过套接字启动一个安全套接字层连接；不执行证书验证 getaddrinfo() 获取一个五元组序列形式的地址信息 getnameinfo() 给定一个套接字地址，返回(主机名，端口号)二元组 getfqdn() 返回完整的域名 gethostname() 返回当前主机名 gethostbyname() 将一个主机名映射到它的IP地址 gethostbyname_ex() gethostbyname()的扩展版本，它返回主机名、别名主机集合和IP地址列表 gethostbyaddr() 讲一个IP地址映射到DNS信息；返回与gethostbyname_ex()相同的三元组 getprotobyname() 将一个协议名(如‘TCP’)映射到一个数字 getservbyname()/getservbyport() 将一个服务名映射到一个端口号，或者反过来；对于任何一个函数来说，协议名都是可选的 ntohl()/ntohs() 将来自网络的整数装换为主机字节序 htonl()/htons() 将来自主机的整数转换为网络字节序 inet_aton()/inet_ntoa() 将IP地址八进制字符串转换成32位的包格式，或者反过来(仅用于IPv4地址) inet_pton()/inet_ntop() 将IP地址字符串转换成打包的二进制格式，或者反过来(同时适用于IPv4和IPv6) getdefaulttimeout()/setdefaulttimeout() 以秒(浮点数)为单位返回默认套接字超时时间；以秒(浮点数)为单位设置默认套接字超时时间 详情参阅socket模块文档 创建TCP服务器/客户端TCP服务器 下面是TCP服务器端的通用伪码，这是设计服务器的一种方式，可根据需求修改来操作服务器 123456789ss = socket() #创建服务器套接字ss.bind() #套接字与地址绑定ss.listen() #监听连接inf_loop: #服务器无线循环 cs = ss.accept() #接受客户端连接 comm_loop: #通信循环 cs.recv()/cs.send() #对话(接收/发送) cs.close() #关闭客户端套接字ss.close() #关闭服务器套接字 TCP时间戳服务器 12345678910111213141516171819202122232425262728293031323334353637383940#!usr/bin/python3# -*- coding:UTF-8 -*-# 导入socket模块和time.ctime()的所有属性from socket import *from time import ctime# HOST变量是空白，这是对bind()方法的标识，标识它可以使用任何可用的地址# 选择一个随机的端口号# 缓冲区大小为1KBHOST = ''PORT = 12345BUFSIZE = 1024ADDR = (HOST, PORT)# 分配了TCP服务套接字# 将套接字绑定到服务器地址# 开启TCP的监听调用# listen()方法的参数是在连接被转接或拒绝之前，传入连接请求的最大数tcpSerSock = socket(AF_INET, SOCK_STREAM)tcpSerSock.bind(ADDR)tcpSerSock.listen(5)while True: # 服务器循环，等待客户端的连接的连接 print('waiting for connection...') tcpCliSock, addr = tcpSerSock.accept() print('...connected from:', addr) while True: # 当一个连接请求出现时，进入对话循环，接收消息 data = tcpCliSock.recv(BUFSIZE) if not data: # 当消息为空时，退出对话循环 # 关闭客户端连接，等待下一个连接请求 break tcpCliSock.send(bytes('[%s] %s' % ( ctime(), data.decode('utf-8')), 'utf-8')) tcpCliSock.close() TCP客户端 下面是TCP客户端的通用伪码 12345cs = socket() #创建客户端套接字cs.connect() #尝试连接服务器comm_loop: #通信循环 cs.send()/cs.recv #对话(发送/接收)cs.close() #关闭客户端套接字 TCP时间戳客户端 1234567891011121314151617181920212223242526272829303132333435#!usr/bin/python3# -*- coding: UTF-8 -*-# 导入socket模块所有属性from socket import *# 服务器的主机名# 服务器的端口号,应与服务器设置的完全相同# 缓冲区大小为1KBHOST = '127.0.0.1'PORT = 12345BUFSIZE = 1024ADDR = (HOST, PORT)# 分配了TCP客户端套接字# 主动调用并连接到服务器tcpCliSock = socket(AF_INET, SOCK_STREAM)tcpCliSock.connect(ADDR)while True: # 无限循环，输入消息 data = bytes(input('&gt; '), 'utf-8') if not data: # 消息为空则退出循环 break # 发送输入的信息 # 接收服务器返回的信息，最后打印 tcpCliSock.send(data) data = tcpCliSock.recv(BUFSIZE) if not data: # 消息为空则退出循环 break print(data.decode('utf-8'))# 关闭客户端tcpCliSock.close() TCP服务器和客户端运行结果 在运行程序时，必须 首先运行服务器 程序，然后再运行客户端程序。如果先运行客户端程序，将会报未连接到服务器的错误。 按正确的顺序启动程序后，在客户端输入信息，将会接收到加上时间戳处理后的信息，如果直接输入回车，将会关闭客户端，而服务器将会等待下一个连接请求 服务器运行结果 123waiting for connection......connected from: (&apos;127.0.0.1&apos;, 53220)waiting for connection... 客户端运行结果 12345678&gt; hello[Fri Feb 23 14:22:58 2018] hello&gt; hi[Fri Feb 23 14:23:02 2018] hi&gt; hello world[Fri Feb 23 14:23:09 2018] hello world&gt;Process finished with exit code 0 创建UDP服务器/客户端UDP服务器 下面是UDP服务器的伪码 12345ss = socket() #创建服务器套接字ss.bind() #绑定服务器套接字inf_loop: #服务器无线循环 cs = ss.recvfrom()/ss.sendto() #关闭(接收/发送)ss.close() #关闭服务器套接字 UDP时间戳服务器 1234567891011121314151617181920212223#!usr/bin/python3# -*- coding:UTF-8 -*-# 导入socket模块和time.ctime()的全部属性from socket import *from time import ctime# 与TCP相同，由于是无连接，所以没有调用监听传入连接HOST = ''PORT = 12345BUFSIZE = 1024ADDR = (HOST, PORT)udpSerSock = socket(AF_INET, SOCK_DGRAM)udpSerSock.bind(ADDR)while True: # 进入循环等待消息，一条消息到达时，处理并返回它，然后等待下一条消息 print('waiting for message...') data, addr = udpSerSock.recvfrom(BUFSIZE) udpSerSock.sendto(bytes('[%s] %s' % ( ctime(), data.decode('utf-8')), 'utf-8'), addr) print('...received from and returned to:', addr) UDP客户端 下面是客户端的伪码 1234cs = socket() #创建客户端套接字comm_loop: #通信循环 cs.sendto()/cs.recvfrom() #对话(发送/接收)cs.close() #关闭客户端套接字 UDP时间戳客户端 12345678910111213141516171819202122#!usr/bin/python3 # -*- coding:UTF-8 -*- from socket import * HOST = '127.0.0.1' PORT = 12345 BUFSIZE = 1024 ADDR = (HOST, PORT) udpClienSock = socket(AF_INET, SOCK_DGRAM) while True: data = bytes(input('&gt;'), 'utf-8') if not data: break udpClienSock.sendto(data, ADDR) data, ADDR = udpClienSock.recvfrom(BUFSIZE) if not data: break print(data.decode('utf-8')) udpClienSock.close() UDP服务器和客户端运行结果 因为UDP面向无连接的服务，所以程序的启动顺序没有要求。当服务器处理完一个数据报之后在等待下一个继续处理 服务器运行结果 12345waiting for message......received from and returned to: (&apos;127.0.0.1&apos;, 51434)waiting for message......received from and returned to: (&apos;127.0.0.1&apos;, 51434)waiting for message... 客户端运行结果 1234567&gt;hello[Fri Feb 23 15:23:57 2018] hello&gt;hi[Fri Feb 23 15:24:03 2018] hi&gt;Process finished with exit code 0 1.AF_UNIX 是基于文件的套接字，代表 地址家族(address family):UNIX，AF_INET 是基于网络的套接字，代表 地址家族：因特网， AF_INET6 用于底6版因特网协议(IPv6)寻址。 SOCK_STREAM 表示面向连接的TCP套接字， SOCK_DGRAM 代表无连接的UDP套接字。 ↩]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python正则表达式(三)]]></title>
    <url>%2F2018%2F02%2F12%2FPython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[在之前的两篇博文中，已经对正则表达式基本及核心的知识点进行了罗列和总结。而对于正则表达式的使用却缺乏实践。本文将基于《Python核心编程(第三版)》的练习题进行一些练习。 正则表达式 识别后续的字符串：“bat”、“bit”、“but”、“hat”、“hit”或者“hut”。 1234567891011121314import remode = re.compile(r'bat|bit|but|hat|hit|hut')#mode = re.compile(r'[bh][iau]t')strs = ['bat', 'bit', 'but', 'hat', 'hit', 'hut']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'bat''bit''but''hat''hit''hut' 匹配由单个空格分隔的任意单词对，也就是姓和名。 12345678import remode = re.compile(r'^[A-Za-z]+ [A-Za-z]+$')strs = ['david Bob', 'D.Jone Steven', 'Lucy D May']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'david Bob' 匹配由单个逗号和单个空白符分隔的任何单词和单个字母，如姓氏的首字母。 123456789import remode = re.compile(r'[A-Za-z]+,\s[A-Za-z]+')strs = ['david, Bob', 'D.Jone, Steven', 'Lucy, D, May']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'david, Bob''Lucy, D' 匹配所有有效Python 标识符1的集合。 123456789101112import remode = re.compile(r'[^0-9][\w_]+')#用in排除关键字strs = ['1var', 'v_ar', '_var', 'var', 'var_9', 'var_']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'v_ar''_var''var''var_9''var_' 根据读者当地的格式，匹配街道地址（使你的正则表达式足够通用，来匹配任意数量的街道单词，包括类型名称）。例如，美国街道地址使用如下格式：1180 BordeauxDrive。使你的正则表达式足够灵活，以支持多单词的街道名称，如3120 De la CruzBoulevard。 123456789import remode = re.compile(r'^\d&#123;4&#125;( [A-Z][a-z]+)+$')strs = ['1221 Bordeaux Drive', '54565 Bordeaux Drive', 'Bordeaux Drive', '1221 Bordeaux Drive Drive']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'1221 Bordeaux Drive''1221 Bordeaux Drive Drive' 匹配以“www”起始且以“.com”结尾的简单Web 域名；例如，www://www. yahoo.com/。选做题：你的正则表达式也可以支持其他高级域名，如.edu、.net 等（例如，http://www.foothill.edu）。 1234567891011import remode = re.compile(r'^(http[s]?://)?www\.(\w+\.)+(com|net|edu)$')strs=['https://www.baidu.com', 'http://www.bilibili.com', 'www.baidu.com', 'baidu.com', 'www.cqupt.edu']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'https://www.baidu.com''http://www.bilibili.com''www.baidu.com''www.cqupt.edu' 匹配所有能够表示Python 整数的字符串集。 12345678910import remode = re.compile(r'^\d+[lL]?$')strs = ['123', '123l', '12312L']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'123''123l''12312L' 匹配所有能够表示Python 长整数的字符串集。 123456789import remode = re.compile(r'^\d+[lL]$')strs = ['123', '123l', '12312L']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'123l''12312L' 匹配所有能够表示Python 浮点数的字符串集。 12345678910import remode = re.compile(r'(0|[1-9]\d*)(\.\d+)?$')strs = ['00.10', '0.123', '12.23', '12', '12.36l']for s in strs: if mode.match(s) is not None:mode.match(s).group() #输出结果'0.123''12.23''12' 匹配所有能够表示Python 复数的字符串集。 12345678910import remode = re.compile(r'^((0|[1-9]\d*)(\.\d+)?\+)?((0|[1-9]\d*)(\.\d+)?j)?$')strs = ['12.3+1.2j', '1+2j', '4j']for s in strs: if mode.match(s) is not None:mode.match(s).group() #输出结果'12.3+1.2j''1+2j''4j' 匹配所有能够表示有效电子邮件地址的集合（从一个宽松的正则表达式开始，然后尝试使它尽可能严谨，不过要保持正确的功能）。 123456789101112import remode = re.compile(r'^\w+@(\w+\.)+(com|com\.cn|net)$')strs = ['12345@qq.com', 'sina@163.com', 'qq@sina.com.cn', 'net@21cn.com', 'new123@163.sina.com']for s in strs: if mode.match(s) is not None:mode.match(s).group() #输出结果'12345@qq.com''sina@163.com''qq@sina.com.cn''net@21cn.com''new123@163.sina.com' type()。内置函数type()返回一个类型对象，如下所示，该对象将表示为一个Pythonic类型的字符串。 12345678910import remode = re.compile(r'&lt;type \'(.*)\'&gt;')strs = ['&lt;type \'int\'&gt;', '&lt;type \'float\'&gt;', '&lt;type \'builtin_function_or_method\'&gt;']for s in strs: if mode.match(s) is not None:mode.match(s).group(1)#输出结果'int''float''builtin_function_or_method' 处理日期。1.2 节提供了来匹配单个或者两个数字字符串的正则表达式模式，来表示1～9 的月份(0?[1-9])。创建一个正则表达式来表示标准日历中剩余三个月的数字。 12345678910import remode = re.compile(r'1[0-2]')strs = ['10', '11', '12']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'10''11''12' 创建一个允许使用连字符的正则表达式，但是仅能用于正确的位置。例如，15 位的信用卡号码使用4-6-5 的模式，表明4 个数字-连字符-6 个数字-连字符-5 个数字；16 位的信用卡号码使用4-4-4-4 的模式。 123456789import remode = re.compile(r'\d&#123;4&#125;-((\d&#123;6&#125;-\d&#123;5&#125;)|(\d&#123;4&#125;-\d&#123;4&#125;-\d&#123;4&#125;))')strs = ['1234-567890-12345', '1234-5678-8012-3456']for s in strs: if mode.match(s) is not None:mode.match(s).group()#输出结果'1234-567890-12345''1234-5678-8012-3456' 1.标识符有字母、数字、下划线组成，但不能由数字开头 ↩]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python正则表达式(二)]]></title>
    <url>%2F2018%2F02%2F10%2FPython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[正则表达式的匹配规则基本已经在上一篇博文中全部罗列出来了，下面便是结合到具体语言进行学习和练习了。由于个人兴趣和想要专研的方向，在这里将会使用Python 1 语言进行描述。 正则表达式和Python语言re模块：核心函数和方法 函数方法 描述 仅仅是re函数模块 compile(pattern, flags=0) 使用任何可选的标记来编译正则表达式的模式，然后返回一个正则表达式对象 re模块函数和正则表达式对象的方法 match(pattern, string, flags=0) 尝试使用带有可选的标记的正则表达式的模式来匹配字符串，如果匹配成功，就返回匹配对象；如果失败，就返回None search(pattern, string, flags=0) 使用可选标记搜索字符串中第一次出现的正则表达式模式。如果匹配成功，则返回匹配对象；如果匹配失败，怎返回None findall(pattern, string [,flags]) 查找字符串中所有(非重复)出现的正则表达式模式，并返回一个匹配列表 finditer(pattern, string[,flags]) 与findall()函数相同，但返回的不是一个列表，而是一个迭代器。对于每一次匹配，迭代器都返回一个匹配对象 split(pattern, string, max=0) 根据正则表达式的模式分隔符，split函数将字符串分割为列表，然后返回成功的列表，分割最多操作max次(默认分割所有匹配成功的位置) sub(pattern, repl, string, count=0) 使用repl替换所有正则表达式的模式在字符串中出现的位置，除非定义count，否则就讲替换所有出现的位置（另见subn()函数，该函数返回替换操作的数目） purge() 清除隐式编译的正则表达式模式 常见的匹配对象方法 group(num=0) 返回整个匹配对象，或者编号为num的特定子组 groups(default=None) 返回一个包含所有匹配子组的元组(如果没有成功匹配，则返回一个空元组) groupdict(default=None) 返回一个包含所有匹配的命名子组的字典，所有的子组名称作为字典的键(如果没有成功匹配，则返回一个空字典) 常用的模块属性（用于大多数正则表达式函数的标记） re.I,re.IGNORECASE 不去分大小写的匹配 re.L,re.LOCALE 根据所使用的本地语言环境通过\w、\w、\b、\B、\s、\S实现匹配 re.M,re.MULTILINE ^和$分别匹配目标字符串中行的起始和结尾，而不是严格匹配整个字符串本身的起始和结尾 re.S,re.DOTALL “.”(点号)通常匹配除了\n(换行符)之外的所有单个字符：该标记表示”.”(点号)能匹配全部字符 re.X,re.VERBOSE 通过反斜线转移，否则所有空格加上#(以及在该行中后续文字)都被忽略，除非在一个字符类中或者允许注释并且提高可读性 部分方法总结 compile(pattern, flags=0)2 使用预编译使用推荐的方式，但不是必须的，可以通过设置标志位(上表已罗列出使用频繁的标记，详情可以查阅文档),标志位通过 （|）合并 group(num=0) 和 groups(default=None) 匹配对象3的两个主要方法。 group() 要么返回整个匹配对象，要么按要求返回特定子组。 groups() 仅返回一个包含唯一或全部子组的元组。如果没有子组的要求，group() 返回整个匹配，groups() 返回一个空元组。 match(pattern, string, flags=0) match() 方法试图从字符串的起始部分对模式进行匹配。如果匹配成功，返回一个匹配对象；如果失败就返回None 12345678910111213 #匹配成功 m = re.match('foo', 'foo') #模式匹配字符串 if m is not None: #如果匹配成功，就输出匹配内容 m.group()'foo' #输出结果#匹配失败m = re.match('foo', 'Bfoo') #模式匹配字符串if m is not None: #如果匹配成功，就输出匹配内容 m.group() #因为起始字符为'B',所以匹配不成功，无任何输出 search(pattern, string, flags=0) search() 的工作方式和 match() 相同，不同之处在于 search() 会用它的字符串参数在任意位置对给定正则表达式模式搜索第一次出现的匹配情况。如果搜索到成功的匹配，就返回一个匹配对象；否则，就返回None。 123456#将上面使用match()方法匹配的串改用search()匹配m = re.search('foo', 'Bfoo') #模式匹配字符串if m is not None: #如果匹配成功，就输出匹配内容 m.group()'foo' #可以看到就算起始位置未能匹配，也能匹配成功 findall(pattern, string[,flags]) 和 finditer(pattern, string[,flags]) findall() 总是返回一个列表，如果没有找到匹配对象，返回一个空列表 finditer() 是一个与 findall() 类似但更节省内存的变体，finditer() 在匹配对象中迭代4 1234567891011121314#findall()匹配re.findall('car', 'carry the barcardi to the car') #模式匹配字符串['car', 'car', 'car'] #返回结果#finditer()匹配iter = re.finditer('car', 'carry the barcardi to the car') #模式匹配字符串for i in iter: #遍历迭代器 print(i.group())#输出结果carcarcar sub(pattern, repl, string, count=0) 和 subn(pattern, repl, string, count=0) sub() 和 subn() 用于实现搜索和替换功能。两者都是将某字符串中所有匹配正则表达式的部分进行某种形式的替换。和 sub() 不同的是，subn() 返回一个表示替换的总数，替换后的字符串和表示替换总数的数字一起作为一个拥有两个元素的元组返回 12345678910#sub()re.sub('car', 'cat', 'My car is not only a car.') #模式匹配字符串'My cat is not only a cat.' #输出结果#subn()re.subn('car', 'cat', 'My car is not only a car.') #模式匹配字符串('My cat is not only a cat.', 2) #输出结果 split(pattern, string, max=0) 正则表达式对象的 split() 方法和字符串的工作方式类似，但它是基于正则表达式的模式分割字符串。 123456789101112131415161718192021222324re.split(':', 'str1:str2:str3') #模式匹配字符串['str1', 'str2', 'str3'] #输出结果，与'str1:str2:str3'.split(':')相同#split()复杂用法#使用split()基于逗号分割字符串，如果空格紧跟在5个数字或者两个大写字母之后，就用split()分割该空格#使用(?=)正向前视断言，不适用输入字符串 而是使用后面的空格作为分割字符串import reDATA = ( 'Mountain View, CA 94040', 'Sunnyvale, CA', 'Los Altos, 94023', 'Cupertino 95014', 'Palo Alto CA',)for datum in DATA: print(re.split(', |(?= (?:\d&#123;5&#125;|[A-Z]&#123;2&#125;)) ', datum))#输出结果['Mountain View', 'CA', '94040']['Sunnyvale', 'CA']['Los Altos', '94023']['Cupertino', '95014']['Palo Alto', 'CA'] 符号的使用| 与 . 和 [] 包括择一匹配符号|、点号.，点号不匹配非字符或换行付\n（即空字符） 字符集[]中的字符只取其一 重复、特殊字符5以及分组 ?操作符表示前面的模式出现零次或一次+操作符表示前面的模式出现至少一次*操作符表示前面的模式出现任意次(包括0次)分组从左起第一个括号开始算第一个分组 123456789101112131415m = re.match('(\w(\w\w))-(\d\d\d)','abc-123')m.group() #完整匹配'abc-123' #输出结果m.group(1) #第一组'abc' #输出结果 m.group(2) #第二组'bc' #输出结果m.group(3) #第三组'123' #输出结果m.groups() #全部子组('abc', 'bc', '123') #输出结果 1.这里Python指代的是Python3.6.4 ↩2.预编译可以提升执行效率，而 re.compile() 方法提供了这个功能。模块函数会对已编译的对象进行缓存，所以无论使用 match() 和 search() 在执行时编译的正则表达式,还是使用 compile() 编译的表达式,在再次使用时都会查询缓存。但使用 compile() 同样可以节省查询缓存的时间 ↩3.除了正则表达式对象之外，还有另外一个对象类型：匹配对象。这些是成功调用 match() 和 search() 返回的对象。 ↩4.如果遇到无法调用 next()方法，可以使用 __next__()方法代替。 ↩5.特殊字符的详情可以参考上一篇博文 ↩]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python正则表达式(一)]]></title>
    <url>%2F2018%2F02%2F09%2FPython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[在Python的学习过程中，正则表达式始终是一道绕不过去的坎.无论提取服务器日志文件还是爬取网页，正则表达式始终扮演着至关重要的角色。下面便对自己学习过程中的一些正则表达式基础做一个总结。 特殊符号和字符 表示法 描述 正则表达式示例 备注 符号 literal 匹配文本字符串的字面值literal foo 只是匹配foo，相当于取等 re1&#124; re2 匹配正则表达式re1或re2 foo&#124; bar 匹配foo或者bar，二选一 . 匹配任何字符(除了\n之外) a.a 匹配axa、aaa、aca等，两个a中间可以是除了\n的任意字符 ^ 匹配字符串起始部分 ^Foo 匹配Foo，不匹配aFoo $ 匹配字符串终止部分 Bar$ 只匹配Bar,不匹配aBar等 * 匹配0次或者多次前面出现的正则表达式 [A-Za-z0-9]* 匹配任意多个字母或数字 + 匹配1次或者多次前面出现的正则表达式 [A-Za-z0-9]+ 匹配一到多个个字母或数字 ? 匹配0次或者1次前面出现的正则表达式 [A-Za-z0-9] 要么有一个字母或数字要么没有 {N} 匹配N次前面出现的正则表达式 [0-9]{3} 匹配三个数字 {M,N} 匹配M~N次前面出现的正则表达式 [0-9]{5,9} 匹配5到9个数字(包括5个和9个) […] 匹配来自字符集的任意单一字符 [aeiou] 匹配一个元音字母 [..x~y..] 匹配x~y范围内的任意单一字符 [A-Za-z] 匹配任意一个英文字母 [^…] 不匹配此字符集中出现的任何一个字符，包括某一范围的字符(如果在此字符集中出现) [\^aeiou][\^A-Za-z0-9] 匹配一个非元音字母和一个非字母数字字符 (*&#124;+&#124;?&#124;{})? 用于匹配上面频繁出现/重复出现符号的非贪婪版本(*、+、?、{}) .*?[a-z] (非贪婪是指尽可能少的匹配) (…) 匹配封闭的正则表达式,然后另存为子组 f(oo&#124; u)bar 匹配foobar,fubar 特殊字符 \d 匹配任何十进制数字，与[0-9]一致(\D和\d相反，不匹配任何非数值型的数字) data\d+.txt 匹配data1.txt、data12.txt \w 匹配任何字母数字字符，与[A-Za-z0-9]相同(\W与之相反) [A-Za-z_]\w+ 匹配任意字母或_加一个或多个字母数字字符(asda,_asda) \s 匹配任何空格字符，与[\n\t\r\v\f]相同(\S与之相反) of\sthe 匹配of the (\n:换行符&#124;\t:水平制表符&#124;\r:回车&#124;\v:垂直制表符&#124;\f:换页符) \b 匹配任何单词边界(\B与之相反) \bThe\b 匹配of The a，不匹配ofThe a \N 匹配已保存的子组N(与上面(…)配合使用) price:\16 匹配price:和前面第16个子组的值 \c 逐字匹配任何特殊字符(即仅按字面意义匹配，不包含特殊含义，\为对特殊字符的转义表示) * 匹配* \A(\Z) 匹配字符串的起始(结束)(另见上面的^和$) \ADear 匹配以Dear开头的 扩展表示法 （?iLmsux） 在正则表达式中嵌入一个或多个特殊”标记”参数(或者通过函数/方法) （?x）,(?im) (?:…) 表示一个匹配不用保存的分组 (?:\w+.)* 匹配任意多个一个或多个字母数字字符与.的组合但不保存改分组 (?P…) 像一个仅由name标识而不是数字ID标识的正则分组匹配 (?P) 给匹配的分组命名为data (?P=name) 在同一个字符串中匹配由(?P)分组之前的文本 (?P=data) 匹配名字为data的串 (?#…) 表示注释，所有内容都被忽略 (?#comment) (?=…) 匹配条件是如果…出现在之后的位置，而不使用输入字符串；称作正向前视断言 (?=.com) 如果一个字符串后面跟着“.com”才做匹配操作，并不适用任何目标字符串 (?!…) 匹配条件是如果…不出现在之后的位置，而不使用输入字符串；称作负向前视断言 (?!.net) 如果一个字符串后面不是跟着“.net”，才做匹配操作 (?&lt;=…) 匹配条件是如果…出现在之前的位置，而不使用输入字符串；称作正向后视断言 (?&lt;=800-) 如果字符串之前为“800-”才做匹配，并不使用任何输入字符串 (?&lt;!…) 匹配条件是如果…不出现在之前的位置，而不使用输入字符串；称作负向后视断言 (?&lt;!192\.168\.) 如果一个字符串之前不是“192.168.”才做匹配，并不适用任何输入字符串 (?(id/name)Y&#124;N 如果分组所提供的id或name(名称)存在，就返回正则表达式的条件匹配Y，如果不存在，就返回N;N是可选项 (?(1)y&#124;x) 如果一个匹配组1(\1)存在就y匹配；否则，就与x匹配 以上为正则表达式的一些基本的符号定义与用法，熟练掌握这些符号是写出高效表达式的基础。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
</search>
